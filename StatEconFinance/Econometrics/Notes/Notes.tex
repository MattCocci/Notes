\documentclass[12pt]{article}

\author{Matthew D. Cocci}
\title{ECO-513: Notes}
\date{\today}

%% Formatting & Spacing %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry} % most detailed page formatting control
\usepackage{fullpage} % Simpler than using the geometry package; std effect
\usepackage{setspace}
%\onehalfspacing
\usepackage{microtype}

%% Formatting %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage[margin=1in]{geometry}
    %   Adjust the margins with geometry package
%\usepackage{pdflscape}
    %   Allows landscape pages
%\usepackage{layout}
    %   Allows plotting of picture of formatting



%% Header %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage{fancyhdr}
%\pagestyle{fancy}
%\lhead{}
%\rhead{}
%\chead{}
%\setlength{\headheight}{15.2pt}
    %   Make the header bigger to avoid overlap

%\fancyhf{}
    %   Erase header settings

%\renewcommand{\headrulewidth}{0.3pt}
    %   Width of the line

%\setlength{\headsep}{0.2in}
    %   Distance from line to text


%% Mathematics Related %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{amsthm} %allows for labeling of theorems
%\numberwithin{equation}{section} % Number equations by section
\usepackage{bbm} % For bold numbers

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{assump}[thm]{Assumption}
\newtheorem{ex}[thm]{Example}

\theoremstyle{remark}
\newtheorem*{rmk}{Remark}
\newtheorem*{note}{Note}

% Below supports left-right alignment in matrices so the negative
% signs don't look bad
\makeatletter
\renewcommand*\env@matrix[1][c]{\hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{*\c@MaxMatrixCols #1}}
\makeatother


%% Font Choices %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
%\usepackage{blindtext}
\usepackage{courier}


%% Figures %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing}
%\usetikzlibrary{arrows.meta}
\usepackage{graphicx}
\usepackage{subfigure}
    %   For plotting multiple figures at once
%\graphicspath{ {Directory/} }
    %   Set a directory for where to look for figures


%% Hyperlinks %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{hyperref}
\hypersetup{%
    colorlinks,
        %   This colors the links themselves, not boxes
    citecolor=black,
        %   Everything here and below changes link colors
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

%% Colors %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{color}
\definecolor{codegreen}{RGB}{28,172,0}
\definecolor{codelilas}{RGB}{170,55,241}

% David4 color scheme
\definecolor{d4blue}{RGB}{100,191,255}
\definecolor{d4gray}{RGB}{175,175,175}
\definecolor{d4black}{RGB}{85,85,85}
\definecolor{d4orange}{RGB}{255,150,100}

%% Including Code %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{verbatim}
    %   For including verbatim code from files, no colors
\usepackage{listings}
    %   For including code snippets written directly in this doc

\lstdefinestyle{bash}{%
  language=bash,%
  basicstyle=\footnotesize\ttfamily,%
  showstringspaces=false,%
  commentstyle=\color{gray},%
  keywordstyle=\color{blue},%
  xleftmargin=0.25in,%
  xrightmargin=0.25in
}
\lstdefinestyle{log}{%
  basicstyle=\scriptsize\ttfamily,%
  showstringspaces=false,%
  xleftmargin=0.25in,%
  xrightmargin=0.25in
}


\lstdefinestyle{matlab}{%
  language=Matlab,%
  basicstyle=\footnotesize\ttfamily,%
  breaklines=true,%
  morekeywords={matlab2tikz},%
  keywordstyle=\color{blue},%
  morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},%
  identifierstyle=\color{black},%
  stringstyle=\color{codelilas},%
  commentstyle=\color{codegreen},%
  showstringspaces=false,%
    %   Without this there will be a symbol in
    %   the places where there is a space
  %numbers=left,%
  %numberstyle={\tiny \color{black}},%
    %   Size of the numbers
  numbersep=9pt,%
    %   Defines how far the numbers are from the text
  emph=[1]{for,end,break,switch,case},emphstyle=[1]\color{blue},%
    %   Some words to emphasise
}

\newcommand{\matlabcode}[1]{%
    \lstset{style=matlab}%
    \lstinputlisting{#1}
}
    %   For including Matlab code from .m file with colors,
    %   line numbering, etc.

\lstdefinelanguage{Julia}%
  {morekeywords={abstract,break,case,catch,const,continue,do,else,elseif,%
      end,export,false,for,function,immutable,import,importall,if,in,%
      macro,module,otherwise,quote,return,switch,true,try,type,typealias,%
      using,while},%
   sensitive=true,%
   %alsoother={$},%
   morecomment=[l]\#,%
   morecomment=[n]{\#=}{=\#},%
   morestring=[s]{"}{"},%
   morestring=[m]{'}{'},%
}[keywords,comments,strings]

\lstdefinestyle{julia}{%
    language         = Julia,
    basicstyle       = \scriptsize\ttfamily,
    keywordstyle     = \bfseries\color{blue},
    stringstyle      = \color{codegreen},
    commentstyle     = \color{codegreen},
    showstringspaces = false,
    literate         = %
      {ρ}{{$\rho$}}1
      {ℓ}{{$\ell$}}1
      {∑}{{$\Sigma$}}1
      {Σ}{{$\Sigma$}}1
      {√}{{$\sqrt{}$}}1
      {θ}{{$\theta$}}1
      {ω}{{$\omega$}}1
      {ɛ}{{$\varepsilon$}}1
      {φ}{{$\varphi$}}1
      {σ²}{{$\sigma^2$}}1
      {Φ}{{$\Phi$}}1
      {ϕ}{{$\phi$}}1
      {Dₑ}{{$D_e$}}1
      {Σ}{{$\Sigma$}}1
      {γ}{{$\gamma$}}1
      {δ}{{$\delta$}}1
      {τ}{{$\tau$}}1
      {μ}{{$\mu$}}1
      {β}{{$\beta$}}1
      {Λ}{{$\Lambda$}}1
      {λ}{{$\lambda$}}1
      {r̃}{{$\tilde{\text{r}}$}}1
      {α}{{$\alpha$}}1
      {σ}{{$\sigma$}}1
      {π}{{$\pi$}}1
      {∈}{{$\in$}}1
      {∞}{{$\infty$}}1
}


%% Bibliographies %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage{natbib}
    %---For bibliographies
%\setlength{\bibsep}{3pt} % Set how far apart bibentries are

%% Misc %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{enumitem}
    %   Has to do with enumeration
\usepackage{appendix}
%\usepackage{natbib}
    %   For bibliographies
\usepackage{pdfpages}
    %   For including whole pdf pages as a page in doc
\usepackage{pgffor}
    %   For easier looping


%% User Defined %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newcommand{\nameofcmd}{Text to display}
\newcommand*{\Chi}{\mbox{\large$\chi$}} %big chi
    %   Bigger Chi

% In math mode, Use this instead of \munderbar, since that changes the
% font from math to regular
\makeatletter
\def\munderbar#1{\underline{\sbox\tw@{$#1$}\dp\tw@\z@\box\tw@}}
\makeatother

% Misc Math
\newcommand{\ra}{\rightarrow}
\newcommand{\diag}{\text{diag}}
\newcommand{\ch}{\text{ch}}
\newcommand{\dom}{\text{dom}}
\newcommand{\one}[1]{\mathbf{1}_{#1}}


% Command to generate new math commands:
% - Suppose you want to refer to \boldsymbol{x} as just \bsx, where 'x'
%   is any letter. This commands lets you generate \bsa, \bsb, etc.
%   without copy pasting \newcommand{\bsa}{\boldsymbol{a}} for each
%   letter individually. Instead, just include
%
%     \generate{bs}{\boldsymbol}{a,...,z}
%
% - Uses pgffor package to loop
% - Example with optional argument. Will generate \bshatx to represent
%   \boldsymbol{\hat{x}} for all letters x
%
%     \generate[\hat]{bshat}{\boldsymbol}{a,...,z}

\newcommand{\generate}[4][]{%
  % Takes 3 arguments (maybe four):
  % - 1   wrapcmd (optional, defaults to nothing)
  % - 2   newname
  % - 3   mathmacro
  % - 4   Names to loop over
  %
  % Will produce
  %
  %   \newcommand{\newnameX}{mathmacro{wrapcmd{X}}}
  %
  % for each X in argument 4

  \foreach \x in {#4}{%
    \expandafter\xdef\csname%
      #2\x%
    \endcsname%
    {\noexpand\ensuremath{\noexpand#3{\noexpand#1{\x}}}}
  }
}


% MATHSCR: Gen \sX to stand for \mathscr{X} for all upper case letters
\generate{s}{\mathscr}{A,...,Z}


% BOLDSYMBOL: Generate \bsX to stand for \boldsymbol{X}, all upper and
% lower case.
%
% Letters and greek letters
\generate{bs}{\boldsymbol}{a,...,z}
\generate{bs}{\boldsymbol}{A,...,Z}
\newcommand{\bstheta}{\boldsymbol{\theta}}
\newcommand{\bsmu}{\boldsymbol{\mu}}
\newcommand{\bsSigma}{\boldsymbol{\Sigma}}
\newcommand{\bsvarepsilon}{\boldsymbol{\varepsilon}}
\newcommand{\bsalpha}{\boldsymbol{\alpha}}
\newcommand{\bsbeta}{\boldsymbol{\beta}}
\newcommand{\bsOmega}{\boldsymbol{\Omega}}
\newcommand{\bshatOmega}{\boldsymbol{\hat{\Omega}}}
\newcommand{\bshatG}{\boldsymbol{\hat{G}}}
\newcommand{\bsgamma}{\boldsymbol{\gamma}}
\newcommand{\bslambda}{\boldsymbol{\lambda}}

% Special cases like \bshatb for \boldsymbol{\hat{b}}
\generate[\hat]{bshat}{\boldsymbol}{b,y,x,X,V,S,W}
\newcommand{\bshatbeta}{\boldsymbol{\hat{\beta}}}
\newcommand{\bshatmu}{\boldsymbol{\hat{\mu}}}
\newcommand{\bshattheta}{\boldsymbol{\hat{\theta}}}
\newcommand{\bshatSigma}{\boldsymbol{\hat{\Sigma}}}
\newcommand{\bstildebeta}{\boldsymbol{\tilde{\beta}}}
\newcommand{\bstildetheta}{\boldsymbol{\tilde{\theta}}}
\newcommand{\bsbarbeta}{\boldsymbol{\overline{\beta}}}
\newcommand{\bsbarg}{\boldsymbol{\overline{g}}}

% Redefine \bso to be the zero vector
\renewcommand{\bso}{\boldsymbol{0}}

% Transposes of all the boldsymbol shit
\newcommand{\bsbp}{\boldsymbol{b'}}
\newcommand{\bshatbp}{\boldsymbol{\hat{b'}}}
\newcommand{\bsdp}{\boldsymbol{d'}}
\newcommand{\bsgp}{\boldsymbol{g'}}
\newcommand{\bsGp}{\boldsymbol{G'}}
\newcommand{\bshp}{\boldsymbol{h'}}
\newcommand{\bsSp}{\boldsymbol{S'}}
\newcommand{\bsup}{\boldsymbol{u'}}
\newcommand{\bsxp}{\boldsymbol{x'}}
\newcommand{\bsyp}{\boldsymbol{y'}}
\newcommand{\bsthetap}{\boldsymbol{\theta'}}
\newcommand{\bsmup}{\boldsymbol{\mu'}}
\newcommand{\bsSigmap}{\boldsymbol{\Sigma'}}
\newcommand{\bshatmup}{\boldsymbol{\hat{\mu'}}}
\newcommand{\bshatSigmap}{\boldsymbol{\hat{\Sigma'}}}

% MATHCAL: Gen \calX to stand for \mathcal{X}, all upper case
\generate{cal}{\mathcal}{A,...,Z}

% MATHBB: Gen \X to stand for \mathbb{X} for some upper case
\generate{}{\mathbb}{R,Q,C,Z,N,Z,E}
\newcommand{\Rn}{\mathbb{R}^n}
\newcommand{\RN}{\mathbb{R}^N}
\newcommand{\Rk}{\mathbb{R}^k}
\newcommand{\RK}{\mathbb{R}^K}
\newcommand{\RL}{\mathbb{R}^L}
\newcommand{\Rl}{\mathbb{R}^\ell}
\newcommand{\Rm}{\mathbb{R}^m}
\newcommand{\Rnn}{\mathbb{R}^{n\times n}}
\newcommand{\Rmn}{\mathbb{R}^{m\times n}}
\newcommand{\Rnm}{\mathbb{R}^{n\times m}}
\newcommand{\Rkn}{\mathbb{R}^{k\times n}}
\newcommand{\Cn}{\mathbb{C}^n}
\newcommand{\Cnn}{\mathbb{C}^{n\times n}}

% Dot over
\newcommand{\dx}{\dot{x}}
\newcommand{\ddx}{\ddot{x}}
\newcommand{\dy}{\dot{y}}
\newcommand{\ddy}{\ddot{y}}

% First derivatives
\newcommand{\dydx}{\frac{dy}{dx}}
\newcommand{\dfdx}{\frac{df}{dx}}
\newcommand{\dfdy}{\frac{df}{dy}}
\newcommand{\dfdz}{\frac{df}{dz}}

% Second derivatives
\newcommand{\ddyddx}{\frac{d^2y}{dx^2}}
\newcommand{\ddydxdy}{\frac{d^2y}{dx dy}}
\newcommand{\ddydydx}{\frac{d^2y}{dy dx}}
\newcommand{\ddfddx}{\frac{d^2f}{dx^2}}
\newcommand{\ddfddy}{\frac{d^2f}{dy^2}}
\newcommand{\ddfddz}{\frac{d^2f}{dz^2}}
\newcommand{\ddfdxdy}{\frac{d^2f}{dx dy}}
\newcommand{\ddfdydx}{\frac{d^2f}{dy dx}}


% First Partial Derivatives
\newcommand{\pypx}{\frac{\partial y}{\partial x}}
\newcommand{\pfpx}{\frac{\partial f}{\partial x}}
\newcommand{\pfpy}{\frac{\partial f}{\partial y}}
\newcommand{\pfpz}{\frac{\partial f}{\partial z}}


% argmin and argmax
\DeclareMathOperator*{\argmin}{arg\;min}
\DeclareMathOperator*{\argmax}{arg\;max}


% Various probability and statistics commands
\newcommand{\iid}{\overset{iid}{\sim}}
\newcommand{\med}{\operatorname{med}}
\newcommand{\vc}{\operatorname{vec}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\Cov}{\operatorname{Cov}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\trace}{\operatorname{tr}}
\newcommand{\Corr}{\operatorname{Corr}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\asto}{\xrightarrow{a.s.}}
\newcommand{\pto}{\xrightarrow{P}}
\newcommand{\uto}{\xrightarrow{u}}
\newcommand{\msto}{\xrightarrow{m.s.}}
\newcommand{\dto}{\xrightarrow{d}}
\newcommand{\Lpto}{\xrightarrow{L_p}}
\newcommand{\Lqto}[1]{\xrightarrow{L_{#1}}}
\newcommand{\plim}{\text{plim}_{n\rightarrow\infty}}


% Redefine real and imaginary from fraktur to plain text
\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}

% Shorter sums: ``Sum from X to Y''
% - sumXY  is equivalent to \sum^Y_{X=1}
% - sumXYz is equivalent to \sum^Y_{X=0}
\newcommand{\sumnN}{\sum^N_{n=1}}
\newcommand{\sumin}{\sum^n_{i=1}}
\newcommand{\sumjn}{\sum^n_{j=1}}
\newcommand{\sumim}{\sum^m_{i=1}}
\newcommand{\sumik}{\sum^k_{i=1}}
\newcommand{\sumiN}{\sum^N_{i=1}}
\newcommand{\sumkn}{\sum^n_{k=1}}
\newcommand{\sumtT}{\sum^T_{t=1}}
\newcommand{\sumninf}{\sum^\infty_{n=1}}
\newcommand{\sumtinf}{\sum^\infty_{t=1}}
\newcommand{\sumnNz}{\sum^N_{n=0}}
\newcommand{\suminz}{\sum^n_{i=0}}
\newcommand{\sumknz}{\sum^n_{k=0}}
\newcommand{\sumtTz}{\sum^T_{t=0}}
\newcommand{\sumninfz}{\sum^\infty_{n=0}}
\newcommand{\sumtinfz}{\sum^\infty_{t=0}}

\newcommand{\prodnN}{\prod^N_{n=1}}
\newcommand{\prodin}{\prod^n_{i=1}}
\newcommand{\prodiN}{\prod^N_{i=1}}
\newcommand{\prodkn}{\prod^n_{k=1}}
\newcommand{\prodtT}{\prod^T_{t=1}}
\newcommand{\prodnNz}{\prod^N_{n=0}}
\newcommand{\prodinz}{\prod^n_{i=0}}
\newcommand{\prodknz}{\prod^n_{k=0}}
\newcommand{\prodtTz}{\prod^T_{t=0}}

% Bounds
\newcommand{\atob}{_a^b}
\newcommand{\ztoinf}{_0^\infty}
\newcommand{\kinf}{_{k=1}^\infty}
\newcommand{\ninf}{_{n=1}^\infty}
\newcommand{\minf}{_{m=1}^\infty}
\newcommand{\tinf}{_{t=1}^\infty}
\newcommand{\nN}{_{n=1}^N}
\newcommand{\tT}{_{t=1}^T}
\newcommand{\kinfz}{_{k=0}^\infty}
\newcommand{\ninfz}{_{n=0}^\infty}
\newcommand{\minfz}{_{m=0}^\infty}
\newcommand{\tinfz}{_{t=0}^\infty}
\newcommand{\nNz}{_{n=0}^N}

% Limits
\newcommand{\limN}{\lim_{N\rightarrow\infty}}
\newcommand{\limn}{\lim_{n\rightarrow\infty}}
\newcommand{\limk}{\lim_{k\rightarrow\infty}}
\newcommand{\limt}{\lim_{t\rightarrow\infty}}
\newcommand{\limT}{\lim_{T\rightarrow\infty}}
\newcommand{\limhz}{\lim_{h\rightarrow 0}}

% Shorter integrals: ``Integral from X to Y''
% - intXY is equivalent to \int^Y_X
\newcommand{\intab}{\int_a^b}
\newcommand{\intzN}{\int_0^N}

% Check and x symbols
\usepackage{pifont}
\newcommand{\cmark}{\text{\ding{51}}}
\newcommand{\xmark}{\text{\ding{55}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BODY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}
\maketitle

\tableofcontents


\clearpage
\section{Causality and Exogeneity}

Model
\begin{align*}
  y_n
  = \bsx_n'\bsbeta + \varepsilon_t
\end{align*}
Note that $\bsx_n$ could potentially contained lagged $y_n$. But that
limits whether or not a particular assumption is reasonable for time
series.
\begin{table}[htbp!]
\centering
\begin{tabular}{c|lcccc}
    &
    & Implies
    & Justifies
    & Consistency \&
    & Reasonable for
  \\
  $\bsx_t$ is\dots
    & Defining Feature
    & $\E[\varepsilon_t\varepsilon_{s}]=0$
    & GLS
    & Asymptotic $\calN$
    & Time Series
  \\\hline\hline
  Strictly Exogenous
    & $0=\E[\varepsilon_t|\{\bsx_s\}_{s=-\infty}^\infty]$
    & \xmark
    & \cmark
    & \cmark
    & \xmark
  \\
  Predetermined
    %& $0=\E[\varepsilon_t|\{\bsx_s,y_{s-1}\}_{s=-\infty}^t]$
    & $0=\E[\varepsilon_t|\{\bsx_s\}_{s=-\infty}^t]$
    & \cmark
    & \xmark
    & \cmark
    & \cmark
  \\
  Weaker Predetermined
    & $0=\E[\varepsilon_t\bsx_t]$
    & \xmark
    & \xmark
    & \cmark
    & \cmark
\end{tabular}
\end{table}

Weaker predetermined is used in Hayashi.

Strict exogeneity Generally impossible when $\bsx_n$ has lagged $y_n$ in
it.  Hence, generally not imposed in models with AR structure.
Mostly imposed when $y_n$ and $\bsx_n$ completely distinct

Predetermined and exogeneity are different. One does not imply the
other.
But if already assumping absence of serial correlation, then strict
exogeneity is stronger and does imply predetermined.
But no need to assume that for strict exogeneity.


\clearpage
\section{Market Demand Models}

\begin{comment}
Demand for differentiated products
==================================
- Why we care about the demand system
  - Measuring market power of sellers
  - Measuring welfare
  - Understanding price effects of mergers
  - Understanding which new prices might enter the market
  - Understand how new products affect prices, welfare

- Supply Side
  - We care about this bc we almost always assume that *prices* we
    observe are the outcome of a nash equilibrium in prices (Bertrand
    game)
  - Each firm maximizes profits by setting price, taking as given
    - Demand curve for its products (as a fcn of price)
    - Cost function for producing a certain quantity
  - The FOC imply a pricing function that says

      price = f(mc, markup)

    where markups are related to demand elasticities.
  - Thus given an estimated demand system (i.e. estimated elasticities)
    we can invert the pricing function to recover marginal costs
  - Of course, to estimate the demand system, we need IVs (typically
    cost-shifters) to estimate the system (i.e. price elasticities).
    That's the tough part
  * Note: elasticities depend upon prices. Typically not a problem for
    estimation, but is a problem for counterfactuals

- Demand Side
  - Product Space vs. Char Space (Lancaster 1966, McFadden 1973).
    - Benefits vs. drawbacks
  - Product space: estimate aggregate q(p,y)
    - Models include
      - Linear Expenditure (Stong, 1954): Building block
      - Rotterdam (Theil 1965, Barten 1966)
      - Translog (Christensen, Jorgensen, Lau 1975)
      - AIDS (Deaton and Muellbauer, 1980)
    - Problems/difficulties
      - High dimension with many products
      - Too often, instruments do not vary enough at product level and
        are highly colinear
      - Estimate of *aggregate* demand in rep agent framework, so
        ignores consumer heterogeneity
    - How to solve these problems:
      - Aggregate products into groups and different levels,
        solves dimensionality
      - Symmetry assumption for products: Dixit Stiglitz CES, so only
        one parameter to estimate (but super counterfactual)
      - Logit demand: Good for questions that deal with the optimal
        number of products or optimal variety
    - AIDS specifics
      - Divide product into subgroups, allow flexibility w/in subgroups
      - Key assumptions to justify theoretically this practical approach
        to demand estimation
        - Preference separability: U(q) = f(u1(q(1)),...,un(q(n)))
        - Multi-stage budgeting: Consumers allocated total expenditure
          in stages to different subgroups
      - Sufficient conditions for those two assumptions
        - Indirect utility for *each* segment of generalized Gorman
          Polar Form:

              v_i(p,y_i) = (y_i - f_i(p)) / g(p)

          v_i: indirect utility for agent i given prices p, income y_i.
          f_i: Expenditure necessary to reach utility level
          g(): Price index that is the same for all i
        - Overall utility *additively separable* in sub-utilities
        - For any level, estimate demand for product i in segment g

            wi = ai + bi*log(yg/Pg) + sum_j gamij log(pj) + ei

          wi: Within segment g expenditure share on product i
          yg: Total expenditure on segment g
          Pg: price index for segment g
          pj: Price for product j
        - Price indices
          - Stone log price index: Pg = sum_j wj log(pj)
          - Deaton and Muellbauer exact price index

            Pg = a0 + sum_j aj pj + (1/2)sumj sumk gamjk*log(pj)*log(pk)

    - Hausman Example
      - Stages: Whole market, market segments, individ products
      - Bottom level: AIDS
      - Middle level: AIDS or log-log

          log qg = ag + bg log(y) + sum delgh log(Ph) + eg

        Neither fully consistent with theory
      - Highest level: log-log

          log q = a + b log(y) + del log(P) + Z*gam + e
      - Note: No corner solutions--each consumer buys some of each good
      - Need to classify some products beforehand
    - Hausman, Leonard, Zona (1994)
      - Beer Market
        - Upper level: Light, premium, popular pirce
        - Lower level: Five brands within each segments
      - Idea: There is some underlying pricing model like

          log p_jct = a_jc + log c_jt + om_jct

        a_jc: Product-city FE (city's preference for a brand)
        c_jt: Product-time cost shifter (constant *across cities*)
        om_jct: Absorb supply and demand shocks

        *Exploit variation in *price of same brand*, *across cities*
        *Note: because c_jt fixed across cities, any variation that is
          common across cities will mechanically be attributed to
          supply/c_jt---NOT demand through om_jct.
          Bad assumption if national add campaign?
\end{comment}

\begin{comment}
  - Characteristic space: Products are bundles of chars
    - Theory:
      - Price competition, taking products as given
      - Comp in product space with or without subsequent price comp
    - Empirics: Only do the former, latter Sweeting ECMA 2013 new
    - Common instrument: Product characteristics
      - inefficient
      - Probably inconsistent
    - Common approach:
      - Heterogeneous individuals
      - Discrete choice (i.e. choose one product)
      - Aggregate up, so diemand depends on distribution of
        heterogeneous attributes
    - Theory Model undergirding Discrete-Choice Models
      - J products in a market, agent chooses one or outside good

          max_j,z U_i(x_j,z)  s.t. y_i = p_j + p_z*z

        x_j: characteristics of j
        p_j: price
        y_i: income
        z:   Quantity of outside good
      - Use budget constraint to write choice of z out of problem,
        writing as max over conditional indirect utility function

          max_j U_ij = max_j U_i(x_j, (y_i-p_j)/p_z)
      - Agent chooses j to maximize this utility, i.e. takes whichever j
        maximizes U_ij. Thus we can lay down a model for U_ij directly

    - Metrics:
      - Conditional Indirect Utility: U_ij = U(X_j, p_j, v_ij; theta)
      - Then augment with error unobserved by econometrician

          U_ij* = U_ij + e

        Distribution of e determines consumer i's choice probs, i.e.
        consumer i's demand function
      - Examples:
        - Two goods: j=0,1,2

            U_ij = delj + e_ij      U_i0 = 0

        - Hotelling: Pure horizontal

            U_ij = ubar + (y_i-p_j) - theta d^2(x_j,v_i)

        - Pure Vertical

            U_ij = del_j - vi*pj      vi > 0

          For all products bought in positive quantities, ordering by
          price p_j *same* as ordering by quality del_j.

          Higher price -> higher quality del_j

          So wlog, sort products by price/quality

          Agent chooses product j iff

            del_j - v_i * p_j > del_j+1 - v_i * p_j+1
            del_j - v_i * p_j > del_j-1 - v_i * p_j-1

          Can solve to get that that i chooses j iff

            (del_j+1 - del_j)/(p_j+1-p_j) < v_i < (del_j - del_j-1)/(p_j-p_j-1)

          Hence cutoff points for elasticities determine which products
          chosen. Given a distribution for v_i, can use that CDF to
          compute market share

          ***Model implication: Cross-price elasticities for product j
          are ZERO, except for the neighboring j-1 and j+1 products


        - Logit:

            U_ij = ubar + (y_i-p_j) + delta_j + e_ij

          where del_j = f(x_j, p_j, xi_j)


      - Generally, two main classes: depending on whether there is an
        epsilon or not.

        Matters because with eps_ij, product space *never* exhausted.
        Each new product comes with a new set of eps_ij that, for large
        enough sample, allow the product to deliver high utility for
        *someone* so that the person chooses it, guaranteeing the
        product positive market share and some market power

        The two classes:
        - Sans eps: For f_y>0, f_p<0, f_yp >= 0
          - Pure Hedonic (Berry and Pakes 2007):

              U_ij = f(y_i,p_j) + del_j + sum_k b_k * x_jk * v_ik

          - Ideal Type (Anderson, de Palma, Thisse 1992)

              U_ij = f(y_i,p_j) + del_j + sum_k a_k (x_jk - v_ik)^2

        - Cum eps (BLP 1995): Used to reconcile the model with the data.
          Without, often no way to fit everything. Like sticking in an
          error term in OLS even when we think relationship is linear

            U_ij = f(y_i,p_j) + del_j + sum_k b_k * x_jk * v_ik + eps_ij

          which retains logit as a special case

        Instruments: Assume X *exogenous* so use
        - Cost shifters
        - Functions of X likely to be correlated with markups

    - Logit model: U_ij = del_j + eps_ij where del_j = f(x_j,p_j,xi_j)
      - Analytic expression in terms of del_j terms
      - Further restriction: McFadden
        - del_j = x_j*b - a*p_j + xi_j
        - Then can rearrange market share equation to get linear form

            del_j = log(s_j) - log(s_0)
                  = x_j*b - a*p_j + xi_j

          which is a useful linear form
        - Can use FE to get rid of xi_j
        - Can instrument for prices using standard IV procedures
      - Problems: own and cross price elasticities
        - Own-price: Increasing in absolute value, but really people who
          buy more expensive products probably *less* sensitive to price
        - Cross-price: Depends only on market shares and prices, NOT
          similarities between goods. IIA?
        *All of function of the lack of heterogeneity
      - xi_j introduces potential endogeneity of prices.
        Often assume E[xi_j|X]=0 and built instruments from that.
        But maybe problematic

    - Nested Logit model: Relaxes IIA by grouping products
      - Model given by

          U_ij = del_j + zeta_{ig}(sig) + (1-sig)*eps_ij

        where zeta_ig(sig) common to all products in nest g.
        As sig -> 0, standard logit
        As sig -> 1, only nests matter

      - Assume that zeta_ig(sigma) ~ s.t. entire term

          zeta_{ig}(sig) + (1-sig)*eps_ij

        is EV so we get back standard logit formulas

      - Example nesting: Outside good in one nest, rest in other nest.
        Yields linear equation

          log(s_j) - log(s_0) = x_j*b - a*p_j + sig*log(s_{j/g}) + xi_j

        Instrument for prices and s_{j/g}

    - BLP, aka Random Coefficients, Mixed Logit, Heterogeneous Logit
      - Generalizes logit model from b to bi

          U_ij = ( x_j*b_i - a*p_j + xi_j ) + eps_ij
          b_i  = b + Sigma*v_i

        so then

          U_ij    = delta_j + v_ij
          delta_j = x_j*b - a*p_j + xi_j      Mean utility for brand j
          v_ij    = x_j Sigma v_i + eps_ij

        xi_j and eps_ij not observed by econometrician, only consumer.
        Former probably correlated with price p_j, maybe char X_j

        So like logit, but residual term v_ij *no longer* iid, so
        consumers who like one product more likely to like similar
        products

      - Need to be able to invert and write del(s), i.e. del as a
        function of shares, rather than just s(del) (shares as a
        function of delta). Can then write GMM moment conditions

        In earlier models, done analytically. In BLP, must do
        numerically, conditional on nonlinear model params, i.e. Sigma.
        Given that, can spec moment conds. But also need moment conds to
        identify Sigma params too

        Also need to simulate shares

      - Two step estimator:
        - GMM objective function is
        - Inverson to Recover Deltas: Given observed shares and guesses
          for del and Sigma, can set up system of J+1 eqs in the dels

            s_j = s_j(del0, ..., del_J)

          where LHS is data and RHS is simulated from model, given Sigma
          and taking draws of v_i

        - Assume instrument Z s.t. E[xi*Z] = 0 where xi = del-X*b-a*p
          under *true* params a,b
        - Construct sample version of that moment
        - Estimate a,b by minning that sample criterion function
        - BUT, that depends on delta which we don't know -> TWO STEPS
        - Invert this system to get the dels, which can be used to calc
          the above sample criterion function

      - Algo
        - Fix theta2
        - Kick around delta until shares equated
        - Given delta, compute xi
        - Given xi, form GMM objective function, which depends on whole
          vector theta
        - Kick around theta untily you minimize the objective function

      - Suppose we had s^{-1}, the inverse shares which returns delta as
        a function of theta2. Ignore the fact that we need to compute
        the deltas numerically; just assume we have an analytical
        expression. Algo steps
        - Form xi = s^{-1}-x*b - a*p
        - Find instruments for xi
        - Write GMM objective function
\end{comment}


\begin{prop}
\emph{(Motivation: Consumer Optimization)}
Want to get to the indirect utility functions (over characteristics)
that we use for estimation, from a basic utility maximization over
quantities of the goods consumed, subject to some BC.
\end{prop}


\begin{prop}
Start with general consumer preferences given by continuous utility
function
\begin{align*}
  U(Q_0,Q_t)
  \qquad\text{where}\quad
  \begin{cases}
    Q_0 & \text{Amount of numeraire consumed} \\
    Q_t &
    \text{Amount of inside good consumed---one of the $J$ options}
    \\
  \end{cases}
\end{align*}
Let $f$ be a function such that $f'>0>f''$ and
\begin{align*}
    f(Q_t) = x_{jt}\beta_i + \xi_{jt} + \varepsilon_{ijt}
\end{align*}
Special cases:
\begin{itemize}
  \item Quasilinear, $U(Q_0,Q_t)=f(Q_t)+Q_0$:
    (conditional) indirect utility is then
    \begin{align*}
      u_{ijt}
      = \alpha_i (I_i-p_{jt}) + x_{jt}\beta_i + \xi_{jt} +
      \varepsilon_{ijt}
    \end{align*}
  \item Cobb-Douglass, $U(Q_0,Q_t)=Q_0^\alpha f(Q_t)^{1-\alpha}$
    (conditional) indirect utility is then
    \begin{align*}
      u_{ijt}
      = \alpha \ln(I_i-p_{jt}) + x_{jt}\beta_i + \xi_{jt} +
      \varepsilon_{ijt}
    \end{align*}
\end{itemize}
From latter case, we see why the argument to indirect utility is
$I_i-p_{jt}$ rather than $p_{jt}$ alone.
\end{prop}


\clearpage
\begin{defn}
(General Discrete Choice Model in Characteristics Space)
Products are bundles of characteristics, and agents in any given market
choose a single product.
The ultimate choice is determined by the indirect utility function,
denoted most generally by
\begin{align*}
  u_{ijt}
  =
  U(x_{jt},\xi_{jt},I_i-p_{jt},D_{it},v_{it};\theta)
  + \varepsilon_{ijt}
\end{align*}
where
\begin{itemize}
  \item $u_{ijt}$:
    Utility for individual $i$ when choosing product $j$
    in market $t$
  \item $x_{jt}$: Observed product characteristics
  \item $\xi_{jt}$: Unobserved product characteristics.
    Worry about correlation with price.
    Acts as a residual, soaking up everything about the product we
    don't/can't explain by characteristics and can be used to reduce the
    dimension when many characteristics.
  \item $I_i-p_{jt}$: Income less price. It's this difference that
    matter, which is why write $I_i-p_{jt}$ as the argument, rather than
    $I_i$ and $p_{jt}$ separately. Only in particular special cases can
    we separate things out (like the quasilinear case below); in others,
    not.
  \item $D_{it}$: Observed consumer attributes (like demographics).
    Often have the distribution from something like CPS
  \item $v_{it}$: Unobserved consumer attributes.
    Often assume particular distribution like normal.
  \item $\varepsilon_{ijt}$: iid error term that reflects the
    econometrician's ignorance, i.e. imperfect specification and
    observation of
    $U(x_{jt},\xi_{jt},I_i-p_{jt},D_{it},v_{it};\theta)$,
    which forces us to put an error term $\varepsilon_{ijt}$ into the
    model to plug the gap between model and data.
\end{itemize}
Thus model-predicted market share of produt $j$ in market $t$ is given
$\theta$ is
\begin{align*}
  \sigma_{jt}(\theta)
  &=
  \E_{D_{it},v_{it},\varepsilon_{ijt}}
  \big[
    \mathbf{1}\{u_{ijt}>u_{ikt}\;\text{for all other $k$}\}
  \big]
\end{align*}
A market is defined as that grouping such that, within $jt$, the terms
$(x_{jt},p_{jt},\xi_{jt})$ don't vary.
Those are allowed to vary only \emph{across} markets, by assumption.
\end{defn}





\begin{defn}
(Special Case: Random Coefficient, a.k.a.\ Mixed Logit, a.k.a.\ BLP
Model)
This is a particular specification of the indirect utility function.
\begin{align*}
  u_{ijt}
  &= x_{jt}\beta_i + \alpha_ip_{jt} + \xi_{jt} + \varepsilon_{ijt} \\
  \qquad\text{where}\quad
  \begin{pmatrix}
    \alpha_i \\ \beta_i
  \end{pmatrix}
  &=
  \begin{pmatrix}
    \alpha \\ \beta
  \end{pmatrix}
  + \Pi D_{it} + \Sigma v_{it}
\end{align*}
Can rewrite in terms of mean indirect utility $\delta_{ijt}$ with
market-specific $\delta_{jt}$ and person-specific deviation from that
mean utility $\mu_{ijt}$ (plus error due to the econometrician's
ignorance):
\begin{align*}
  u_{ijt} &=
  \underbrace{%
    x_{jt}\beta + \alpha p_{jt} +\xi_{jt}
  }_{\delta_{jt}=\delta(x_{jt},p_{jt},\xi_{jt};\theta_1)}
  +
  \underbrace{%
      \begin{pmatrix}
        p_{jt} & x_{jt}
      \end{pmatrix}
      \begin{pmatrix}
        \Pi D_{it} + \Sigma v_{it}
      \end{pmatrix}
  }_{\mu_{ijt}=\mu(x_{jt},p_{jt},D_{ii},v_{it};\theta_2)}
  +\varepsilon_{ijt}
\end{align*}
The key difference relative to the logit model is the introduction of
nonzero $\mu_{ijt}$, which captures the \emph{interaction} of
characteristics and consumer attributes (including observed demographics
$D_{it}$ and unobserved attributes $v_{it}$).
In the logit model, $\mu_{ijt}=0$ by assumption.

The tough part, when we have market-level data only (not
consumer-level), is estimation of $\theta_2=(\Pi,\Sigma)$---the
parameters governing hterogeneity---since we don't observe individual
choices \emph{within} $jt$.
However, we can still estimate/identify $\theta_2$ because we observe
different markets $t$, and those markets have different distributions
of consumer attributes.
That variation in the distribution of consumer attributes across markets
helps us identify $\theta_2$.

With consumer-level data, we have multiple observations with $\xi_{jt}$
held fixed and use the variation we see in demographics across people.
With market-level data, no such luck.
\emph{But}, we do see different markets with different distributions of
characteristics, although the $\xi_{jt}$ are \emph{also} changing across
these markets.
\end{defn}


\begin{comment}
\begin{defn}
(Special Case: Linear Mixed Logit Model, EVI Errors, No Unobserved
Consumer Heterogeneity)
In that case
\begin{align*}
  P[y_{it}=j|D_{it},x_t,p_t,\xi_t;\theta]
  &=
  P[y_{it}=j|D_{it},x_t,p_t,\xi_t;\theta]
\end{align*}
\end{defn}



\paragraph{Estimation with Consumer-Level Data}
For simplicity, suppose that $\Sigma=0$ so that we have model
\begin{align*}
  u_{ijt} &=
  \underbrace{%
    x_{jt}\beta + \alpha p_{jt} +\xi_{jt}
  }_{\delta_{jt}=\delta(x_{jt},p_{jt},\xi_{jt};\theta_1)}
  +
  \underbrace{%
      \begin{pmatrix}
        p_{jt} & x_{jt}
      \end{pmatrix}
      \begin{pmatrix}
        \Pi D_{it}
      \end{pmatrix}
  }_{\mu_{ijt}=\mu(x_{jt},p_{jt},D_{it},v_{it};\theta_2)}
  +\varepsilon_{ijt}
\end{align*}
Further suppose that $\varepsilon_{ijt}$ are EV Type I distributed.
Can then estimate in two steps:
\begin{enumerate}
  \item By assuming that $\varepsilon_{ijt}$ are EV Type I distributed,
    \begin{align*}
      P[y_{it}=j|D_{it},x_t,p_t,\xi_t;\theta]
      &=
      P[y_{it}=j|D_{it},,x_t,p_t,\delta_{jt};\theta]
      \\
      &=
      \frac{%
        \exp\big\{
          \delta_{jt}+
          (p_{jt} \; x_{jt})
          \Pi D_{it}
        \big\}
      }{%
        1+
        \sum_{k=1}^J
        \exp\big\{
          \delta_{kt}+
          (p_{kt} \; x_{kt})
          \Pi D_{it}
        \big\}
      }
    \end{align*}
    From this, we can estimate $\delta_{jt}$ terms and $\Pi$.

    \paragraph{$\Pi$ Identification}
    Parameter $\Pi$ is identified via variation in $D_{it}$ holding
    $\delta_{jt}$ fixed. In other words, variation in
    demographics/characteristics \emph{holding fixed} product-market
    attributes.

    \paragraph{$\Sigma$ Identification}
    In the more complex case with $\Sigma\neq 0$, that matrix is
    identified from within market share variation in choice
    probabilities, i.e. holding market share fixed?


  \item
    We know that
    \begin{align*}
      \delta_{jt}=x_{jt}\beta + \alpha p_{jt}+\xi_{jt}
    \end{align*}
    So given $\delta_{jt}$ estimates from step 1, recover $\beta$ and
    $\alpha$.

    Note: since we expect $p_{jt}$ and $\xi_{jt}$ to be correlated, need
    an IV for prices or an assumption about the panel/autocorrelation
    structure of $\xi_{jt}$ for identification/estimation.

    \paragraph{$\theta_1$ Identification}
    This is identified from variation across markets
\end{enumerate}
\end{comment}


\clearpage
\paragraph{Estimation with Market-Level Data}
Recall our starting point:
\begin{align*}
  u_{ijt} &=
  \underbrace{%
    x_{jt}\beta + \alpha p_{jt} +\xi_{jt}
  }_{\delta_{jt}=\delta(x_{jt},p_{jt},\xi_{jt};\theta_1)}
  +
  \underbrace{%
      \begin{pmatrix}
        p_{jt} & x_{jt}
      \end{pmatrix}
      \begin{pmatrix}
        \Pi D_{it} + \Sigma v_{it}
      \end{pmatrix}
  }_{\mu_{ijt}=\mu(x_{jt},p_{jt},D_{ii},v_{it};\theta_2)}
  +\varepsilon_{ijt}
\end{align*}
We'd naturally think to estimate this model's parameters by choosing
$\theta$ such that model-predicted $\sigma_{jt}(\theta)$ matches the
observed market shares $s_{jt}$.
However, as mentioned, $\sigma_{jt}(\theta)$ involves $\xi_{jt}$, which
worry about being corellated with price $p_{jt}$.
Therefore, we need some IV approach, and it's not clear how to
formulate/accomplish that by just minimizing the distance between
$s_{jt}$ and $\sigma_{jt}(\theta)$.
Moreover, $\sigma_{jt}(\theta)$ is super nonlinear, despite the utility
representation looking very linear for a given individual.
So maybe we can help our estimation by exploiting linearity somehow.

All this suggests finding a proper orthogonality condition for the
model, so we do GMM estimation.
To start, suppose that we have vector of instruments $z_{jt}$ such that
\begin{align*}
  0 = \E[\xi_{jt}z_{jt}]
  = \E[(\delta_{jt}-x_{jt}\beta-\alpha p_{jt})z_{jt}]
\end{align*}
Often, $z_{jt}=(x_{jt}'\,\tilde{z}_{jt})'$ where $\tilde{z}_{jt}$ is an
scalar instrument for price.
Conditional on $\delta_{jt}$, that's enough moment conditions to
identify $(\alpha \beta')'$.
Of course, the above moment condition isn't immediately and obviously
useful because we \emph{don't} know $\delta_{jt}$, and that \emph{also}
depends on parameters. So we need some way to estimate $\delta_{jt}$ and
more moments to identify the $\theta_2$ parameters which determine
$\delta_{jt}$.

The big BLP innovation is to note/prove that, under weak conditions, we
can invert (numerically) the model's share equation
$\sigma_j(\delta_t,x_t,p_t;\theta_2)$ to find the $\delta_t$
that equates model $\sigma_j(\delta_t,x_t,p_t;\theta_2)$ to
observed shares $s_t$.
Thus we can write
\begin{align*}
  \delta_{jt}=\sigma_{jt}^{-1}(s_t,x_t,p_t;\theta_2)
\end{align*}
Then we can rewrite the above moment condition as
\begin{align*}
  0
  = \E[(\sigma_{jt}^{-1}(s_t,x_t,p_t;\theta_2)-x_{jt}\beta-\alpha p_{jt})z_{jt}]
  = \E[\xi_{jt}(\theta)z_{jt}]
\end{align*}
But of course, that's not enough to to identify all the parameters,
$z_{jt}$ is not large enough. We need to add more instruments to get to
$Z_{jt}$, which has enough to identify $\theta_2$ as well. Then we have
\begin{align*}
  0
  = \E[(\sigma_{jt}^{-1}(s_t,x_t,p_t;\theta_2)-x_{jt}\beta-\alpha p_{jt})Z_{jt}]
  = \E[\xi_{jt}(\theta)Z_{jt}]
\end{align*}
Thus instruments play two roles:
\begin{itemize}
  \item Generate moments to identify consumer-level parameters
    $\theta_2$.

    Unlike with consumer data (where we have multiple observations
    within a $jt$ to identify individual-level parameters), we don't
    have that here.
    Here we don't have that and must use the instruments to identify the
    parameters $\theta_2$.

    Very clear in nested logit example

  \item Deal with correlation of prices and errors
\end{itemize}


\clearpage
Ideal experiment: randomly vary prices, characteristics, and product
characteristics. See where consumers switch. IVs try to mimic that.
Sources of IVs:
\begin{itemize}
  \item Supply-side information (BLP)
  \item Many markets, $T$ large, lots of variation in demographics
    and product choices across those markets (Nevo)
  \item Micro-moments/information (MicroBLP)
\end{itemize}
Price approximately equals marginal cost plus markup.
So look for things that are exogeneous which impact marginal cost or
markup.
\begin{itemize}
  \item
    Characteristics-based Instruments:
    Assume $\E[\xi_{jt}|x_t]=0$ where $x_t$ is across
    \emph{all} products.\footnote{%
      This make sense if we assume $x_{jt}$ set before $\xi_{jt}$.
    }
    Can then take as an instrument \emph{any} function of $x_t$.
    BLP proposed the following:
    \begin{itemize}
      \item Own characteristics
      \item Average characteristics of other products produced by
        \emph{same} firm
      \item Average characteristics of products produced by
        \emph{competitors}
    \end{itemize}
    Latter two (proximity of given product to others) affects markup
    term, affects price.
    As you move across markets $jt$, competition in the form of
    different products with different characteristics \emph{vary}, which
    affect markup.

  \item Cost-based Instruments:
    These instruments affect marginal costs, which shifts price
    \begin{itemize}
      \item
        Assume $\E[\xi_{jt}|w_t]=0$ where $w_t$ includes characteristics
        (not in $x_t$ since we already built moments from them) that
        enter cost side only, but \emph{not} demand side.
        Then $\xi_{jt}$ is independent of $w_t$, allowing us to form
        instruments as functions of $w_t$.

      \item Price of inputs for each company, interacted with product
        dummies to generate variation by product within the same company

      \item Indirect measures of cost

        Example: Prices of the product in \emph{other} markets, e.g.
        price of cereal in Portland as instrument for price of cereal in
        Boston.

        Validity argument: after controlling for common effects for the
        product (common Cheerios effect), assume everything left over in
        $\xi_{jt}$ after controlling for these things is independent across
        markets.
        (Not valid if regional coordination between Boston and Maine prices)

        Example: local product managers who don't coordinate, so after
        controlling for the Cheerios effect, the price in Portland reflects
        the efforts of marketing manager in Portland, which is independent
        of price in Boston.
        It has identification power because marginal cost of producing
        Cheerios is common across markets, hence prices are correlated
        across markets by ``price equals MC plus markup.''
    \end{itemize}

  \item Dynamic panel:
    Assume $\xi_{jt}=\rho \xi_{jt-1}+\eta_{jt}$, moment condition
    $\E[\eta_{jt}|x_{t-1}]=0$.
\end{itemize}
Nested logit is a special case of RC, where characteristics are
\emph{segment dummies} with a \emph{very particular} distribution on
those dummies.

Connect elasticities to markups via Bertrand pricing model.
That's where all the implied markups come from.
Supply side side, where we can back out markup.


\clearpage
$\xi_{jt}$ is econometrically a residual that ensures observed market
share equals model market share.
Since only $\delta_{jt}$ (not $\mu_{ijt}$) is a \emph{linear} function
of $\xi_{jt}$ (so that $\xi_{jt}$ is effectively just an error term),
that's equivalent to playing around with $\delta_{jt}$ until observed
market share equals model market share.
And under weak conditions, we can invert the share relationship to write
$\delta_{jt}$ as a function of observed shares, characteristics, prices,
and $\theta_2$ (individual characteristic parameters).
Then once we have $\delta_{jt}$, which is a linear function of
$\xi_{jt}$ which acts like a residual, we can form a moment condition
and effectively regress $\delta_{jt}$ on $jt$-specific variables to
recover $\xi_{jt}$ and identify parameters.

Algo
\begin{itemize}
  \item Develop function mapping $(\delta_t,\theta_2)$ into shares:
    $\sigma_j(\delta_t,x_t,p_t;\theta_2)$.

    Assume that $\varepsilon_{ijt}$ so that things are in logit form,
    then compute $\sigma_j$ from expectation via simulation, drawing
    $(D_{it},v_{it})$ from some distribution

  \item Given a guess for $\theta_2$, search for $\delta_2$ such that
    $\sigma_j=s_j$, using the function from the first step.

    Do this by contraction mapping

  \item
    Use computed $\delta_t$ to compute $\xi_{jt}$ and form the GMM
    objective function as a function of total $\theta$.
    In particular, form error term $\xi_{jt}(\theta)$ as
    inverse share less $x_{jt}\beta_+\alpha p_{jt}$.

  \item Search for $\theta$ that minimizes objective function
\end{itemize}
Identification
\begin{itemize}
  \item Ideal experiment: Randomly vary prices and characteristics, see
    what people buy/switch to
  \item Instruments are trying to mimic this
\end{itemize}



\clearpage
\subsection{Sketch Notes}

\subsubsection{Simple Example}

\paragraph{Model}
Random utility
\begin{align*}
  u_{ijt}
  &=
  x_{jt}'\beta
  - \alpha p_{jt}
  + \xi_{jt}
  + \varepsilon_{ij}
\end{align*}
where
\begin{itemize}
  \item $i=1,\ldots,I$ agents
  \item $t=1,\ldots,T$ markets
  \item $j=1,\ldots,J$ products
  \item $x_{jt}$ vector, product $j$ characteristics
  \item $p_{jt}$ price of $j$ at $t$
  \item $\xi_{jt}=\xi_j + \xi_t + \Delta \xi_{jt}$,
    represents unobserved characteristic of $j$ slash demand shock at
    $t$ for $j$ slash measurement error in the price.
    Permanent component for product $j$ is $\xi_j$.
    Common shock at $t$ is $\xi_t$.
    Product-time specific shock for $j$ is $\xi_{jt}$.
  \item $\varepsilon_{ij}$ some logit error term
\end{itemize}
By logit error $\varepsilon_{ij}$, this multinomial choice problem
(determined by the random utilities $u_{ijt}$) implies market shares
$s_{jt}(x,\beta,\alpha,\xi)$ that we can match to true market shares
$S_{jt}$:
\begin{align*}
  S_{jt} = s_{jt}(x,\beta,\alpha,\xi)
  =
  \frac{%
    \exp(x_{jt}'\beta - \alpha p_{jt} + \xi_{jt})
  }{%
    \sum_{j'=1}^J \exp(x_{j't}'\beta - \alpha p_{j't} + \xi_{j't})
  }
\end{align*}
Normalize utility of outside good $j=0$ to zero, $u_{i0t}=0$, which
implies
\begin{align*}
  s_{0t}(x,\beta,\alpha,\xi)
  &=
  \frac{%
    \exp(0)
  }{%
    \sum_{j'=1}^J \exp(x_{j't}'\beta - \alpha p_{j't} + \xi_{j't})
  }
  \\
  -
  e_t
  :=
  \log
  s_{0t}(x,\beta,\alpha,\xi)
  &=
  -
  \log\left(
    \sum_{j'=1}^J \exp(x_{j't}'\beta - \alpha p_{j't} + \xi_{j't})
  \right)
\end{align*}
So then
\begin{align*}
  \log(s_{jt}(x,\beta,\alpha,\xi))
  &=
  x_{jt}'\beta - \alpha p_{jt} + \xi_{jt}
  + e_t
  \\
  \implies\quad
  \log(s_{jt}(x,\beta,\alpha,\xi))
  -
  \log(s_{0t}(x,\beta,\alpha,\xi))
  &=
  x_{jt}'\beta - \alpha p_{jt} + \xi_{jt}
\end{align*}
Note that we have data on the LHS, $S_{jt}-S_{0t}$.


\clearpage
\paragraph{Estimation}
Want to estimate regression
\begin{align*}
  S_{jt}-S_{0t}
  &=
  x_{jt}'\beta - \alpha p_{jt} + \xi_{jt}
\end{align*}
Approaches
\begin{itemize}
  \item
    Regression, but worried about correlation between $p_{jt}$ and
    $\xi_{jt}$
  \item
    Estimate FE model
    \begin{align*}
      S_{jt}-S_{0t}
      &=
      x_{jt}'\beta - \alpha p_{jt}
      + \xi_{j}
      + \xi_{t}
      + \Delta \xi_{jt}
    \end{align*}
    Better, but still worried about correlation between $p_{jt}$ and
    $\Delta \xi_{jt}$.
    Also worried about colinearity between $\xi_j$ and $x_{jt}$ if
    characteristics are time-invariant.

  \item
    Instruments.

    Supply shifter, i.e. something that changes costs.

    Measures of isolation in product space
    $z_{jtk}=\sum_{j'\neq j}x_{j'tk}$, which measures how much product
    $j$ contributes to the average of characteristic $k$.
\end{itemize}



\paragraph{Simple BLP Model}
Preferences are specified
\begin{align*}
  u(x_j,\xi_j,p_j,v_i;\theta_d)
\end{align*}
where $\theta_d$ are demand parameters.
In particular,
\begin{align*}
  u_{ij}
  &= x_j\beta_i - \alpha p_j + \xi_j + \varepsilon_{ij}
  \\
  \beta_{ij}
  &= \beta_k + \sigma_k \eta_{ik}
\end{align*}
where $\varepsilon_{ij}$ are logit, $\eta_{ik}$ are random, so we have
random coefficients $\beta_i$, which is the break with the pure logit
model.
Can rewrite
\begin{align*}
  u_{ij}
  &=
  \delta_j + v_{ij}
  \\
  \delta_j
  &=
  x_j\beta - \alpha p_j + \xi_j
  \\
  v_{ij}
  &=
  \sum_k  x_{jk} \sigma_k \eta_{ik}
  + \varepsilon_{ij}
\end{align*}
Let $A_j(\delta)$ given vector $\delta=(\delta_j)$ denote the set of
all error terms $v_{ij}$ consistent with $j$ being the utility
maximizing choice.
Then the model-implied market share for product $j$, conditional on the
$\delta$'s, is given by
\begin{align*}
  s_j(\delta(x,p,\xi),x,\theta)
  =
  \int_{A_j(\delta)} f(v)\;dv
\end{align*}
In words, the share for product $j$ is the probability mass associated
with $j$ being the optimal choice.
Given data $\tilde{s}_j$ on the shares,
want to pick parameters $\theta$ match match data and model-implied
shares:
\begin{align*}
  \tilde{s}_j
  =
  s_j(\delta(x,p,\xi),x,\theta)
\end{align*}
Conditional on $\theta$, $J$ equations in $J$ unknown $\xi$'s.
Of course don't know $\theta$. So have to find instrument for $\xi_j$.


Computation
\begin{itemize}
  \item Given $\sigma$ and $\delta$, compute market shares implied by
    model. Innermost step.
  \item Given $\sigma$, find $\delta$ to equate market shares, using
    contraction mapping.
  \item Given $\delta$, $\beta$, $\alpha$, form $\xi$ as residual.
  \item Form GMM moment condition, interacting $\xi$ residual with
    instruments.
    Estimate parameters via GMM.
\end{itemize}























%\clearpage
%\section{VARs}

%Three types of concepts, all distinct
%\begin{itemize}
  %\item Shock: Economically meaningful primitive exogeneous forces.
    %They have the following characteristics
    %\begin{itemize}
      %\item Exogenous with respect to other current and lagged endogenous
        %variables in the model. This is putting a finer point on
        %``primitive'' and ``exogenous''
      %\item Uncorrelated with each other so we can identify unique
        %causual effects
      %\item Represent unanticipated movements in exogenous variables or
        %news about future movements in exogeneous variables
    %\end{itemize}
  %\item Innovation: The residuals from a reduced-form VAR
  %\item Instrument
%\end{itemize}
%These three concepts are all generally distinct.
%It is only through the process of \emph{identification} that we
%link/equate innovations with the shocks

%Model
%\begin{align*}
  %Y_t
  %&= B(L)Y_t + \Omega \varepsilon_t
  %\qquad\text{where}\quad
  %\varepsilon_t \sim (0,D)
  %\\
  %B(L)
  %&= B_0 + \sum_{k=1}^p B_kL^k
%\end{align*}
%Corresponding reudced form
%\begin{align*}
  %A(L)Y_t
  %&= \eta_t
  %\qquad\text{where}\quad
  %\eta_t
  %\sim (0,\Sigma_\eta)
  %\\
  %A(L)
  %&= I-\sum_{k=1}^p A_kL^k
%\end{align*}
%Can then link reduced form innovations $\eta_t$ to the structural shocks
%$\varepsilon_t$ by rewriting
%\begin{align*}
  %(I-B_0)Y_t
  %&=
  %\sum_{k=1}^p B_k Y_{t-k}
  %+
  %\Omega \varepsilon_t
  %\\
  %Y_t
  %&=
  %\sum_{k=1}^p A_k Y_{t-k}
  %+
  %\eta_t
%\end{align*}
%From this, deduce that
%\begin{align*}
  %\eta_t
  %&=
  %(I-B_0)^{-1}\Omega\varepsilon_t
  %\\
  %\iff\quad
  %\eta_t
  %&= B_0\eta_t + \Omega \varepsilon_t
%\end{align*}

%Identification approaches
%\begin{itemize}
  %\item Triangularization/Cholesky: Impose zero restrictions
    %so that an endogenous variable does not respond to other endogenous
    %variables contemporaneously.
    %The variable ordered ``first'' responds to no other endogenous
    %variables.
    %The variable ordered ``last'' respond to everything else in the
    %system.

  %\item Nonzero restrictions, structural VAR: set a coefficient to some
    %number which is known for good theoretical reasons

  %\item Heteroscedasticity

  %\item High Frequency identification: Use daily data to isolate effect
    %of Fed announcements on rates. If you control for the Fed's
    %information set, then this is plausible identification of shock/news

  %\item
    %External Instruments/Proxy SVARs:
    %External series $Z_t$ (outside the endogenous variable vector $Y_t$)
    %is a valid instrument for identifying shock $\varepsilon_{ti}$ if
    %\begin{align*}
      %\E[Z_t\varepsilon_{ti}] &\neq 0 \\
      %\E[Z_t\varepsilon_{tj}] &= 0
      %\qquad
      %\forall j\neq i
    %\end{align*}
    %The first condition ensures relevance/usefullnes. The second
    %condition ensures exogeneity.
    %How to implement
    %\begin{enumerate}
      %\item Estimate reduced form VAR to get estimated residuals
        %$\{\hat{\eta}_t\}$
      %\item Regression $\eta_{tj}$ on $\eta_{ti}$ for $j\neq i$ using
        %$Z_t$ as the instrument.
        %These provide unbiased estimates of the ceofficients
    %\end{enumerate}

  %\item
    %Long Run Restrictions:
    %Moving average rep
    %\begin{align*}
      %Y_t = C(L)\eta_t
      %\qquad\text{where}\quad
      %C(L) = A(L)^{-1}
    %\end{align*}
    %Can write $Y_t$ as
    %\begin{align*}
      %Y_t = D(L)\varepsilon_t = C(L)H\varepsilon_t
    %\end{align*}
    %Then want to say that some shock has no effect on some variable in
    %the long run. This amounts to restricting $D^{ij}(1)=0$.
    %This can accommodate whether you want zero long run effect on level
    %or growth rate, depending on whether the variables included are
    %levels or growth rates.

  %\item Sign Restrictions

  %\item FAVARs: For including more information

  %\item DSGE
%\end{itemize}
%Jorda local projection method: For overcoming the negative effects of
%misspecification on estimated IRFs. In the usual way they are computed,
%there's a possibility that the errors would just be compounded.
%Jorda's solution is like iterated vs. direct forecasting.





\clearpage
\section{Cochrane on Unit Roots}

\subsection{Facts about Unit Roots and Shit}

Cochrane's Time Series book has a nice little history of this
literature. He also mentiones Campbell and Perron

Random walk
\begin{align}
  y_t = y_{t-1} + \varepsilon_t
  \label{rw}
\end{align}
Spectral density of an AR(1) with $\phi\ra 1$ approaching random walk
\begin{align*}
  \lim_{\phi\ra 1}f(\omega)
  =
  \lim_{\phi\ra 1}
  \frac{\sigma^2}{1+\phi^2-2\phi \cos(\omega)}
  =
  \frac{\sigma^2}{2(1-\cos(\omega))}
\end{align*}
As $\omega\ra 0$, $f(\omega)\ra \infty$, so the spectral density is
super peaked close to $\omega=0$, i.e. at low frequency.

Random walk a special case of a unit root process. A unit root process
or difference stationary process or I(1) process generalizes the RW and
is any process
\begin{align}
  y_t &= \mu + y_{t-1} + a(L)\varepsilon_t
  \label{I1}
\end{align}
where $a(L)\varepsilon_t$ is stationary.
This is unit root because the implicit lag polynomial on $y_t$,
$(1-z)$, has a root/zero at $z=1$.

Trend stationary is special case of Model~\ref{I1}
\begin{align*}
  y_t &= \mu t + b(L)\varepsilon_t
\end{align*}
This arises when $a(L)$ in Model~\ref{I1} has a unit root that we can
factor out so that
\begin{align*}
  y_t
  &= \mu + y_{t-1} + a(L)\varepsilon_t
  \\
  (1-L)y_t
  &= \mu + (1-L)b(L)\varepsilon_t
  \\
  \iff\quad
  y_t
  &=
  \mu t
  +
  b(L)\varepsilon_t
\end{align*}
Hence, if the model is trend-stationary, it is \emph{also} I(1).
But compare what you get after first differencing the unit root and
trend stationary processes
\begin{align*}
  \Delta y_t
  &= \mu + a(L)\varepsilon_t\\
  \Delta y_t
  &=
  \mu + (1-L)b(L)\varepsilon_t
\end{align*}
In the case of Model~\ref{I1}, the $a(L)$ that remains is generally
invertible and you can get an AR rep for $\Delta y_t$.
But in the trend stationary case, the $(1-L)b(L)$ that remains is
\emph{not} invertible, so no AR rep available.

Rather than think of I(1) processes mechanically as a generalization of
the random walk, the game of studying these processes is figuring out
the implications for the level or long run forecast of a process.

Spectral density at frequency zero of the I(1) process is $a(1)$.
This determines the low frequency movements.
If a pure random walk, then $a(1)=1$.
If trend stationary, then $a(1)=0$.
Of course, intermediate possibilities.

By beveridge nelson, every I(1) process can be written as a sum of a RW
and a stationary process.
There are many ways to do such a decomposition but beveridge nelson is
nice.
In beveridge nelson, the random walk component today is the value if you
forecast the model forever into the future, then run back a linear
trend. The point today in that run-backward linear trend is the random
walk value.
In other words, it's the

OLS estimate of $\phi$ in the following model is downward biased
with too-tight standard errors when $\phi$ close to one:
\begin{align*}
  y_t = \phi y_{t-1} + \varepsilon_t
\end{align*}
So our $<1$ OLS estimates could actually have been generated by random
walks.

Suppose you have a random walk model and estimate it like it's something
trend stationary. This is also bad, and will lead to finding misleading
nonexistent linear trends that are actualy just random walk.

Suppose you regress a random walk on another random walk. The
coefficient estimate will be misleadingly high.



%\clearpage
%\subsection{How big is the Random Walk in GNP}

%Punchline: GNP does actually revert back to trend, but only over several
%years. So in the short run, GNP behaves like a unit root.
%So if you fit a model to the short run behavior, you will incorrectly
%infer long run persistence too that isn't actually there.

%Idea: ``Measure size of random walk component in GNP from the variance
%of its long differences.''
%Two competing models
%\begin{align*}
  %\text{Pure Random Walk:}&\quad
  %y_t
  %= bt + \sum_{j=0}^\infty a_j \varepsilon_{t-j}
  %\\
  %\text{Stationary about Trend:}&\quad
  %y_t
  %= \mu + y_{t-1} + \varepsilon_t
%\end{align*}
%Notice
%\begin{align*}
  %\text{Pure Random Walk}
  %\quad&\implies\quad
  %\Var(y_t-y_{t-k})
  %= k\sigma^2_\varepsilon
  %\\
  %\text{Stationary about Trend}
  %\quad&\implies\quad
  %\Var(y_t-y_{t-k})
  %= 2\sigma^2_y
%\end{align*}
%Can also form variance ratio
%\begin{align*}
  %R
  %&= \frac{\Var(y_t-y_{t-k})/k}{\Var(y_t-y_{t-1})}
%\end{align*}


%\clearpage
%\section{Great Mortgaging}

%Introduce ``long-run annual-frequency dataset on disaggregated
%(mortgage vs. business) bank credit for 17 advanced economies since
%1870.''
%Growth in credit has mostly been rapid growth in mortgage lending, and
%that is robust across countries.

%Questions:
%- We see greater bank lending to households relative to businesses.
  %Does this happen in low-growth economies?
%- Maybe mortgage lending is high private return to the banks but low
  %social return because it's not investing in technology or productive
  %assets. Need a mechanism for this to happen in GE
%- Aiyagari with shocks to the borrowing limit that is below zero
%- Why was mortgage loan growth so strong \emph{then}? Has to be
  %securitization and demand for higher yielding assets.
  %But the run up is still slightly after Solomon brothers did their
  %thing.
%- Why is mortgage lending so different from nonmortgage business
  %lending? Is it the size of the balance sheet or the composition (i.e.
  %the simple fact that banks mostly do that now)?
  %We see a run up in bank loans to GDP. But really it's the composition
  %that has changed.
%- Look at banks/credit unions and lenders that differ in the amount that
  %they lend to households vs. to businesses. Are the ones that lend to
  %households more fragile?


\clearpage
\section{Jump Processes}


\begin{defn}(Cadlag Function)
A function $f:[0,T]\ra\R^d$ is \emph{cadlag} if the $f$ is
right-continuous, and the lefthand limit $\lim_{\delta \ra 0}
f(t-\delta)$ exists for any point in the domain, though this lefthand
limit need \emph{not} equal the righthand limit.
This allows for jumps.
\end{defn}
\begin{defn}(Random, Stopping, Hitting Times)
A \emph{random time} $\tau$ is a nonnegative random variable.

A \emph{stopping time} with respect to filtration $\{\sF_t\}$ is a
random time that is also $\sF_t$-measurable for all $t$, i.e.
$\{\tau\leq t\}\in\sF_t$. In effect, this means that any instant, we can
tell whether or not the event (i.e. the process stopping) has happened.

Given process $X_t$, a \emph{hitting time} $\tau_A$ is a random variable
that encodes the first time $X_t$ hits open set $A$:
\begin{align*}
  \tau_A(\omega):=\argmin_{t} X_t(\omega)\in A
\end{align*}
\end{defn}


\begin{defn}(Counting Process)
Suppose we have an increasing sequence\footnote{%
  I assume ``increasing sequence'' means $T_n\leq T_{n+m}$ for all
  $m\geq 0$, realization by realization
}
of random times $T_n:\Omega\ra\R_+$ with
$P[\limn T_n=\infty]=1$.
Define the \emph{counting process} as $\N$-valued random variable $X_t$
that counts the number of random times (i.e. number of $T_n$'s)
occurring within $[0,t]$.
\begin{align*}
  X_t
  =
  \#\{
    n
    \;|\;
    T_n\leq t,
    \qquad n\geq 1
  \}
  =
  \sumninf
  \mathbf{1}_{\{T_n\leq t\}}
\end{align*}
$X_t$ is Cadlag by construction, and also piecewise constants with jumps
of one unit.
\end{defn}


\begin{defn}(Poisson Process)
The \emph{Poisson Process} $N_t$ is a particular counting process where
each random time $T_n$ is a partial sum of iid exponential RVs:
\begin{align*}
  T_n = \sumin \tau_i
  \qquad
  \tau_i\iid \text{Exp}(\lambda)
\end{align*}
Denote this process by $N_t\sim\text{Poisson}(\lambda t)$ since
\begin{align*}
  P[N_t=n]
  =
  e^{-\lambda t}
  \frac{(\lambda t)^n}{n!}
\end{align*}
$N_t$ is the only counting process with independent and stationary
increments.
\end{defn}

\begin{defn}(Random Measure)
Given  an increasing sequence of random times $T_n:\Omega\ra\R_+$,
define \emph{random measure} $\mu:\Omega\times(\R_+,\sB(\R_+))\ra \N$ on
the natural numbers:
%The sequence $T_n:\Omega\ra\R_+$ that we used to define a counting
%process $X_t$ to count the number of points in $[0,t]$ also
\begin{align*}
  \mu(\omega,A)
  =
  \#\{
    n
    \;|\;
    T_n(\omega)\in A\in\sB(\R_+),\;\; n\geq 1
  \}
\end{align*}
This measure is \emph{random} because $\mu$ is indexed by $\omega$ in
its first argument.
And for each $\omega\in\Omega$, $\mu(\omega,A)$ gives the number of
jumps (or jump times $T_n$) in the set $A$.
Of course, since jumps are random, each different $\omega\in\Omega$
implies a different time/realization for each $T_n(\omega)$, hence a
different answer for how many jumps occurred in $A$.
%We can of course take the expectation over $\Omega$ to get
%\begin{align*}
%\end{align*}

Since the sequence of random times $\{T_n\}$ can be used to define a
corresponding counting process $X_t$, we can offer an alternative
definition of $X_t$ using the random measure $\mu$:
\begin{align}
  X_t(\omega)
  =
  \mu(\omega,[0,t])
  =
  \int_0^t
  \mu(\omega,ds)
  \label{jumprelate}
\end{align}
Thus the number of jumps of $X_t$ in interval $[s,t]$ is given by
$\mu(\omega,[s,t])$.

For every counting process, there is a corresponding jump measure, and
vice versa.
\end{defn}

\begin{defn}
Let $\mu(\omega,A)$ be the associated jump measure for Poisson process
$N_t\sim\text{Poisson}(\lambda t)$.
Since jump measure $\mu(\omega,A)$ is random, we can take it's
expectation and use Expression~\ref{jumprelate} along with
$N_t\sim\text{Poisson}(\lambda t)$
to simplify
\begin{align*}
  \E[\mu(\omega,[0,t])]
  =
  \E[N_t(\omega)]
  =
  \lambda t
\end{align*}
We can think of $\mu$ as the derivative of $N_t$ in the following sense
\begin{align*}
  \frac{dN_t(\omega)}{dt}
  &=
  \mu(\omega,[t,t+dt])
  \qquad\text{where}\quad
  \mu
  = \sum_{n=1}^\infty \delta_{T_n(\omega)}
\end{align*}
i.e. $\mu$ is the sum of Dirac measures at all jump times.
\end{defn}

\begin{defn}
Let $(\Omega,\sF,P)$ be a probability space.
Let $(\R^d,\sG)$ be a a measurable space, and $\lambda$ a positive Radon
measure on that space.
Define a \emph{Poisson random measure}
\begin{align*}
  \mu:\Omega\times(\R^d,\sG)\ra \N
\end{align*}
such that for almost all $\omega\in\Omega$,
$\mu(\omega,\cdot)$ is a $\N$-valued Radon measure on $(\R^d,\sG)$
satisfiying, for any $A\in\sG$,
$\mu(\omega,A)<\infty$ and
\begin{align*}
  P[\mu(\omega,A)=n]
  =
  e^{-\lambda[A]}
  \frac{\big(\lambda[A]\big)^n}{n!}
\end{align*}
and for any disjoint measurable sets $A_1,\ldots,A_m\in\sG$, the RVs
$\mu(\omega,A_1),\ldots,\mu(\omega,A_m)$ are independent.

Can also associated a Poisson random measure with a sequence of points
$\{X_n(\omega)\}\ninf$ in $\R^d$ such that
\begin{align*}
  \mu(\omega,A)
  &=
  \sumninf \mathbf{1}_{\{X_n(\omega)\in A\}}
  \\
  \mu
  &=
  \sumninf \delta_{X_n(\omega)}
\end{align*}
\end{defn}

\clearpage
\subsection{Levy Processes}

\begin{defn}(Levy Process)
Cadlag process $X$ on $\R^d$ with $X_0=0$, satisfying the following three
properties
\begin{enumerate}[label=(\roman*)]
  \item Independent Increments:
    For any $s<t<u$, the RVs
    $X_u-X_t$ and $X_t-X_s$ are independent.
  \item Stationary Increments:
    The distribution of $X_{t+s}-X_t$ does not depend upon $t$
  \item Stochastic Continuity:
    For all $t,\varepsilon>0$,
    $\lim_{s\ra 0} P[|X_{t+s}-X_t|>\varepsilon]=0$.

    Note that this does not mean the process $X_t$ is strictly
    continuous, or that any finite interval $[0,T]$ only has a countable
    or finite number of jumps.
    Rather it only means that jumps do not happen at deterministic
    times, and that at any given time $t$, the probability of a jump is
    zero.
\end{enumerate}
\end{defn}







\clearpage
\section{Function Spaces}

Hilbert space, complete (closed under limits) inner product space.

$L^p$ space is set of functions with norm
$\left(\int |f(x)|^p dx\right)^{1/p}$.

$L^2$ space is also a Hilbert space.

Orthonormal basis $\phi_1,\phi_2,\ldots$ is any sequence of functions
with norm 1 that are orthogonal
\begin{align*}
  \int^b_a \phi_j^2(x)\;dx=1
  \qquad
  \qquad
  \int^b_a \phi_j(x)\phi_k(x)\;dx=0
  \qquad
  j\neq k
\end{align*}
Example: Fourier polynomial basis, Legendre basis (orthogonalized
polynomials), wavelets




\clearpage
\section{Statistics 705}







\subsection{Likelihood Function}

Notation: $L(\theta)$ for likelihood, $\ell(\theta)$ for log-likelihood.

Result:
Suppose we have two datasets $x_{1:N}$ and $y_{1:N}$.
Say $x_{1:N}\sim y_{1:N}$ if
$L(\theta|x_{1:N})\propto L(\theta|y_{1:N})$.
This defines an equivalence class for datasets/observations.
Moreover, the partition induced by the equivalence relation $\sim$ is
the minimal sufficient partition.

Proof:
If proportional, then ratio does not depend upon $\theta$.
Then datasets obs equivalent from perspective of likelihood
maximization.
Thus we can partition data into obs equivalent buckets.
Moreover, likelihood sufficient statistic so then

Likelihood function itself is a minimal sufficient statistic.

Proof:
The ratio result above, easy.

Can I compute the likelihood from this statistic? If yes, then the
statistic is sufficient.
Hence, minimal sufficient stat is minimal amount of information you need
to construct the likelihood.


Likelihood also forms a sufficient partition of the data.
Equivalence class formed by likelihood proportional for two datasets.


\begin{defn}
(Profile Likelihood)
Suppose we can partition $\theta=(\eta',\xi')'$.
The \emph{profile likelihood} for $\eta$ is defined as
\begin{align*}
  L(\eta) = \sup_\xi L(\eta,\xi)
\end{align*}
\end{defn}

\begin{defn}(Equivariant)
If $\eta=g(\theta)$ then $\hat{\eta}=g(\hat{\theta})$ where the hat
guys are the MLE estimates.
So no matter how you parameterize things, you get the same MLE. Nice
property.
\end{defn}


Result: MLE is equivariant.
Two cases
\begin{itemize}
  \item $g(\theta)$ invertible:
    Then can write $\eta=g(\theta)$ and $\theta=g^{-1}(\eta)$.
    Define $L^*(\eta)=L(g^{-1}(\eta))=L(\theta)$.
    Then for any $\eta$,
    \begin{align*}
      L^*(\hat{\eta})
      =
      \max_\eta
      L^*(\eta)
      =
      \max_\eta
      L(g^{-1}(\eta))
      =
      \max_\theta
      L(\theta)
      =
      L(\hat{\theta})
      \geq
      L(\theta)
      =
      L^*(g^{-1}(\theta))
      =
      L^*(\eta)
    \end{align*}
  \item If $g(\theta)$ not invertible, define
    profile likelihood.
    \begin{align*}
      L^*(\eta) =
      \sup_{\theta\,:\,g(\theta)=\eta}
      L(\theta)
      L(\theta)
    \end{align*}
    Do the same steps.
    In words, suppose multiple $\theta$ map to the same $\eta$, and we
    ask what is the MLE over $\eta$?
    The value we assign to the likelihood at a given $\eta$ is now
    associated with one of the $\theta$'s such that $\eta=g(\theta)$,
    and in particular, the one that induces maximal likelihood value.
\end{itemize}



\subsection{Parametric Point Estimation}

A few approaches
\begin{itemize}
  \item Method of moments
  \item MLE
  \item Bayesian estimators
\end{itemize}






\subsection{Distance Between Distributions}

Let $P,Q$ be two distributions with densities $p,q$.
\begin{itemize}
  \item Total variation distance:
    $TV(P,Q)=\sup_A|P(A)-Q(A)|$
  \item $L_1$ distance: $d_1(P,Q) = \int |p-q|$
  \item $L_2$ distance: $d_2(P,Q) = \int (p-q)^2$
  \item Hellinger distance: $h(P,Q) = \sqrt{\int (\sqrt{p}-\sqrt{q})^2}$
  \item Kullback-Leibler divergence: $K(P,Q)=\int p\log(p/q)$.
\end{itemize}
Properties
\begin{itemize}
  \item $TV(P,Q)=\frac{1}{2}d_1(P,Q)$.
  \item $h^2(P,Q)=2(1-\int \sqrt{pq})$
  \item $TV(P,Q)\leq h(P,Q)\leq \sqrt{2TV(P,Q)}$
  \item $h^2(P,Q)\leq K(P,Q)$
  \item $TV(P,Q)\leq h(P,Q)\leq \sqrt{K(P,Q)}$
  \item $TV(P,Q)\leq \sqrt{K(P,Q)/2}$
\end{itemize}






\clearpage
\section{Causal Inference}

\href{http://www.stat.cmu.edu/~larry/=stat705/Lecture17.pdf}{Reference}








\clearpage
\section{Notation}

To standardize
\begin{itemize}
  \item $N$ and $T$ for total number of observations.
  \item No bold
  \item $x_{1:N}$ or $x_{1:T}$ for dataset
  \item Always put log in front for log-likelihood
  \item Always write likelihood function without data as argument,
    except Bayesian
  \item Use ${}_0$ to emphasize true parameter.
  \item ${}_N$ to emphasize asymptotics
  \item $;$ for likelihood, except in Bayesian context where I switch to
    $|$
\end{itemize}






\clearpage
\section{Recent Progress on OLS Regression}

Given data $\calD_n = \{Y_i,X_i\}_{i=1}^n$,
we can always compute OLS estimates
\begin{align*}
  \hat{\theta}
  :=
  \argmin_\theta
  \frac{1}{n}
  \sumin
  (Y_i-X_i'\theta)^2
  =
  (X'X)^{-1}X'Y
  =
  (X'X)^{-1}
  \sumin
  X_iY_i
\end{align*}
In the particular setting of causal inference, we suppose that
$X_i=(D_i,W_i')'$, where $D_i$ is some treatment variable of interest
(generally just a binary indicator) in which case we write
$\hat{\theta}= (\hat{\beta},\hat{\gamma}')'$.
Under regularity conditions, these estimates will converge to
\emph{some estimand}.
The question is what is this estimand?
Is it what we want?
And the answer to that question depends in many ways on our setting,
goals, and assumptions.

We generally run the regression with one of two potential goals in mind.
\begin{enumerate}
  \item
    (\emph{Prediction \& CEF Approx.}):
    Finding the best linear predictor of $Y_i$ given $X_i$ or, closely
    related\footnote{%
      Recall the CEF is the best predictor of $Y_i$ given $X_i$
      generally in a minimum MSE sense.
    }
    and often of greater importance for econometric, modeling, and
    inference purposes, the best linear approximation of the CEF,
    defined
    \begin{align*}
      \mu(x):=\E[Y_i|X_i=x]
    \end{align*}
    To be as general as possible, we allow the CEF to be a
    \emph{nonlinear} function;
    therefore, we will not assume that outcomes are generated by a
    \emph{linear DGP defined by} some parameter vector $\theta$
    and shock $\varepsilon_i$, e.g.
    \begin{align}
      Y_i
      &=
      %D_i\beta
      %+
      %W_i'\gamma
      %+
      %\varepsilon_i
      %=
      X_i'\theta
      +
      \varepsilon_i
      \label{regeq}
    \end{align}
    Rather, $\theta$ and $\varepsilon_i$ will be
    \emph{defined from the DGP} using projections---an enormously
    important distinction.

    Defining $\theta$ as the best linear approximation to generally
    nonlinear $\mu(x)$ requires care precisely because of the possible
    nonlinearity in $\mu(x)$.
    Linear regresion will essentially draw a straight line through the
    the function $\mu(x)$, weighting a given point $x$ by some
    distribution for the $X_i$.
    If the function $\mu(x)$ were truly linear, the distribution we use
    for weighting doesn't matter for the fit because the slope is
    constant across the full support of $X_i$ and so we'll estimate the
    very same slope (on average or in the limit) given any set of
    weights.
    But with nonlinear $\mu(x)$, it will matter whether we choose to fit
    the line weighting by the unconditional superpopulation distribution
    of $X_i$ or the conditional empirical distribution given by the
    data matrix $X$.
    So remember that the estimand depends upon the distribution of $X_i$
    that we use for weighting.

    Our choice of weights and estimand then directly determine the type
    of inference about $\hat{\theta}$ that we conduct---namely,
    whether or not we condition on regressors $X$ in our
    sample when thinking about sampling variability of our
    estimators---and the center of either the finite-sample or (more
    typically) the limiting distribution of our estimator.
    But regardless of whether we condition on the regressors or not,
    analysis proceeds the same way, by making sampling assumptions and
    appealing to large $n$ asymptotics to derive an approximate finite
    sample distribution for $\hat{\theta}$.
    But here's more about the two inference perspectives.
    \begin{enumerate}[label=(\alph*)]
      \item Conditional Inference Perspective
        \begin{itemize}
          \item Regression estimand provides the best linear
            approximation to CEF \emph{conditional} on the distribution
            of $X$ in our sample.
            So if the sample $X$ is quite different from the population,
            the estimand might have little exernal validity.

          \item Takes sample $X$ as given and hold fixed over repeated
            samples.
            Sampling uncertainty driven by variability in outcomes
            $Y_i$ given $X_i$.
            Because we condition on $X$, can even allow for arbitrary
            correlation among regressors across units.

          \item
            When deriving the asymptotic distribution, note that the
            data matrix $X$ and the empirical distribution impled by $X$
            change with $n$.
            So we then generally have a \emph{sequence}
            of estimands, changing with $n$ rather than some fixed
            estimand defined off the (unchanging) superpopulation
            distribution, as in unconditional inference.
            But we can still derive an asymptotic distribution, albeit
            using different sampling and regularity conditions.

          \item Typical starting point of regression; perspective
            that underlies Gauss-Markov.

        \end{itemize}

      \item Unconditional inference
        \begin{itemize}
          \item Regression will deliver the best linear approximation to
            the CEF over the \emph{unconditional} distribution of $X_i$
            in the superpopulation.
          \item Do not condition on the $X$ observed in the
            sample.
            Sampling uncertainty driven by variability in $Y|X=x$
            for a given $x$ \emph{and} the variability in drawn $X$.
        \end{itemize}
    \end{enumerate}

  \item
    (\emph{Causal Inference}):
    We would like to assign to the regression estimands some
    \emph{causal} interpretation, i.e. show that they equal some
    meaningful and interpretable weighted average treatment effect, with
    treatment effects defined in terms of potential outcomes a la the
    Rubin Causal Model.

    Sampling variability in estimators may be driven solely by
    (conditional-on-$W_i$) random assignment, i.e.
    \emph{design-based uncertainty}, or by \emph{both} design-based
    uncertainty and sampling-based uncertainty.
    This will have direct implications for inference.
\end{enumerate}
EHW Variance Estimator:
Define
\begin{align*}
  %\hat{\theta}
  %&=
  %\argmin_\theta
  %\sumin
  %(Y_i-X_i'\theta)
  %=
  %(X'X)^{-1}X'Y
  %\\
  %\hat{\beta}
  %&=
  %(\widetilde{D}'\widetilde{D})^{-1}\widetilde{D}'Y
  %\qquad\text{where}\quad
  %%\E[D_i|Y(D),W]=W'\delta
  %\widetilde{D}
  %=
  %D-H_WD
  %\\
  %\hat{\varepsilon}_i
  %&=
  %Y_i-X_i'\hat{\theta}
  %\\
  \hat{V}_{EHW}
  &=
  n(X'X)^{-1}
  \left(
  \sum_i \hat{\varepsilon}^2_i X_iX_i'
  \right)
  (X'X)^{-1}
\end{align*}
We will consider under which assumptions this is too large, too small,
or just right.



\clearpage
\subsection{Estimands}
First let's define some estimands.
These are all candidates for the limiting $\theta$ for which
$\hat{\theta}$ is consistent under some set of assumptions and
regularity conditions.
For estimands constructed from the sample $\{Y_i,X_i\}_{i=1}^n$ and
corresonding covariate matrix $X$ at hand, I add an $n$ subscript to
emphasize that the estimand will change with $n$ if we take an
asymptotic perspective, which is useful to remember.
\begin{itemize}
  \item (\emph{Descriptive, Unconditional Estimand}):
    Assume that our sample $\calD_n$ is drawn from some superpopulation.
    Then we can define an estimand constructed from the joint
    superpopulation distribution over outcomes and covariates
    $(Y,X)$.
    We use $\E^{sp}$ to denote that teh expectation is taken with
    respect to that superpopulation distribution.
    \begin{align*}
      \theta_{du}
      &:=
      \argmin_{\theta}
      \E^{sp}[(Y_i-X_i'\theta)^2]
      \\
      &\hphantom{:}=
      \argmin_{\theta}
      \E^{sp}[(\mu(X_i)-X_i'\theta)^2]
      \qquad
      \text{LIE}
      \\
      &\hphantom{:}=
      \E^{sp}[X_iX_i']^{-1}
      \E^{sp}[X_iY_i]
      =
      \E^{sp}[X_iX_i']^{-1}
      \E^{sp}[X_i\mu(X_i)]
      \qquad
      \text{Solving FOCs, LIE}
    \end{align*}
    The subscript $du$ indicates that this is a \emph{descriptive},
    \emph{unconditional} estimand.
    Descriptive because we do not assign it a causal interpretation;
    rather, it simply captures one measure of association between
    outcomes $Y$ and covariates $X$.
    Unconditional because it is defined using the superpopulation
    distribution, not the sample at hand.


  \item
    (\emph{Descriptive, Conditional on $X$ Estimand}):
    Condition on the sample data matrix $X$, define the following
    estimand as the best linear approximation to the CEF for samples
    with identical $X$.
    Adding the argument $X$ emphasizes this point.
    \begin{align*}
      \theta_{dc,n}(X)
      &=
      \argmin_{\theta}
      \frac{1}{n}
      \sum_i
      (\mu(X_i)-X_i'\theta)^2
      =
      (X'X)^{-1}X'\mu(X)
    \end{align*}
    The subscript $dc$ indicates again that this is a \emph{descriptive}
    (non-causal), \emph{conditional} on $X$ estimand.


  \item
    (\emph{Causal, Superpopulation Estimand}):
    Assume $X_i=(D_i,W_i')'$.
    Define the following where the expectation $\E^{D,sp}$ is taken over
    both the random assignment mechanism for $D_i$ and the joint
    superpopulation distribution over
    %potential outcomes, treatment, and covariates
    $(Y_i(d),D_i,W_i)$.
    \begin{align*}
      \theta_{cs}
      =
      (\beta_{cs},\gamma_{cs}')'
      &:=
      \argmin_{\theta}
      \E^{D,sp}[(Y_i-X_i'\theta)^2]
      =
      \E^{D,sp}[X_iX_i']^{-1}
      \E^{D,sp}[X_iY_i]
    \end{align*}
    This is a causal estimand because we will make assumptions on the
    assignment mechanism for $D_i$ which will allow us to assign a
    causal interpretation to $\beta_{cs}$.

  \clearpage
  \item
    (\emph{Design-Based Finite Sample Estimand}):
    Define the following estimand where the conditional expectation
    $\E^D$ is taken over the random assignment mechanism for $D$
    alone---no random sampling, potential outcomes are fixed for the
    sample at hand---while conditioning on the full set of potential
    outcomes $Y(D)$ and covariates $W$ in the sample.
    %$Y_i=Y_i(D_i)$ is the realized outcome that depends upon random $D_i$.
    \begin{align*}
      \theta_{cf,n}
      &:=
      \argmin_{\theta}
      \E^D\left[
        \sum_{i=1}^n
        (Y_i-X_i'\theta)^2
        \,\bigg|\,Y(D),W
      \right]
      =
      \E^D
      \left[
      {X}_i{X}_i'
      \,|\,
      Y(D),W
      \right]^{-1}
      \E^D
      \left[
      {X}_iY_i
      \,|\,
      Y(D),W
      \right]
    \end{align*}
\end{itemize}
Each (generally distinct) estimand definition in turn defines a
(generally unique) error:
\begin{align*}
  \varepsilon_{\ell,i}
  &:=
  Y_i-X_i'\theta_{\ell}
  \qquad
  \ell\in\{(du), (dc,n), (cs), (cf,n)\}
\end{align*}
From there, we can rearrange and sub into the OLS formula to rewrite the
estimator in preparation for asymptotic analysis:
\begin{align*}
  \sqrt{n}
  (
  \hat{\theta}
  -
  \theta_{\ell}
  )
  =
  (X'X/n)^{-1}
  \frac{1}{\sqrt{n}}
  \sumin
  X_i
  \underbrace{%
    (Y_i-X_i'\theta_{\ell})
  }_{\varepsilon_{\ell,i}}
\end{align*}
Under different sampling and regularity assumptions on the terms in the
sum, we can then derive corresponding limiting distributions.


\clearpage
\subsection{Assumptions for Inference}

\paragraph{Sampling Assumptions}
These are necessary for characterizing
\emph{sampling-based uncertainty}, where randomness in our estimators is
induced by random sampling, as opposed to design-based uncertainty
(although these two kinds of uncertainty can often both be relevant).
If we assume $n\ra\infty$, the randomness induced by sampling can be
approximated by a normal law according to some CLT, which we can use for
inference about regression estimands.
The assumptions will help ensure that we can apply some CLT.
\begin{enumerate}[label=(\roman*)]
  \item[S1.]
    (\emph{Random Sampling}):
    $(Y_i,X_i)$ iid from superpop.

    This ensures we have external validity for extrapolating from sample
    to superpopulation.

    Note that this assumption might still be used for
    conditional inference.
    It simply says how the $X$ that we condition on were
    generated---namely, independently and identically distributed across
    units.
    This is a bit stronger than needed (although it makes the
    asymptotic distributions of estimators easier to derive since we can
    use the Lindeberg-Levy iid CLT); therefore, the next condition is
    also presented as a relaxation that is still nonetheless sufficient
    for asymptotically normal limiting distributions of estimators under
    conditional inference.

    Similarly, this assumptions might still be used for causal
    inference on top of the inherent design-based uncertainty that's
    already there.

  \item[S2.]
    (\emph{Conditional Sampling}):
    Conditional on $X$, the $Y_i$ are independent with
    mean $\mu(X_i)$.

    Relative to S1, the $X_i$ can now be correlated arbitrarily across
    units, rather than iid.

\end{enumerate}
\paragraph{Regularity Assumptions to Apply CLTs under Sampling}
\begin{enumerate}
  \item[R1.] For unconditional inference
    (which only makes sense under S1)
    \begin{enumerate}[label=(\roman*)]
      \item $\E[X_iX_i']^{-1}$ exists and full rank
      \item $(Y_i,X_i)$ have finite 4th moments
    \end{enumerate}
  \item[R2.] For conditional inference under S1
    \begin{enumerate}[label=(\roman*)]
      \item $X_i$ has finite 2nd moment
      \item $\Var(Y_i|X_i)<\infty$
    \end{enumerate}
  \item[R3.] For conditional inference under S2
    \begin{enumerate}[label=(\roman*)]
      \item $X'X/n$ and $\calV_{dc,n}$ each converge to some positive
        definite limits
      \item $\E[|Y_i-\mu(X_i)|^{2+\eta}|X]$ bounded for some $\eta>0$
        and
        $\max_i H_{ii}\ra 0$ or $\max_i \tilde{H}_{ii}\ra 0$
        for inference on $\theta_{dc}$ or $\beta_{dc}$ respectively.
        The assumptions ensure that we can invoke the Lindberg-Feller
        (or really, the Lyapunov) CLT.
    \end{enumerate}
\end{enumerate}

\clearpage
\paragraph{Assignment Mechanism Assumptions}
These assumptions on the the assignment mechanism are needed to assign
the regression estimands a causal interpretation and to characterize the
\emph{design-based uncertainty} inherent in our regression estimators.

Throughout, we restrict to
\emph{binary treatment},\footnote{%
  Binary treatment can be relaxed, but it
  makes proofs easier.
  Otherwise, instead of a weighted average of $\tau_i$'s, our
  estimands might be a weighted average of derivatives.
}
which implies realized outcomes derived from potential outcomes as
follows:
\begin{align*}
  Y_i = Y_i(D_i)=Y_i(0)+D_i\tau_i
  .
\end{align*}
Assumptions we will employ:
\begin{enumerate}
  \item[C1.]
    (\emph{Random Assignment in Superpopulation}):
    The propensity score is a linear function of one's own covariates
    $W_i$ and does not depend upon own or others' potential outcomes:
    \begin{align*}
      P[D_i=1|Y_i(1),Y_i(0),W_i]
      =
      P[D_i=1|W_i]
      =
      \E[D_i|W_i]
      =W_i'\delta
    \end{align*}
  \item[C2.]
    (\emph{Random Assignment in Finite Population}):
    Conditional on $Y(D),W$ (the full set of potential outcomes and
    regressors for all units in sample), $D_i$ independent across
    $i$ and
    \begin{align*}
      P[D_i=1|Y(D),W]
      =E[D_i|Y(D),W]
      =E[D_i|W_i]
      =W_i'\delta
    \end{align*}
    By independence, $P[D_i=1|Y(D),W]$ is enough to characterize the
    \emph{joint} distribution $P[D|Y(D),W]$ of treatment assignments.
\end{enumerate}
Note
\begin{itemize}
  \item
    These assumptions ensure that controlling for $W_i$ \emph{linearly}
    is enough to ensure as good as random assignment, hence OLS will
    recover a causal estimand.
  \item
    If we instead assume that controlling for $W_i$
    is enough but \emph{only} if controlled for
    \emph{nonparametrically} (i.e. the unconfoundedness assumption),
    we should dispense with linear regression altogether and
    instead use nonparametric regression adjustments or propensity
    score methods to construct a consistent estimator of some weighted
    average of causal effects that has a clear interpretation.
    Otherwise, OLS estimates \emph{some} weighted average of causal
    effects, with strange, uninterpretable weights.
  \item
    If, even worse, it's not even enough to control for covariates, we
    need to take an IV approach and content ourselves with some
    weighted average of LATEs.
\end{itemize}
\paragraph{Regularity Assumptions for Inference under Strictly Design-Based Uncertainty}
\begin{itemize}
  \item $n^{-1}\sumin \lVert W_i\rVert^{4+\eta}$ bounded
  \item $n^{-1}\sumin \E[Y_i|Y(D),W]^{4+\eta}$ bounded
  \item $n^{-1}\sumin \E[D_i^{4+\eta}|W_i]$ bounded
  \item $\E[X'X|W]/n$ coverges to a positive definite limit.
\end{itemize}


\clearpage
\subsection{Sampling Based Inference}

Results
\begin{enumerate}
  \item
    (\emph{Unconditional Inference, iid Sampling of $(Y_i,X_i)$ from
    Superpop.}):
    If our estimand is $\theta_{du}$, under S1 and R1, we can apply
    Lindeberg-Levy to obtain
    \begin{align*}
      \sqrt{n}(\hat{\theta}-\theta_{du})
      =
      (X'X/n)^{-1}
      \frac{1}{\sqrt{n}}
      \sumin
      X_i
      \underbrace{%
        (Y_i-X_i'\theta_{du})
      }_{\varepsilon_{du,i}}
      &
      \; \dto\;
      \calN\big(
        0,\,
        \underbrace{%
        \E[X_iX_i']^{-1}
        \;
        \E\big[\varepsilon^2_{du,i}\,X_iX_i'\big]
        \;
        \E[X_iX_i']^{-1}
        }_{\calV_{du}}
      \big)
    \end{align*}
    We see from the term in the sum why we need finite fourth moments
    (for $X$, at least) to apply Lindeberg-Levy.

    Additionally, under further regularity conditions $\hat{V}_{EHW}$ is
    consistent for $\calV_{du}$.

  \item
    (\emph{Conditional Inference, iid Sampling of $(Y_i,X_i)$ from
    Superpopulation}):
    If our estimand is $\theta_{dc,n}(X)=(X'X)^{-1}X'\mu(X)$,
    under S1 and R2, we obtain the following limiting distribution of our
    estimator by the Lindeberg-Levy CLT, which we can apply since the
    terms of the sum are mean zero and (under S1) iid:
    \begin{align*}
      \sqrt{n}(\hat{\theta}-\theta_{dc,n}(X))
      &=
      (X'X/n)^{-1}
      \frac{1}{\sqrt{n}}
      \sum_i
      X_i
      %\underbrace{%
        (Y_i-\mu(X_i))
      %}_{\varepsilon_{cf,i}}
      \; \dto\;
      \calN\big(
        0,
        \underbrace{%
        \E[X_iX_i']^{-1}
        \E[\Var(Y_i|X_i)X_iX_i']
        \E[X_iX_i']^{-1}
        }_{\calV_{dc}}
      \big)
    \end{align*}
    A note about these asymptotics.
    The random sampling induces a random sequence of
    $\calD_n=\{Y_i,X_i\}_{i=1}^n$ and thus a random sequence of
    estimands, $\theta_{dc,n}(X)$ each built from $\calD_n$.
    And so $\sqrt{n}(\hat{\theta}-\theta_{dc,n}(X))$ is a difference of two
    random objects, unlike $\sqrt{n}(\hat{\theta}-\theta_{du})$ where
    $\theta_{du}$ is a fixed object defined from the superpopulation
    distribution.
    But deriving the asymptotic distribution under random sampling
    assumption S1 is still easy since the terms in the sum are still
    independent, mean-zero RVs.
    And then we can see from the term in the sum why we only need R2
    rather than R1 to apply Lindeberg-Levy.

    We can also relate $\calV_{du}$ and $\calV_{dc}$---both asymptotic
    variances under random sampling assumption S1.
    In particular, it can be shown that
    \begin{align*}
      \E[\varepsilon^2_{du,i}|X_i]
      &=
      \Var(Y_i|X_i) + (\mu(X_i)-X_i'{\theta}_{du})^2
    \end{align*}
    Therefore,
    \begin{align*}
      \calV_{du}
      &=
      \E[X_iX_i']^{-1}
      \;
      \E\big[\varepsilon^2_{du,i}\,X_iX_i'\big]
      \;
      \E[X_iX_i']^{-1}
      =
      \E[X_iX_i']^{-1}
      \;
      \E\big[\E[\varepsilon^2_{du,i}|X_i]\,X_iX_i'\big]
      \;
      \E[X_iX_i']^{-1}
      \\
      &=
      \E[X_iX_i']^{-1}
      \;
      \E\big[\Var(Y_i|X_i)\,X_iX_i'\big]
      \;
      \E[X_iX_i']^{-1}
      +
      \E[X_iX_i']^{-1}
      \;
      \E\big[(\mu(X_i)-X_i'\theta_{du})^2\,X_iX_i'\big]
      \;
      \E[X_iX_i']^{-1}
      \\
      &=
      \calV_{dc}
      +
      \E[X_iX_i']^{-1}
      \;
      \E\big[(\mu(X_i)-X_i'\theta_{du})^2\,X_iX_i'\big]
      \;
      \E[X_iX_i']^{-1}
    \end{align*}
    Since $\hat{V}_{EHW}$ is consistent for $\calV_{du}$ under random
    sampling S1, it is clear from the above expression that
    the variance estimate will be \emph{too large} for conditional
    inference unless the true (generally nonlinear) regression function
    $\mu(X_i)$ is, in fact, linear.
    This suggests using the difference between $\calV_{du}$ and
    $\calV_{dc}$ as one measure of nonlinearity in $\mu(X_i)$.

  \item
    (\emph{Conditional Inference, Independent Conditional Sampling of $Y_i|X_i$}):
    Rather than use S1 which requires the $X_i$ to be iid, we can weaken
    to conditional sampling S2.
    In particular, under under S2 and R3,
    \begin{align*}
      \sqrt{n}(\hat{\theta}-\theta_{dc,n}(X))
      &=
      (X'X/n)^{-1}
      \frac{1}{\sqrt{n}}
      \sum_i
      X_i
      %\underbrace{%
        (Y_i-\mu(X_i))
      %}_{\varepsilon_{cf,i}}
      \\
      &\sim
      \;
      \calN\big(
        0,
        \underbrace{%
          n(X'X)^{-1}
          \left(
          \sum_i
          \Var(Y_i|X_i)\,X_iX_i'
          \right)
          (X'X)^{-1}
        }_{=:\calV_{dc,n}}
      \big)
      +
      o_p(1)
    \end{align*}
    To prove, rewrite in preparation of applying the Lindeberg-Feller
    CLT:
    \begin{align*}
      \sqrt{n}(\hat{\theta}-\theta_{dc,n}(X))
      %&=
      %(X'X/n)^{-1/2}
      %\sumin
      %(X'X)^{-1/2}
      %X_i
      %(Y_i-\mu(X_i))
      %\\
      &=
      \sumin
      \sqrt{n}
      (X'X)^{-1}
      X_i
      (Y_i-\mu(X_i))
    \end{align*}
    We already have independence of the terms in the sum.
    To apply the Lindeberg-Feller CLT, we must also verify that the sum
    of the variances of the terms of the sum converge to some limit.
    Since we're doing conditional-on-$X$ inference, the variances will
    also be conditional on $X$.
    \begin{align*}
      %\sumin
      %\Var\left(
      %(X'X)^{-1/2}
      %X_i
      %(Y_i-\mu(X_i))
      %\;\big|\;
      %X
      %\right)
      %&=
      %(X'X)^{-1/2}
      %\left(
      %\sumin
      %\Var\left(
      %Y_i
      %\,|\,
      %X
      %\right)
      %X_i
      %X_i'
      %\right)
      %(X'X)^{-1/2}
      %\\
      \sumin
      \Var\left(
      \sqrt{n}
      (X'X)^{-1}
      X_i
      (Y_i-\mu(X_i))
      \;\big|\;
      X
      \right)
      &=
      n
      \sumin
      (X'X)^{-1}
      \Var\left(
      Y_i
      \,\big|\,
      X
      \right)
      X_i
      X_i'
      (X'X)^{-1}
      =
      \calV_{dc,n}
    \end{align*}
    We assume that this converges to some limit.
    Together with the assumption that $X'X/n$ converges to some limit,
    a simple sufficient condition for this is that, say,
    $\Var(Y_i|X_i)<C$ for some constant $C$.

    Together with the other regularity conditions,
    by Lindeberge-Feller CLT,
    \begin{align*}
      \sqrt{n}(\hat{\theta}-\theta_{dc,n}(X))
      &=
      (X'X/n)^{-1/2}
      \sumin
      (X'X)^{-1/2}
      X_i
      (Y_i-\mu(X_i))
      &\dto
      \calN\left(
      0,\,
      \lim_{n\ra\infty}
      \calV_{dc,n}
      \right)
    \end{align*}


\end{enumerate}




\clearpage
\subsection{Causal Inference}

\begin{enumerate}
  \item
    (\emph{Alternative Estimator Expressions}):
    For proving that some estimand is, in fact, a weighted average of
    causal effects, it is convenient to define the following expression
    \begin{align*}
        \ddot{D}_i
        &:=
        D_i-W_i'\delta
        \\
        \ddot{X}_i
        &:=
        (\ddot{D}_i,W_i')'
    \end{align*}
    where, recall, $\delta$ is the parameter vector characterizing the
    propensity score in Assumptions C1 and C2.
    This makes $\ddot{D}$ mean zero.

    Recall that we defined the regression estimands
    \begin{align*}
      \theta_{cs}
      =
      (\beta_{cs},
      \gamma_{cs}')'
      &:=
      \E^{D,sp}[X_iX_i']^{-1}
      \E^{D,sp}[X_iY_i]
      \\
      \theta_{cf,n}
      =
      (\beta_{cf,n},
      \gamma_{cf,n}')'
      &:=
      \E^D\left[ {X}_i{X}_i' \,|\, Y(D),W \right]^{-1}
      \E^D \left[ {X}_iY_i \,|\, Y(D),W \right]
    \end{align*}
    Note that we can show
    \begin{align*}
      \beta_{cs}
      &=
      e_1'
      \E^{D,sp}[\ddot{X}_i\ddot{X}_i']^{-1}
      \E^{D,sp}[\ddot{X}_iY_i]
      \\
      \gamma_{cs}
      &=
      \hphantom{e_1'}
      \E^{D,sp}[{W}_i{W}_i']^{-1}
      \E^{D,sp}[{W}_i(Y_i-D_i\beta_{cs})]
      \\
      \beta_{cf,n}
      &=
      e_1'
      \E^{D}[\ddot{X}_i\ddot{X}_i'\,|\,Y(D),W]^{-1}
      \E^{D}[\ddot{X}_iY_i\,|\,Y(D),W]
      \\
      \gamma_{cf,n}
      &=
      \hphantom{e_1'}
      \E^{D}[{W}_i{W}_i'\,|\,Y(D),W]^{-1}
      \E^{D}[{W}_i(Y_i-D_i\beta_{cf,n})\,|\,Y(D),W]
      \\
      &=
      \hphantom{e_1'}
      (W'W)^{-1}
      \sumin
      {W}_i
      \E^{D}[(Y_i-D_i\beta_{cf,n})\,|\,Y(D),W]
    \end{align*}
    Notice that for design-based inference about $\theta_{cf,n}$, only
    $D_i$ or $\ddot{D}_i$ (or $X_i$ and $\ddot{X}_i$ which contains it)
    sit in the expectation since covariates and potential outcomes are
    fixed for the current sample.


  \item
    (\emph{Causal Inference under iid Sampling from Superpopulation}):
    Suppose that Assumptions S1 and R1 hold.
    Then, as argued above,
    \begin{align*}
      \sqrt{n}(\hat{\theta}-\theta_{du})
      =
      (X'X/n)^{-1}
      \frac{1}{\sqrt{n}}
      \sumin
      X_i
      \underbrace{%
        (Y_i-X_i'\theta_{du})
      }_{\varepsilon_{du,i}}
      &
      \; \dto\;
      \calN\big(
        0,\,
        \underbrace{%
        \E[X_iX_i']^{-1}
        \;
        \E\big[\varepsilon^2_{du,i}\,X_iX_i'\big]
        \;
        \E[X_iX_i']^{-1}
        }_{\calV_{du}}
      \big)
    \end{align*}
    Additionally under C1, $\E=\E^{D,sp}$ so that
    \begin{align*}
      \theta_{cs}=\theta_{du}
      \qquad
      \qquad
      \calV_{cs}=\calV_{du}
    \end{align*}
    If we further assume binary treatment, we can obtain the
    following expression for $\beta_{cs}=\beta_{du}$, which gives the
    estimand a causal interpretation as a weighted average of causal
    effects with known weights:
    \begin{align*}
      \beta_{cs}
      =
      \beta_{du}
      =
      \E[\lambda(W_i)\tau(W_i)]
      \qquad\text{where}\quad
      \tau(w)
      &=
      \E[\tau_i|W_i=w]
      \\
      \lambda(w)
      &=
      \frac{%
        \Var(\ddot{D}_i|W_i=w)
      }{%
        \E[\Var(\ddot{D}_i|W_i=w)]
      }
      =
      \frac{%
        \Var({D}_i|W_i=w)
      }{%
        \E[\Var({D}_i|W_i=w)]
      }
    \end{align*}
    To prove, use the definition of $\beta_{cs}$, which means computing
    the following moments under Assumption C1:
    \begin{align*}
      \E[\ddot{D}_iY_i]
      &=
      \E\big[
        \ddot{D}_i
        \big(Y_i(0)+D_i\tau_i\big)
      \big]
      =
      \E\big[
        \E
        \big[
        \ddot{D}_i
        \big(Y_i(0)+D_i\tau_i\big)
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
      \big]
      \\
      &=
      \E\big[
        \E
        \big[
        \ddot{D}_iY_i(0)
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
      \big]
      +
      \E\big[
        \E
        \big[
        \ddot{D}_iD_i\tau_i
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
      \big]
      \\
      &=
      \E\big[
        \E
        \big[
        \ddot{D}_i
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
        \cdot
        \E
        \big[
        Y_i(0)
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
      \big]
      +
      \E\big[
        \E
        \big[
        \ddot{D}_i
        D_i
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
        \cdot
        \E
        \big[
        \tau_i
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
      \big]
      \\
      &=
      \E\big[
        \E
        \big[
        \ddot{D}_i
        \,|\,
        W_i
        \big]
        \cdot
        \E
        \big[
        Y_i(0)
        \,|\,
        W_i
        \big]
      \big]
      +
      \E\big[
        \E
        \big[
        \ddot{D}_i
        D_i
        \,|\,
        W_i
        \big]
        \cdot
        \E
        \big[
        \tau_i
        \,|\,
        W_i
        \big]
      \big]
      \\
      &=
      \E\big[
        0
        \cdot
        \E
        \big[
        Y_i(0)
        \,|\,
        W_i
        \big]
      \big]
      +
      \E\big[
        \E
        \big[
        \ddot{D}_i^2
        \,|\,
        W_i
        \big]
        \cdot
        \tau(W_i)
      \big]
      \\
      &=
      \E\big[
        \Var
        \big(
        \ddot{D}_i
        \,|\,
        W_i
        \big)
        \cdot
        \tau(W_i)
      \big]
      \\
      \E[\ddot{X}_i\ddot{X}_i']
      &=
      \E
      \begin{bmatrix}
        \ddot{D}_i^2
        &
        \ddot{D}_iW_i'
        \\
        \ddot{D}_iW_i
        &
        W_iW_i'
      \end{bmatrix}
      =
      \E
      \left[
      \E
      \left[
      \begin{matrix}
        \ddot{D}_i^2
        &
        \ddot{D}_iW_i'
        \\
        \ddot{D}_iW_i
        &
        W_iW_i'
      \end{matrix}
      \;
      \bigg|
      \;
      W_i
      \right]
      \right]
      =
      \begin{pmatrix}
        \E[\Var(\ddot{D}_i|W_i)]
        &
        0
        \\
        0
        &
        \E[W_iW_i']
      \end{pmatrix}
      \\
      {\theta}_{cs}
      &=
      \E[\ddot{X}_i\ddot{X}_i']^{-1}
      \E[\ddot{X}_i{Y}_i]
      =
      \begin{pmatrix}
        \E[\Var(\ddot{D}_i|W_i)]^{-1}
        &
        0
        \\
        0
        &
        \E[W_iW_i']^{-1}
      \end{pmatrix}
      \begin{pmatrix}
        \E[\ddot{D}_iY_i]
        \\
        \E[W_iY_i]
      \end{pmatrix}
      \\
      \beta_{cs}
      &=
      \E\left[
        \frac{%
          \Var(\ddot{D}_i|W_i)
        }{%
          \E[\Var(\ddot{D}_i|W_i)]
        }
        \tau(W_i)
      \right]
    \end{align*}
    Finally, notice $\Var(\ddot{D}_i|W)=\Var(D_i|W_i)$.

    A few remarks
    \begin{itemize}
      \item With no controls and binary treatment, assignment is truly
        random and so $\beta_{cs}=\E[\tau_i]$, i.e. no weighting.
        Moreover, the variance expression reduces to
        \begin{align*}
          \calV_{du}
          &=
          \frac{S_0^2}{n_0/n}
          +
          \frac{S_1^2}{n_1/n}
          +
          o_p(1)
        \end{align*}

      \item If we would like to estimate unweighted $\E[\tau_i]$,
        we cannot simply do standard OLS regression since it converges
        to $\beta_{cs}=\E[\lambda(W_i)\tau(W_i)]$, as argued.
        Instead, we must reweight because of the selection.


      \item However, the OLS estimand is optimal in the following sense:
        Among all weighted average treatment effects
        $\E[\tilde{\lambda}(W_i)\tau(W_i)]$ where $\tilde{\lambda}(w)$
        is some weighting function we may choose,
        under homoskedasticy $\Var(Y_i|D_i,W_i)=\sigma^2$,
        the OLS estimand with its particular weighting function
        $\lambda(w)$ derived above has the smallest asymptotic variance
        among all weighting functions $\tilde{\lambda}(w)$.

        For intuition, notice from the expression for the weights that
        we upweight those values $w$ such that $\Var(D_i|W_i=w)$ is
        largest (the denominator just normalizes the weights).
        This might seem counterintuitive, but note the variance is
        maximized when binary $D_i$ has probability close to 0.5.
        Thuse we upweight those values of $w$ for which the proportion
        of treatment and control is most balanced, i.e. those values of
        $w$ for which we can most precisely estimate the conditional
        average treatment effect $\E[\tau_i|W_i=w]$.

        Under homoskedasticity of outcomes, this weighting scheme is a
        good thing to do because the precision of our estimates for
        $\E[\tau_i|W_i=w]$ is \emph{solely} determined by the balance
        between treatment and control, not also the conditional variance
        of outcomes.
        Therefore, homoskedasticy is necessary for the estimand to be
        optimal.
        Otherwise, under conditional heteroskedasticity, we'd also want
        to use the conditional variance of outcomes/treatment effects to
        determine the weights in the estimand because there's no use
        upweighting a value $w$ with good balance if the conditional
        heteroskedasticity at that value of $w$ is large.
        Therefore, with heteroskedasticity, the optimal (minimum
        asymptotic variance) weighted average treatment effect estimand
        would take into account both $\Var(D_i|W_i=w)$ and the
        conditional variance $\Var(Y_i|D_i,W_i)$, while the optimal
        estimator would accordingly weight the observations, i.e. be a
        WLS estimator rather than OLS.
    \end{itemize}


  \item
    (\emph{Causal Inference, Strictly Design Based Uncertainty}):
    If we consider only design-based uncertainty, we don't need any
    sampling assumptions, only an assumption on the assignment
    mechanism.
    In particular, assuming binary treatment and C2, $\beta_{cf}$ can
    also be assigned a causal interpretation as a weighted average of
    casual effects with known weights.
    After substituting in and working out the expectations,
    we get an expression that is simply the sample analog of what we had
    in Result 4 (which is unsurprising since the sample is now the
    population):
    \begin{align*}
      \beta_{cf,n}
      &:=
      \sumin
      \left(
      \frac{%
        \sigma^2_D(W_i)
      }{%
        \sumjn \sigma^2_D(W_j)
      }
      \right)
      \tau_i
      \qquad\text{where}\quad
      \sigma^2_D(W_i)
      :=
      \Var(D_i|W_i)
    \end{align*}
    Recall that $\tau_i$ is fixed, the only uncertainty is in the
    assginment vector $D$.

\end{enumerate}

\clearpage
blah

\clearpage
For causal inference, it will also be useful to define the following,
based on recentering $D_i$, for some fixed real vector
$\delta$,\footnote{%
  We will discuss this vector later when we get to the causal inference
  results.
  But for now, just take $\delta$ as some given fixed vector; the
  definitions can still be stated.
}
For causal inference on the superpopulation taking into account
uncertainty from both random assignment and sampling, define the
following estimands constructed from the joint superpopulation
distribution over $(Y_i,X_i)$.
Later, we will show $\theta_{cs}=\theta_{du}$ (i.e. these can be
motivated as OLS estimands) and that these have a causal interpretation.
\begin{align*}
    %\ddot{\theta}_{cs}
    %=
    (\beta_{cs},\ddot{\gamma}_{cs}')'
    &:=
    \E[\ddot{X}_i\ddot{X}_i']^{-1}\E[\ddot{X}_iY_i]
    \\
    \gamma_{cs}
    &:=
    \E[W_iW_i']^{-1}
    \E[W_i(Y_i-D_i\beta_{cs})]
    \\
    \theta_{cs}
    &:=
    (\beta_{cs},\gamma_{cs})
\end{align*}
Next, define the following quantities, where again, the expectations in
the expectation are taken over random assignment only, not sampling.
Later, we will show $\theta_{cf}=\theta_{df,n}$ (i.e. these can be
motivated as OLS estimands) and that these have a causal interpretation.
\begin{align*}
    %\ddot{\theta}_{cf}
    %=
    (\beta_{cf},\ddot{\gamma}_{cf}')'
    &:=
    \E\left[
    \ddot{X}_i\ddot{X}_i'
    \,|\,
    Y(D),W
    \right]^{-1}
    \E
    \left[
    \ddot{X}_iY_i
    \,|\,
    Y(D),W
    \right]
    \\
    &\hphantom{:}=
    \begin{pmatrix}
      \E[
      \ddot{D}_i^2
      \,|\,
      Y(D),W
      ]
      &
      \E[
      \ddot{D}_i
      \,|\,
      Y(D),W
      ]
      W_i'
      \\
      \E[
      \ddot{D}_i
      \,|\,
      Y(D),W
      ]
      W_i
      & W_iW_i'
    \end{pmatrix}^{-1}
    \begin{pmatrix}
    \E
    \left[
    \ddot{D}_iY_i(D_i)
    \,|\,
    Y(D),W
    \right]
    \\
    W_i
    \E
    \left[
    Y_i(D_i)
    \,|\,
    Y(D),W
    \right]
    \end{pmatrix}
    \\
    \gamma_{cf}
    &:=
    \left[
    \sumin
    W_iW_i'
    \right]^{-1}
    \left[
    \sumin
    W_i
    \E\big[
    (Y_i-D_i\beta_{cf})
    \,|\,
    Y(D),W
    \big]
    \right]
    \\
    &\hphantom{:}=
    (W'W)^{-1}
    \left[
    \sumin
    W_i
    \E\big[
    (Y_i(D_i)-D_i\beta_{cf})
    \,|\,
    Y(D),W
    \big]
    \right]
    \\
    \theta_{cf}
    &:=
    (\beta_{cf},\gamma_{cf})
    \\
    \varepsilon_{cf,i}
    &:=
    Y_i-X_i'\theta_{cf}
    =
    Y_i
    -D_i\beta_{cf}
    -W_i'\gamma_{cf}
\end{align*}
%\begin{align*}
    %\gamma_{cf}
    %&:=
    %(W'W)^{-1}
    %W'\E[(Y-D\beta_{cf}) \,|\,W,Y(0)]
    %\\
    %&=
    %(W'W)^{-1}
    %\sumin
    %W_i\E[(Y_i-D_i\beta_{cf})\,|\,W,Y(0)]
    %\\
    %=
    %(W'W)^{-1}
    %\sumin
    %W_i
    %\big(
    %Y_i(0)
    %+
    %\E[D_i|W,Y(0)]
    %\cdot(\tau_i-\beta_{cf})
    %\big)
%\end{align*}



\clearpage

\clearpage
\paragraph{Results}
\begin{enumerate}

  \item


  \item
    Moreover, note that
    \begin{itemize}
      \item ${\beta}_{cs}=\beta_{du}$
        because $\ddot{D}_i$ is simply a recentering of $D_i$ using
        a linear function of covariates $W_i$ already in the regression.
        In other words,
        the coefficient on $\ddot{D}_i$ in the regression of $Y_i$ on
        $\ddot{X}_i$ equals the coefficient on $D_i$ in the regression of
        $Y_i$ on $X_i$.
      \item $\gamma_{cs}=\gamma_{du}$.
        This follows because
        \begin{align*}
          Y_i = D_i\beta_{du}+W_i'\gamma_{du} + \varepsilon_{du,i}
        \end{align*}
        Therefore, regressing $Y_i-D_i\beta_{du}$ on $W_i$ alone will
        recover the same parameter $\gamma_{du}$ that we get from regressing
        $Y_i$ on $X_i=(D_i,W_i')'$.
      \item
        $\theta_{cs}=(\beta_{cs},\gamma_{cs}')'=(\beta_{du},\gamma_{du}')'=\theta_{du}$
        by the previous bullet points.
    \end{itemize}

  \item
    First note that the definition of
    $\theta_{cf}=(\beta_{cf},\gamma_{cf}')'$ can be motivated as
    the regression estimand $\theta_{df,n}$.
    In particular,
    \begin{itemize}
      \item ${\beta}_{cf}=\beta_{df,n}$
        because $\ddot{D}_i$ is simply a recentering of $D_i$ using
        a linear function of covariates $W_i$ already in the regression.
      \item $\gamma_{cf}=\gamma_{df,n}$.
        This follows because
        \begin{align*}
          Y = D\beta_{df,n}+W'\gamma_{df,n} + \varepsilon_{df,n}
        \end{align*}
        Therefore, regressing $Y_i-D_i\beta_{df,n}$ on $W_i$ alone will
        recover the same parameter $\gamma_{df,n}$ that we get from
        regressing $Y_i$ on $X_i=(D_i,W_i')'$.
      \item
        $\theta_{df,n}=(\beta_{df,n},\gamma_{df,n}')'=(\beta_{cf},\gamma_{cf}')'=\theta_{cf}$
        by the previous bullet points.
    \end{itemize}


\end{enumerate}






\clearpage
Ideas
\begin{itemize}
  \item Start with inference about the mean under treatment.
    Can get unbiased estimator for this.
    For inference, there's the probability that a center treats both, vs
    treated by different centers.

  \item Rewrite sums from $i=1,\ldots,n$ as sum over clusters or pseudo
    clusters
  \item There is an equivalence class of clusters defined by distance.
    This location will ensure that a given pair is treated.
    This set of locations will ensure that a given pair is treated.
  \item Guido when to cluster paper, see what it says about causal
    inference.
\end{itemize}



%% APPPENDIX %%

% \appendix




\end{document}


https://www.youtube.com/watch?v=UrefKMSEuAI&list=PLE125425EC837021F
https://www.youtube.com/user/mathematicalmonk/featured

https://www.youtube.com/watch?v=4RZiWZXdbTw&list=PL1M5TsfDV6Vufqfs_h5fDR3pBhIj4QOW7&index=2
https://www.youtube.com/watch?v=S5TVIPknDI4&list=PL1M5TsfDV6Vui-q_q1Bq5kF2Y77udGwWx
https://www.youtube.com/watch?v=ROLeLaR-17U&list=PL1M5TsfDV6Vu-GcB4Eb1P1KQ3wVxMI9Mn
https://www.youtube.com/watch?v=4xF_DMbL14w&list=PL1M5TsfDV6VsE11CCeMuBL0owBpwp4xru
https://www.youtube.com/watch?v=TfKwgGT2fSM&list=PL1M5TsfDV6Vs9biqgcsAG-ZQAqqkXaOqA
https://www.youtube.com/watch?v=nlsR4lxYBRo&list=PL1M5TsfDV6Vs53iHrxybY3rUa0MU1qAOy
https://www.youtube.com/watch?v=Kv2qe2nBATI&list=PL1M5TsfDV6VsiMw3IAsfyaZBmZfpSj7Bf
https://www.youtube.com/watch?v=Zxyj8HU2Kmg
https://www.youtube.com/watch?v=Pz4ephK-f94
https://www.youtube.com/results?search_query=spline
https://www.youtube.com/watch?v=3jQs02dbfrI&list=PL06ytJZ4Ak1rXmlvxTyAdOEfiVEzH00IK

https://www.youtube.com/watch?v=UOMvUaYfpH4
https://www.youtube.com/watch?v=_PwhiWxHK8o
https://www.youtube.com/watch?v=HTVDo0Bd36Y
https://www.youtube.com/watch?v=y1JuX5IsIuE
https://www.youtube.com/watch?v=1Eg6TvOx2OY
https://www.youtube.com/watch?v=P_og8H-VkIY&list=PLwJRxp3blEvZ8AKMXOy0fc0cqT61GsKCG
https://www.youtube.com/watch?v=WV_jcaDBZ2I&list=PLwJRxp3blEvaOTZfSKXysxRmi6gXJf5gP
https://www.youtube.com/watch?v=GMVh02WGhoc&list=PLwJRxp3blEvaxmHgI2iOzNP6KGLSyd4dz
https://www.youtube.com/watch?v=Za1YxRJL-SA&list=PLwJRxp3blEvZBAn3bwAAtdJqotRPBWBlP
https://www.youtube.com/watch?v=WK03XgoVsPM&list=PLD15D38DC7AA3B737
https://www.youtube.com/watch?v=zvrcyqcN9Wo
https://www.youtube.com/watch?v=JHvmBb6YKDw




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%% SAMPLE CODE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    %% VIEW LAYOUT %%

        \layout

    %% LANDSCAPE PAGE %%

        \begin{landscape}
        \end{landscape}

    %% BIBLIOGRAPHIES %%

        \cite{LabelInSourcesFile}  %Use in text; cites
        \citep{LabelInSourcesFile} %Use in text; cites in parens

        \nocite{LabelInSourceFile} % Includes in refs w/o specific citation
        \bibliographystyle{apalike}  % Or some other style

        % To ditch the ``References'' header
        \begingroup
        \renewcommand{\section}[2]{}
        \endgroup

        \bibliography{sources} % where sources.bib has all the citation info

    %% SPACING %%

        \vspace{1in}
        \hspace{1in}

    %% URLS, EMAIL, AND LOCAL FILES %%

      \url{url}
      \href{url}{name}
      \href{mailto:mcocci@raidenlovessusie.com}{name}
      \href{run:/path/to/file.pdf}{name}


    %% INCLUDING PDF PAGE %%

        \includepdf{file.pdf}


    %% INCLUDING CODE %%

        %\verbatiminput{file.ext}
            %   Includes verbatim text from the file

        \texttt{text}
            %   Renders text in courier, or code-like, font

        \matlabcode{file.m}
            %   Includes Matlab code with colors and line numbers

        \lstset{style=bash}
        \begin{lstlisting}
        \end{lstlisting}
            % Inline code rendering


    %% INCLUDING FIGURES %%

        % Basic Figure with size scaling
            \begin{figure}[h!]
               \centering
               \includegraphics[scale=1]{file.pdf}
            \end{figure}

        % Basic Figure with specific height
            \begin{figure}[h!]
               \centering
               \includegraphics[height=5in, width=5in]{file.pdf}
            \end{figure}

        % Figure with cropping, where the order for trimming is  L, B, R, T
            \begin{figure}
               \centering
               \includegraphics[trim={1cm, 1cm, 1cm, 1cm}, clip]{file.pdf}
            \end{figure}

        % Side by Side figures: Use the tabular environment


