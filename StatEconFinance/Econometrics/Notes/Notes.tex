\documentclass[12pt]{article}

\author{Matthew D. Cocci}
\title{ECO-513: Notes}
\date{\today}

%% Formatting & Spacing %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry} % most detailed page formatting control
\usepackage{fullpage} % Simpler than using the geometry package; std effect
\usepackage{setspace}
%\onehalfspacing
\usepackage{microtype}

%% Formatting %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage[margin=1in]{geometry}
    %   Adjust the margins with geometry package
%\usepackage{pdflscape}
    %   Allows landscape pages
%\usepackage{layout}
    %   Allows plotting of picture of formatting



%% Header %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage{fancyhdr}
%\pagestyle{fancy}
%\lhead{}
%\rhead{}
%\chead{}
%\setlength{\headheight}{15.2pt}
    %   Make the header bigger to avoid overlap

%\fancyhf{}
    %   Erase header settings

%\renewcommand{\headrulewidth}{0.3pt}
    %   Width of the line

%\setlength{\headsep}{0.2in}
    %   Distance from line to text


%% Mathematics Related %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{amsthm} %allows for labeling of theorems
%\numberwithin{equation}{section} % Number equations by section
\usepackage{bbm} % For bold numbers

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{assump}[thm]{Assumption}
\newtheorem{ex}[thm]{Example}

\theoremstyle{remark}
\newtheorem*{rmk}{Remark}
\newtheorem*{note}{Note}

% Below supports left-right alignment in matrices so the negative
% signs don't look bad
\makeatletter
\renewcommand*\env@matrix[1][c]{\hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{*\c@MaxMatrixCols #1}}
\makeatother


%% Font Choices %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
%\usepackage{blindtext}
\usepackage{courier}


%% Figures %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing}
%\usetikzlibrary{arrows.meta}
\usepackage{graphicx}
\usepackage{subfigure}
    %   For plotting multiple figures at once
%\graphicspath{ {Directory/} }
    %   Set a directory for where to look for figures


%% Hyperlinks %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{hyperref}
\hypersetup{%
    colorlinks,
        %   This colors the links themselves, not boxes
    citecolor=black,
        %   Everything here and below changes link colors
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

%% Colors %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{color}
\definecolor{codegreen}{RGB}{28,172,0}
\definecolor{codelilas}{RGB}{170,55,241}

% David4 color scheme
\definecolor{d4blue}{RGB}{100,191,255}
\definecolor{d4gray}{RGB}{175,175,175}
\definecolor{d4black}{RGB}{85,85,85}
\definecolor{d4orange}{RGB}{255,150,100}

%% Including Code %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{verbatim}
    %   For including verbatim code from files, no colors
\usepackage{listings}
    %   For including code snippets written directly in this doc

\lstdefinestyle{bash}{%
  language=bash,%
  basicstyle=\footnotesize\ttfamily,%
  showstringspaces=false,%
  commentstyle=\color{gray},%
  keywordstyle=\color{blue},%
  xleftmargin=0.25in,%
  xrightmargin=0.25in
}
\lstdefinestyle{log}{%
  basicstyle=\scriptsize\ttfamily,%
  showstringspaces=false,%
  xleftmargin=0.25in,%
  xrightmargin=0.25in
}


\lstdefinestyle{matlab}{%
  language=Matlab,%
  basicstyle=\footnotesize\ttfamily,%
  breaklines=true,%
  morekeywords={matlab2tikz},%
  keywordstyle=\color{blue},%
  morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},%
  identifierstyle=\color{black},%
  stringstyle=\color{codelilas},%
  commentstyle=\color{codegreen},%
  showstringspaces=false,%
    %   Without this there will be a symbol in
    %   the places where there is a space
  %numbers=left,%
  %numberstyle={\tiny \color{black}},%
    %   Size of the numbers
  numbersep=9pt,%
    %   Defines how far the numbers are from the text
  emph=[1]{for,end,break,switch,case},emphstyle=[1]\color{blue},%
    %   Some words to emphasise
}

\newcommand{\matlabcode}[1]{%
    \lstset{style=matlab}%
    \lstinputlisting{#1}
}
    %   For including Matlab code from .m file with colors,
    %   line numbering, etc.

\lstdefinelanguage{Julia}%
  {morekeywords={abstract,break,case,catch,const,continue,do,else,elseif,%
      end,export,false,for,function,immutable,import,importall,if,in,%
      macro,module,otherwise,quote,return,switch,true,try,type,typealias,%
      using,while},%
   sensitive=true,%
   %alsoother={$},%
   morecomment=[l]\#,%
   morecomment=[n]{\#=}{=\#},%
   morestring=[s]{"}{"},%
   morestring=[m]{'}{'},%
}[keywords,comments,strings]

\lstdefinestyle{julia}{%
    language         = Julia,
    basicstyle       = \scriptsize\ttfamily,
    keywordstyle     = \bfseries\color{blue},
    stringstyle      = \color{codegreen},
    commentstyle     = \color{codegreen},
    showstringspaces = false,
    literate         = %
      {ρ}{{$\rho$}}1
      {ℓ}{{$\ell$}}1
      {∑}{{$\Sigma$}}1
      {Σ}{{$\Sigma$}}1
      {√}{{$\sqrt{}$}}1
      {θ}{{$\theta$}}1
      {ω}{{$\omega$}}1
      {ɛ}{{$\varepsilon$}}1
      {φ}{{$\varphi$}}1
      {σ²}{{$\sigma^2$}}1
      {Φ}{{$\Phi$}}1
      {ϕ}{{$\phi$}}1
      {Dₑ}{{$D_e$}}1
      {Σ}{{$\Sigma$}}1
      {γ}{{$\gamma$}}1
      {δ}{{$\delta$}}1
      {τ}{{$\tau$}}1
      {μ}{{$\mu$}}1
      {β}{{$\beta$}}1
      {Λ}{{$\Lambda$}}1
      {λ}{{$\lambda$}}1
      {r̃}{{$\tilde{\text{r}}$}}1
      {α}{{$\alpha$}}1
      {σ}{{$\sigma$}}1
      {π}{{$\pi$}}1
      {∈}{{$\in$}}1
      {∞}{{$\infty$}}1
}


%% Bibliographies %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{natbib}
    %---For bibliographies
%\setlength{\bibsep}{3pt} % Set how far apart bibentries are

%% Misc %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{enumitem}
    %   Has to do with enumeration
\usepackage{appendix}
%\usepackage{natbib}
    %   For bibliographies
\usepackage{pdfpages}
    %   For including whole pdf pages as a page in doc
\usepackage{pgffor}
    %   For easier looping


%% User Defined %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newcommand{\nameofcmd}{Text to display}
\newcommand*{\Chi}{\mbox{\large$\chi$}} %big chi
    %   Bigger Chi

% In math mode, Use this instead of \munderbar, since that changes the
% font from math to regular
\makeatletter
\def\munderbar#1{\underline{\sbox\tw@{$#1$}\dp\tw@\z@\box\tw@}}
\makeatother

% Misc Math
\newcommand{\ra}{\rightarrow}
\newcommand{\diag}{\text{diag}}
\newcommand{\ch}{\text{ch}}
\newcommand{\dom}{\text{dom}}
\newcommand{\one}[1]{\mathbf{1}_{#1}}


% Command to generate new math commands:
% - Suppose you want to refer to \boldsymbol{x} as just \bsx, where 'x'
%   is any letter. This commands lets you generate \bsa, \bsb, etc.
%   without copy pasting \newcommand{\bsa}{\boldsymbol{a}} for each
%   letter individually. Instead, just include
%
%     \generate{bs}{\boldsymbol}{a,...,z}
%
% - Uses pgffor package to loop
% - Example with optional argument. Will generate \bshatx to represent
%   \boldsymbol{\hat{x}} for all letters x
%
%     \generate[\hat]{bshat}{\boldsymbol}{a,...,z}

\newcommand{\generate}[4][]{%
  % Takes 3 arguments (maybe four):
  % - 1   wrapcmd (optional, defaults to nothing)
  % - 2   newname
  % - 3   mathmacro
  % - 4   Names to loop over
  %
  % Will produce
  %
  %   \newcommand{\newnameX}{mathmacro{wrapcmd{X}}}
  %
  % for each X in argument 4

  \foreach \x in {#4}{%
    \expandafter\xdef\csname%
      #2\x%
    \endcsname%
    {\noexpand\ensuremath{\noexpand#3{\noexpand#1{\x}}}}
  }
}


% MATHSCR: Gen \sX to stand for \mathscr{X} for all upper case letters
\generate{s}{\mathscr}{A,...,Z}


% BOLDSYMBOL: Generate \bsX to stand for \boldsymbol{X}, all upper and
% lower case.
%
% Letters and greek letters
\generate{bs}{\boldsymbol}{a,...,z}
\generate{bs}{\boldsymbol}{A,...,Z}
\newcommand{\bstheta}{\boldsymbol{\theta}}
\newcommand{\bsmu}{\boldsymbol{\mu}}
\newcommand{\bsSigma}{\boldsymbol{\Sigma}}
\newcommand{\bsvarepsilon}{\boldsymbol{\varepsilon}}
\newcommand{\bsalpha}{\boldsymbol{\alpha}}
\newcommand{\bsbeta}{\boldsymbol{\beta}}
\newcommand{\bsOmega}{\boldsymbol{\Omega}}
\newcommand{\bshatOmega}{\boldsymbol{\hat{\Omega}}}
\newcommand{\bshatG}{\boldsymbol{\hat{G}}}
\newcommand{\bsgamma}{\boldsymbol{\gamma}}
\newcommand{\bslambda}{\boldsymbol{\lambda}}

% Special cases like \bshatb for \boldsymbol{\hat{b}}
\generate[\hat]{bshat}{\boldsymbol}{b,y,x,X,V,S,W}
\newcommand{\bshatbeta}{\boldsymbol{\hat{\beta}}}
\newcommand{\bshatmu}{\boldsymbol{\hat{\mu}}}
\newcommand{\bshattheta}{\boldsymbol{\hat{\theta}}}
\newcommand{\bshatSigma}{\boldsymbol{\hat{\Sigma}}}
\newcommand{\bstildebeta}{\boldsymbol{\tilde{\beta}}}
\newcommand{\bstildetheta}{\boldsymbol{\tilde{\theta}}}
\newcommand{\bsbarbeta}{\boldsymbol{\overline{\beta}}}
\newcommand{\bsbarg}{\boldsymbol{\overline{g}}}

% Redefine \bso to be the zero vector
\renewcommand{\bso}{\boldsymbol{0}}

% Transposes of all the boldsymbol shit
\newcommand{\bsbp}{\boldsymbol{b'}}
\newcommand{\bshatbp}{\boldsymbol{\hat{b'}}}
\newcommand{\bsdp}{\boldsymbol{d'}}
\newcommand{\bsgp}{\boldsymbol{g'}}
\newcommand{\bsGp}{\boldsymbol{G'}}
\newcommand{\bshp}{\boldsymbol{h'}}
\newcommand{\bsSp}{\boldsymbol{S'}}
\newcommand{\bsup}{\boldsymbol{u'}}
\newcommand{\bsxp}{\boldsymbol{x'}}
\newcommand{\bsyp}{\boldsymbol{y'}}
\newcommand{\bsthetap}{\boldsymbol{\theta'}}
\newcommand{\bsmup}{\boldsymbol{\mu'}}
\newcommand{\bsSigmap}{\boldsymbol{\Sigma'}}
\newcommand{\bshatmup}{\boldsymbol{\hat{\mu'}}}
\newcommand{\bshatSigmap}{\boldsymbol{\hat{\Sigma'}}}

% MATHCAL: Gen \calX to stand for \mathcal{X}, all upper case
\generate{cal}{\mathcal}{A,...,Z}

% MATHBB: Gen \X to stand for \mathbb{X} for some upper case
\generate{}{\mathbb}{R,Q,C,Z,N,Z,E,U,Y}
\newcommand{\Rn}{\mathbb{R}^n}
\newcommand{\RN}{\mathbb{R}^N}
\newcommand{\Rk}{\mathbb{R}^k}
\newcommand{\RK}{\mathbb{R}^K}
\newcommand{\RL}{\mathbb{R}^L}
\newcommand{\Rl}{\mathbb{R}^\ell}
\newcommand{\Rm}{\mathbb{R}^m}
\newcommand{\Rnn}{\mathbb{R}^{n\times n}}
\newcommand{\Rmn}{\mathbb{R}^{m\times n}}
\newcommand{\Rnm}{\mathbb{R}^{n\times m}}
\newcommand{\Rkn}{\mathbb{R}^{k\times n}}
\newcommand{\Cn}{\mathbb{C}^n}
\newcommand{\Cnn}{\mathbb{C}^{n\times n}}

% Dot over
\newcommand{\dx}{\dot{x}}
\newcommand{\ddx}{\ddot{x}}
\newcommand{\dy}{\dot{y}}
\newcommand{\ddy}{\ddot{y}}

% First derivatives
\newcommand{\dydx}{\frac{dy}{dx}}
\newcommand{\dfdx}{\frac{df}{dx}}
\newcommand{\dfdy}{\frac{df}{dy}}
\newcommand{\dfdz}{\frac{df}{dz}}

% Second derivatives
\newcommand{\ddyddx}{\frac{d^2y}{dx^2}}
\newcommand{\ddydxdy}{\frac{d^2y}{dx dy}}
\newcommand{\ddydydx}{\frac{d^2y}{dy dx}}
\newcommand{\ddfddx}{\frac{d^2f}{dx^2}}
\newcommand{\ddfddy}{\frac{d^2f}{dy^2}}
\newcommand{\ddfddz}{\frac{d^2f}{dz^2}}
\newcommand{\ddfdxdy}{\frac{d^2f}{dx dy}}
\newcommand{\ddfdydx}{\frac{d^2f}{dy dx}}


% First Partial Derivatives
\newcommand{\pypx}{\frac{\partial y}{\partial x}}
\newcommand{\pfpx}{\frac{\partial f}{\partial x}}
\newcommand{\pfpy}{\frac{\partial f}{\partial y}}
\newcommand{\pfpz}{\frac{\partial f}{\partial z}}


% argmin and argmax
\DeclareMathOperator*{\argmin}{arg\;min}
\DeclareMathOperator*{\argmax}{arg\;max}


% Various probability and statistics commands
\newcommand{\iid}{\overset{iid}{\sim}}
\newcommand{\med}{\operatorname{med}}
\newcommand{\vc}{\operatorname{vec}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\Cov}{\operatorname{Cov}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\trace}{\operatorname{tr}}
\newcommand{\Corr}{\operatorname{Corr}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\asto}{\xrightarrow{a.s.}}
\newcommand{\pto}{\xrightarrow{P}}
\newcommand{\uto}{\xrightarrow{u}}
\newcommand{\msto}{\xrightarrow{m.s.}}
\newcommand{\dto}{\xrightarrow{d}}
\newcommand{\Lpto}{\xrightarrow{L_p}}
\newcommand{\Lqto}[1]{\xrightarrow{L_{#1}}}
\newcommand{\plim}{\text{plim}_{n\rightarrow\infty}}


% Redefine real and imaginary from fraktur to plain text
\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}

% Shorter sums: ``Sum from X to Y''
% - sumXY  is equivalent to \sum^Y_{X=1}
% - sumXYz is equivalent to \sum^Y_{X=0}
\newcommand{\sumnN}{\sum^N_{n=1}}
\newcommand{\sumin}{\sum^n_{i=1}}
\newcommand{\sumjn}{\sum^n_{j=1}}
\newcommand{\sumim}{\sum^m_{i=1}}
\newcommand{\sumik}{\sum^k_{i=1}}
\newcommand{\sumiN}{\sum^N_{i=1}}
\newcommand{\sumkn}{\sum^n_{k=1}}
\newcommand{\sumtT}{\sum^T_{t=1}}
\newcommand{\sumninf}{\sum^\infty_{n=1}}
\newcommand{\sumtinf}{\sum^\infty_{t=1}}
\newcommand{\sumnNz}{\sum^N_{n=0}}
\newcommand{\suminz}{\sum^n_{i=0}}
\newcommand{\sumknz}{\sum^n_{k=0}}
\newcommand{\sumtTz}{\sum^T_{t=0}}
\newcommand{\sumninfz}{\sum^\infty_{n=0}}
\newcommand{\sumtinfz}{\sum^\infty_{t=0}}

\newcommand{\prodnN}{\prod^N_{n=1}}
\newcommand{\prodin}{\prod^n_{i=1}}
\newcommand{\prodiN}{\prod^N_{i=1}}
\newcommand{\prodkn}{\prod^n_{k=1}}
\newcommand{\prodtT}{\prod^T_{t=1}}
\newcommand{\prodnNz}{\prod^N_{n=0}}
\newcommand{\prodinz}{\prod^n_{i=0}}
\newcommand{\prodknz}{\prod^n_{k=0}}
\newcommand{\prodtTz}{\prod^T_{t=0}}

% Bounds
\newcommand{\atob}{_a^b}
\newcommand{\ztoinf}{_0^\infty}
\newcommand{\kinf}{_{k=1}^\infty}
\newcommand{\ninf}{_{n=1}^\infty}
\newcommand{\minf}{_{m=1}^\infty}
\newcommand{\tinf}{_{t=1}^\infty}
\newcommand{\nN}{_{n=1}^N}
\newcommand{\tT}{_{t=1}^T}
\newcommand{\kinfz}{_{k=0}^\infty}
\newcommand{\ninfz}{_{n=0}^\infty}
\newcommand{\minfz}{_{m=0}^\infty}
\newcommand{\tinfz}{_{t=0}^\infty}
\newcommand{\nNz}{_{n=0}^N}

% Limits
\newcommand{\limN}{\lim_{N\rightarrow\infty}}
\newcommand{\limn}{\lim_{n\rightarrow\infty}}
\newcommand{\limk}{\lim_{k\rightarrow\infty}}
\newcommand{\limt}{\lim_{t\rightarrow\infty}}
\newcommand{\limT}{\lim_{T\rightarrow\infty}}
\newcommand{\limhz}{\lim_{h\rightarrow 0}}

% Shorter integrals: ``Integral from X to Y''
% - intXY is equivalent to \int^Y_X
\newcommand{\intab}{\int_a^b}
\newcommand{\intzN}{\int_0^N}

% Check and x symbols
\usepackage{pifont}
\newcommand{\cmark}{\text{\ding{51}}}
\newcommand{\xmark}{\text{\ding{55}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BODY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}
\maketitle

\tableofcontents


\clearpage
\section{Causality and Exogeneity}

Model
\begin{align*}
  y_n
  = \bsx_n'\bsbeta + \varepsilon_t
\end{align*}
Note that $\bsx_n$ could potentially contained lagged $y_n$. But that
limits whether or not a particular assumption is reasonable for time
series.
\begin{table}[htbp!]
\centering
\begin{tabular}{c|lcccc}
    &
    & Implies
    & Justifies
    & Consistency \&
    & Reasonable for
  \\
  $\bsx_t$ is\dots
    & Defining Feature
    & $\E[\varepsilon_t\varepsilon_{s}]=0$
    & GLS
    & Asymptotic $\calN$
    & Time Series
  \\\hline\hline
  Strictly Exogenous
    & $0=\E[\varepsilon_t|\{\bsx_s\}_{s=-\infty}^\infty]$
    & \xmark
    & \cmark
    & \cmark
    & \xmark
  \\
  Predetermined
    %& $0=\E[\varepsilon_t|\{\bsx_s,y_{s-1}\}_{s=-\infty}^t]$
    & $0=\E[\varepsilon_t|\{\bsx_s\}_{s=-\infty}^t]$
    & \cmark
    & \xmark
    & \cmark
    & \cmark
  \\
  Weaker Predetermined
    & $0=\E[\varepsilon_t\bsx_t]$
    & \xmark
    & \xmark
    & \cmark
    & \cmark
\end{tabular}
\end{table}

Weaker predetermined is used in Hayashi.

Strict exogeneity Generally impossible when $\bsx_n$ has lagged $y_n$ in
it.  Hence, generally not imposed in models with AR structure.
Mostly imposed when $y_n$ and $\bsx_n$ completely distinct

Predetermined and exogeneity are different. One does not imply the
other.
But if already assumping absence of serial correlation, then strict
exogeneity is stronger and does imply predetermined.
But no need to assume that for strict exogeneity.


\clearpage
\section{Market Demand Models}

\begin{comment}
Demand for differentiated products
==================================
- Why we care about the demand system
  - Measuring market power of sellers
  - Measuring welfare
  - Understanding price effects of mergers
  - Understanding which new prices might enter the market
  - Understand how new products affect prices, welfare

- Supply Side
  - We care about this bc we almost always assume that *prices* we
    observe are the outcome of a nash equilibrium in prices (Bertrand
    game)
  - Each firm maximizes profits by setting price, taking as given
    - Demand curve for its products (as a fcn of price)
    - Cost function for producing a certain quantity
  - The FOC imply a pricing function that says

      price = f(mc, markup)

    where markups are related to demand elasticities.
  - Thus given an estimated demand system (i.e. estimated elasticities)
    we can invert the pricing function to recover marginal costs
  - Of course, to estimate the demand system, we need IVs (typically
    cost-shifters) to estimate the system (i.e. price elasticities).
    That's the tough part
  * Note: elasticities depend upon prices. Typically not a problem for
    estimation, but is a problem for counterfactuals

- Demand Side
  - Product Space vs. Char Space (Lancaster 1966, McFadden 1973).
    - Benefits vs. drawbacks
  - Product space: estimate aggregate q(p,y)
    - Models include
      - Linear Expenditure (Stong, 1954): Building block
      - Rotterdam (Theil 1965, Barten 1966)
      - Translog (Christensen, Jorgensen, Lau 1975)
      - AIDS (Deaton and Muellbauer, 1980)
    - Problems/difficulties
      - High dimension with many products
      - Too often, instruments do not vary enough at product level and
        are highly colinear
      - Estimate of *aggregate* demand in rep agent framework, so
        ignores consumer heterogeneity
    - How to solve these problems:
      - Aggregate products into groups and different levels,
        solves dimensionality
      - Symmetry assumption for products: Dixit Stiglitz CES, so only
        one parameter to estimate (but super counterfactual)
      - Logit demand: Good for questions that deal with the optimal
        number of products or optimal variety
    - AIDS specifics
      - Divide product into subgroups, allow flexibility w/in subgroups
      - Key assumptions to justify theoretically this practical approach
        to demand estimation
        - Preference separability: U(q) = f(u1(q(1)),...,un(q(n)))
        - Multi-stage budgeting: Consumers allocated total expenditure
          in stages to different subgroups
      - Sufficient conditions for those two assumptions
        - Indirect utility for *each* segment of generalized Gorman
          Polar Form:

              v_i(p,y_i) = (y_i - f_i(p)) / g(p)

          v_i: indirect utility for agent i given prices p, income y_i.
          f_i: Expenditure necessary to reach utility level
          g(): Price index that is the same for all i
        - Overall utility *additively separable* in sub-utilities
        - For any level, estimate demand for product i in segment g

            wi = ai + bi*log(yg/Pg) + sum_j gamij log(pj) + ei

          wi: Within segment g expenditure share on product i
          yg: Total expenditure on segment g
          Pg: price index for segment g
          pj: Price for product j
        - Price indices
          - Stone log price index: Pg = sum_j wj log(pj)
          - Deaton and Muellbauer exact price index

            Pg = a0 + sum_j aj pj + (1/2)sumj sumk gamjk*log(pj)*log(pk)

    - Hausman Example
      - Stages: Whole market, market segments, individ products
      - Bottom level: AIDS
      - Middle level: AIDS or log-log

          log qg = ag + bg log(y) + sum delgh log(Ph) + eg

        Neither fully consistent with theory
      - Highest level: log-log

          log q = a + b log(y) + del log(P) + Z*gam + e
      - Note: No corner solutions--each consumer buys some of each good
      - Need to classify some products beforehand
    - Hausman, Leonard, Zona (1994)
      - Beer Market
        - Upper level: Light, premium, popular pirce
        - Lower level: Five brands within each segments
      - Idea: There is some underlying pricing model like

          log p_jct = a_jc + log c_jt + om_jct

        a_jc: Product-city FE (city's preference for a brand)
        c_jt: Product-time cost shifter (constant *across cities*)
        om_jct: Absorb supply and demand shocks

        *Exploit variation in *price of same brand*, *across cities*
        *Note: because c_jt fixed across cities, any variation that is
          common across cities will mechanically be attributed to
          supply/c_jt---NOT demand through om_jct.
          Bad assumption if national add campaign?
\end{comment}

\begin{comment}
  - Characteristic space: Products are bundles of chars
    - Theory:
      - Price competition, taking products as given
      - Comp in product space with or without subsequent price comp
    - Empirics: Only do the former, latter Sweeting ECMA 2013 new
    - Common instrument: Product characteristics
      - inefficient
      - Probably inconsistent
    - Common approach:
      - Heterogeneous individuals
      - Discrete choice (i.e. choose one product)
      - Aggregate up, so diemand depends on distribution of
        heterogeneous attributes
    - Theory Model undergirding Discrete-Choice Models
      - J products in a market, agent chooses one or outside good

          max_j,z U_i(x_j,z)  s.t. y_i = p_j + p_z*z

        x_j: characteristics of j
        p_j: price
        y_i: income
        z:   Quantity of outside good
      - Use budget constraint to write choice of z out of problem,
        writing as max over conditional indirect utility function

          max_j U_ij = max_j U_i(x_j, (y_i-p_j)/p_z)
      - Agent chooses j to maximize this utility, i.e. takes whichever j
        maximizes U_ij. Thus we can lay down a model for U_ij directly

    - Metrics:
      - Conditional Indirect Utility: U_ij = U(X_j, p_j, v_ij; theta)
      - Then augment with error unobserved by econometrician

          U_ij* = U_ij + e

        Distribution of e determines consumer i's choice probs, i.e.
        consumer i's demand function
      - Examples:
        - Two goods: j=0,1,2

            U_ij = delj + e_ij      U_i0 = 0

        - Hotelling: Pure horizontal

            U_ij = ubar + (y_i-p_j) - theta d^2(x_j,v_i)

        - Pure Vertical

            U_ij = del_j - vi*pj      vi > 0

          For all products bought in positive quantities, ordering by
          price p_j *same* as ordering by quality del_j.

          Higher price -> higher quality del_j

          So wlog, sort products by price/quality

          Agent chooses product j iff

            del_j - v_i * p_j > del_j+1 - v_i * p_j+1
            del_j - v_i * p_j > del_j-1 - v_i * p_j-1

          Can solve to get that that i chooses j iff

            (del_j+1 - del_j)/(p_j+1-p_j) < v_i < (del_j - del_j-1)/(p_j-p_j-1)

          Hence cutoff points for elasticities determine which products
          chosen. Given a distribution for v_i, can use that CDF to
          compute market share

          ***Model implication: Cross-price elasticities for product j
          are ZERO, except for the neighboring j-1 and j+1 products


        - Logit:

            U_ij = ubar + (y_i-p_j) + delta_j + e_ij

          where del_j = f(x_j, p_j, xi_j)


      - Generally, two main classes: depending on whether there is an
        epsilon or not.

        Matters because with eps_ij, product space *never* exhausted.
        Each new product comes with a new set of eps_ij that, for large
        enough sample, allow the product to deliver high utility for
        *someone* so that the person chooses it, guaranteeing the
        product positive market share and some market power

        The two classes:
        - Sans eps: For f_y>0, f_p<0, f_yp >= 0
          - Pure Hedonic (Berry and Pakes 2007):

              U_ij = f(y_i,p_j) + del_j + sum_k b_k * x_jk * v_ik

          - Ideal Type (Anderson, de Palma, Thisse 1992)

              U_ij = f(y_i,p_j) + del_j + sum_k a_k (x_jk - v_ik)^2

        - Cum eps (BLP 1995): Used to reconcile the model with the data.
          Without, often no way to fit everything. Like sticking in an
          error term in OLS even when we think relationship is linear

            U_ij = f(y_i,p_j) + del_j + sum_k b_k * x_jk * v_ik + eps_ij

          which retains logit as a special case

        Instruments: Assume X *exogenous* so use
        - Cost shifters
        - Functions of X likely to be correlated with markups

    - Logit model: U_ij = del_j + eps_ij where del_j = f(x_j,p_j,xi_j)
      - Analytic expression in terms of del_j terms
      - Further restriction: McFadden
        - del_j = x_j*b - a*p_j + xi_j
        - Then can rearrange market share equation to get linear form

            del_j = log(s_j) - log(s_0)
                  = x_j*b - a*p_j + xi_j

          which is a useful linear form
        - Can use FE to get rid of xi_j
        - Can instrument for prices using standard IV procedures
      - Problems: own and cross price elasticities
        - Own-price: Increasing in absolute value, but really people who
          buy more expensive products probably *less* sensitive to price
        - Cross-price: Depends only on market shares and prices, NOT
          similarities between goods. IIA?
        *All of function of the lack of heterogeneity
      - xi_j introduces potential endogeneity of prices.
        Often assume E[xi_j|X]=0 and built instruments from that.
        But maybe problematic

    - Nested Logit model: Relaxes IIA by grouping products
      - Model given by

          U_ij = del_j + zeta_{ig}(sig) + (1-sig)*eps_ij

        where zeta_ig(sig) common to all products in nest g.
        As sig -> 0, standard logit
        As sig -> 1, only nests matter

      - Assume that zeta_ig(sigma) ~ s.t. entire term

          zeta_{ig}(sig) + (1-sig)*eps_ij

        is EV so we get back standard logit formulas

      - Example nesting: Outside good in one nest, rest in other nest.
        Yields linear equation

          log(s_j) - log(s_0) = x_j*b - a*p_j + sig*log(s_{j/g}) + xi_j

        Instrument for prices and s_{j/g}

    - BLP, aka Random Coefficients, Mixed Logit, Heterogeneous Logit
      - Generalizes logit model from b to bi

          U_ij = ( x_j*b_i - a*p_j + xi_j ) + eps_ij
          b_i  = b + Sigma*v_i

        so then

          U_ij    = delta_j + v_ij
          delta_j = x_j*b - a*p_j + xi_j      Mean utility for brand j
          v_ij    = x_j Sigma v_i + eps_ij

        xi_j and eps_ij not observed by econometrician, only consumer.
        Former probably correlated with price p_j, maybe char X_j

        So like logit, but residual term v_ij *no longer* iid, so
        consumers who like one product more likely to like similar
        products

      - Need to be able to invert and write del(s), i.e. del as a
        function of shares, rather than just s(del) (shares as a
        function of delta). Can then write GMM moment conditions

        In earlier models, done analytically. In BLP, must do
        numerically, conditional on nonlinear model params, i.e. Sigma.
        Given that, can spec moment conds. But also need moment conds to
        identify Sigma params too

        Also need to simulate shares

      - Two step estimator:
        - GMM objective function is
        - Inverson to Recover Deltas: Given observed shares and guesses
          for del and Sigma, can set up system of J+1 eqs in the dels

            s_j = s_j(del0, ..., del_J)

          where LHS is data and RHS is simulated from model, given Sigma
          and taking draws of v_i

        - Assume instrument Z s.t. E[xi*Z] = 0 where xi = del-X*b-a*p
          under *true* params a,b
        - Construct sample version of that moment
        - Estimate a,b by minning that sample criterion function
        - BUT, that depends on delta which we don't know -> TWO STEPS
        - Invert this system to get the dels, which can be used to calc
          the above sample criterion function

      - Algo
        - Fix theta2
        - Kick around delta until shares equated
        - Given delta, compute xi
        - Given xi, form GMM objective function, which depends on whole
          vector theta
        - Kick around theta untily you minimize the objective function

      - Suppose we had s^{-1}, the inverse shares which returns delta as
        a function of theta2. Ignore the fact that we need to compute
        the deltas numerically; just assume we have an analytical
        expression. Algo steps
        - Form xi = s^{-1}-x*b - a*p
        - Find instruments for xi
        - Write GMM objective function
\end{comment}


\begin{prop}
\emph{(Motivation: Consumer Optimization)}
Want to get to the indirect utility functions (over characteristics)
that we use for estimation, from a basic utility maximization over
quantities of the goods consumed, subject to some BC.
\end{prop}


\begin{prop}
Start with general consumer preferences given by continuous utility
function
\begin{align*}
  U(Q_0,Q_t)
  \qquad\text{where}\quad
  \begin{cases}
    Q_0 & \text{Amount of numeraire consumed} \\
    Q_t &
    \text{Amount of inside good consumed---one of the $J$ options}
    \\
  \end{cases}
\end{align*}
Let $f$ be a function such that $f'>0>f''$ and
\begin{align*}
    f(Q_t) = x_{jt}\beta_i + \xi_{jt} + \varepsilon_{ijt}
\end{align*}
Special cases:
\begin{itemize}
  \item Quasilinear, $U(Q_0,Q_t)=f(Q_t)+Q_0$:
    (conditional) indirect utility is then
    \begin{align*}
      u_{ijt}
      = \alpha_i (I_i-p_{jt}) + x_{jt}\beta_i + \xi_{jt} +
      \varepsilon_{ijt}
    \end{align*}
  \item Cobb-Douglass, $U(Q_0,Q_t)=Q_0^\alpha f(Q_t)^{1-\alpha}$
    (conditional) indirect utility is then
    \begin{align*}
      u_{ijt}
      = \alpha \ln(I_i-p_{jt}) + x_{jt}\beta_i + \xi_{jt} +
      \varepsilon_{ijt}
    \end{align*}
\end{itemize}
From latter case, we see why the argument to indirect utility is
$I_i-p_{jt}$ rather than $p_{jt}$ alone.
\end{prop}


\clearpage
\begin{defn}
(General Discrete Choice Model in Characteristics Space)
Products are bundles of characteristics, and agents in any given market
choose a single product.
The ultimate choice is determined by the indirect utility function,
denoted most generally by
\begin{align*}
  u_{ijt}
  =
  U(x_{jt},\xi_{jt},I_i-p_{jt},D_{it},v_{it};\theta)
  + \varepsilon_{ijt}
\end{align*}
where
\begin{itemize}
  \item $u_{ijt}$:
    Utility for individual $i$ when choosing product $j$
    in market $t$
  \item $x_{jt}$: Observed product characteristics
  \item $\xi_{jt}$: Unobserved product characteristics.
    Worry about correlation with price.
    Acts as a residual, soaking up everything about the product we
    don't/can't explain by characteristics and can be used to reduce the
    dimension when many characteristics.
  \item $I_i-p_{jt}$: Income less price. It's this difference that
    matter, which is why write $I_i-p_{jt}$ as the argument, rather than
    $I_i$ and $p_{jt}$ separately. Only in particular special cases can
    we separate things out (like the quasilinear case below); in others,
    not.
  \item $D_{it}$: Observed consumer attributes (like demographics).
    Often have the distribution from something like CPS
  \item $v_{it}$: Unobserved consumer attributes.
    Often assume particular distribution like normal.
  \item $\varepsilon_{ijt}$: iid error term that reflects the
    econometrician's ignorance, i.e. imperfect specification and
    observation of
    $U(x_{jt},\xi_{jt},I_i-p_{jt},D_{it},v_{it};\theta)$,
    which forces us to put an error term $\varepsilon_{ijt}$ into the
    model to plug the gap between model and data.
\end{itemize}
Thus model-predicted market share of produt $j$ in market $t$ is given
$\theta$ is
\begin{align*}
  \sigma_{jt}(\theta)
  &=
  \E_{D_{it},v_{it},\varepsilon_{ijt}}
  \big[
    \mathbf{1}\{u_{ijt}>u_{ikt}\;\text{for all other $k$}\}
  \big]
\end{align*}
A market is defined as that grouping such that, within $jt$, the terms
$(x_{jt},p_{jt},\xi_{jt})$ don't vary.
Those are allowed to vary only \emph{across} markets, by assumption.
\end{defn}





\begin{defn}
(Special Case: Random Coefficient, a.k.a.\ Mixed Logit, a.k.a.\ BLP
Model)
This is a particular specification of the indirect utility function.
\begin{align*}
  u_{ijt}
  &= x_{jt}\beta_i + \alpha_ip_{jt} + \xi_{jt} + \varepsilon_{ijt} \\
  \qquad\text{where}\quad
  \begin{pmatrix}
    \alpha_i \\ \beta_i
  \end{pmatrix}
  &=
  \begin{pmatrix}
    \alpha \\ \beta
  \end{pmatrix}
  + \Pi D_{it} + \Sigma v_{it}
\end{align*}
Can rewrite in terms of mean indirect utility $\delta_{ijt}$ with
market-specific $\delta_{jt}$ and person-specific deviation from that
mean utility $\mu_{ijt}$ (plus error due to the econometrician's
ignorance):
\begin{align*}
  u_{ijt} &=
  \underbrace{%
    x_{jt}\beta + \alpha p_{jt} +\xi_{jt}
  }_{\delta_{jt}=\delta(x_{jt},p_{jt},\xi_{jt};\theta_1)}
  +
  \underbrace{%
      \begin{pmatrix}
        p_{jt} & x_{jt}
      \end{pmatrix}
      \begin{pmatrix}
        \Pi D_{it} + \Sigma v_{it}
      \end{pmatrix}
  }_{\mu_{ijt}=\mu(x_{jt},p_{jt},D_{ii},v_{it};\theta_2)}
  +\varepsilon_{ijt}
\end{align*}
The key difference relative to the logit model is the introduction of
nonzero $\mu_{ijt}$, which captures the \emph{interaction} of
characteristics and consumer attributes (including observed demographics
$D_{it}$ and unobserved attributes $v_{it}$).
In the logit model, $\mu_{ijt}=0$ by assumption.

The tough part, when we have market-level data only (not
consumer-level), is estimation of $\theta_2=(\Pi,\Sigma)$---the
parameters governing hterogeneity---since we don't observe individual
choices \emph{within} $jt$.
However, we can still estimate/identify $\theta_2$ because we observe
different markets $t$, and those markets have different distributions
of consumer attributes.
That variation in the distribution of consumer attributes across markets
helps us identify $\theta_2$.

With consumer-level data, we have multiple observations with $\xi_{jt}$
held fixed and use the variation we see in demographics across people.
With market-level data, no such luck.
\emph{But}, we do see different markets with different distributions of
characteristics, although the $\xi_{jt}$ are \emph{also} changing across
these markets.
\end{defn}


\begin{comment}
\begin{defn}
(Special Case: Linear Mixed Logit Model, EVI Errors, No Unobserved
Consumer Heterogeneity)
In that case
\begin{align*}
  P[y_{it}=j|D_{it},x_t,p_t,\xi_t;\theta]
  &=
  P[y_{it}=j|D_{it},x_t,p_t,\xi_t;\theta]
\end{align*}
\end{defn}



\paragraph{Estimation with Consumer-Level Data}
For simplicity, suppose that $\Sigma=0$ so that we have model
\begin{align*}
  u_{ijt} &=
  \underbrace{%
    x_{jt}\beta + \alpha p_{jt} +\xi_{jt}
  }_{\delta_{jt}=\delta(x_{jt},p_{jt},\xi_{jt};\theta_1)}
  +
  \underbrace{%
      \begin{pmatrix}
        p_{jt} & x_{jt}
      \end{pmatrix}
      \begin{pmatrix}
        \Pi D_{it}
      \end{pmatrix}
  }_{\mu_{ijt}=\mu(x_{jt},p_{jt},D_{it},v_{it};\theta_2)}
  +\varepsilon_{ijt}
\end{align*}
Further suppose that $\varepsilon_{ijt}$ are EV Type I distributed.
Can then estimate in two steps:
\begin{enumerate}
  \item By assuming that $\varepsilon_{ijt}$ are EV Type I distributed,
    \begin{align*}
      P[y_{it}=j|D_{it},x_t,p_t,\xi_t;\theta]
      &=
      P[y_{it}=j|D_{it},,x_t,p_t,\delta_{jt};\theta]
      \\
      &=
      \frac{%
        \exp\big\{
          \delta_{jt}+
          (p_{jt} \; x_{jt})
          \Pi D_{it}
        \big\}
      }{%
        1+
        \sum_{k=1}^J
        \exp\big\{
          \delta_{kt}+
          (p_{kt} \; x_{kt})
          \Pi D_{it}
        \big\}
      }
    \end{align*}
    From this, we can estimate $\delta_{jt}$ terms and $\Pi$.

    \paragraph{$\Pi$ Identification}
    Parameter $\Pi$ is identified via variation in $D_{it}$ holding
    $\delta_{jt}$ fixed. In other words, variation in
    demographics/characteristics \emph{holding fixed} product-market
    attributes.

    \paragraph{$\Sigma$ Identification}
    In the more complex case with $\Sigma\neq 0$, that matrix is
    identified from within market share variation in choice
    probabilities, i.e. holding market share fixed?


  \item
    We know that
    \begin{align*}
      \delta_{jt}=x_{jt}\beta + \alpha p_{jt}+\xi_{jt}
    \end{align*}
    So given $\delta_{jt}$ estimates from step 1, recover $\beta$ and
    $\alpha$.

    Note: since we expect $p_{jt}$ and $\xi_{jt}$ to be correlated, need
    an IV for prices or an assumption about the panel/autocorrelation
    structure of $\xi_{jt}$ for identification/estimation.

    \paragraph{$\theta_1$ Identification}
    This is identified from variation across markets
\end{enumerate}
\end{comment}


\clearpage
\paragraph{Estimation with Market-Level Data}
Recall our starting point:
\begin{align*}
  u_{ijt} &=
  \underbrace{%
    x_{jt}\beta + \alpha p_{jt} +\xi_{jt}
  }_{\delta_{jt}=\delta(x_{jt},p_{jt},\xi_{jt};\theta_1)}
  +
  \underbrace{%
      \begin{pmatrix}
        p_{jt} & x_{jt}
      \end{pmatrix}
      \begin{pmatrix}
        \Pi D_{it} + \Sigma v_{it}
      \end{pmatrix}
  }_{\mu_{ijt}=\mu(x_{jt},p_{jt},D_{ii},v_{it};\theta_2)}
  +\varepsilon_{ijt}
\end{align*}
We'd naturally think to estimate this model's parameters by choosing
$\theta$ such that model-predicted $\sigma_{jt}(\theta)$ matches the
observed market shares $s_{jt}$.
However, as mentioned, $\sigma_{jt}(\theta)$ involves $\xi_{jt}$, which
worry about being corellated with price $p_{jt}$.
Therefore, we need some IV approach, and it's not clear how to
formulate/accomplish that by just minimizing the distance between
$s_{jt}$ and $\sigma_{jt}(\theta)$.
Moreover, $\sigma_{jt}(\theta)$ is super nonlinear, despite the utility
representation looking very linear for a given individual.
So maybe we can help our estimation by exploiting linearity somehow.

All this suggests finding a proper orthogonality condition for the
model, so we do GMM estimation.
To start, suppose that we have vector of instruments $z_{jt}$ such that
\begin{align*}
  0 = \E[\xi_{jt}z_{jt}]
  = \E[(\delta_{jt}-x_{jt}\beta-\alpha p_{jt})z_{jt}]
\end{align*}
Often, $z_{jt}=(x_{jt}'\,\tilde{z}_{jt})'$ where $\tilde{z}_{jt}$ is an
scalar instrument for price.
Conditional on $\delta_{jt}$, that's enough moment conditions to
identify $(\alpha \beta')'$.
Of course, the above moment condition isn't immediately and obviously
useful because we \emph{don't} know $\delta_{jt}$, and that \emph{also}
depends on parameters. So we need some way to estimate $\delta_{jt}$ and
more moments to identify the $\theta_2$ parameters which determine
$\delta_{jt}$.

The big BLP innovation is to note/prove that, under weak conditions, we
can invert (numerically) the model's share equation
$\sigma_j(\delta_t,x_t,p_t;\theta_2)$ to find the $\delta_t$
that equates model $\sigma_j(\delta_t,x_t,p_t;\theta_2)$ to
observed shares $s_t$.
Thus we can write
\begin{align*}
  \delta_{jt}=\sigma_{jt}^{-1}(s_t,x_t,p_t;\theta_2)
\end{align*}
Then we can rewrite the above moment condition as
\begin{align*}
  0
  = \E[(\sigma_{jt}^{-1}(s_t,x_t,p_t;\theta_2)-x_{jt}\beta-\alpha p_{jt})z_{jt}]
  = \E[\xi_{jt}(\theta)z_{jt}]
\end{align*}
But of course, that's not enough to to identify all the parameters,
$z_{jt}$ is not large enough. We need to add more instruments to get to
$Z_{jt}$, which has enough to identify $\theta_2$ as well. Then we have
\begin{align*}
  0
  = \E[(\sigma_{jt}^{-1}(s_t,x_t,p_t;\theta_2)-x_{jt}\beta-\alpha p_{jt})Z_{jt}]
  = \E[\xi_{jt}(\theta)Z_{jt}]
\end{align*}
Thus instruments play two roles:
\begin{itemize}
  \item Generate moments to identify consumer-level parameters
    $\theta_2$.

    Unlike with consumer data (where we have multiple observations
    within a $jt$ to identify individual-level parameters), we don't
    have that here.
    Here we don't have that and must use the instruments to identify the
    parameters $\theta_2$.

    Very clear in nested logit example

  \item Deal with correlation of prices and errors
\end{itemize}


\clearpage
Ideal experiment: randomly vary prices, characteristics, and product
characteristics. See where consumers switch. IVs try to mimic that.
Sources of IVs:
\begin{itemize}
  \item Supply-side information (BLP)
  \item Many markets, $T$ large, lots of variation in demographics
    and product choices across those markets (Nevo)
  \item Micro-moments/information (MicroBLP)
\end{itemize}
Price approximately equals marginal cost plus markup.
So look for things that are exogeneous which impact marginal cost or
markup.
\begin{itemize}
  \item
    Characteristics-based Instruments:
    Assume $\E[\xi_{jt}|x_t]=0$ where $x_t$ is across
    \emph{all} products.\footnote{%
      This make sense if we assume $x_{jt}$ set before $\xi_{jt}$.
    }
    Can then take as an instrument \emph{any} function of $x_t$.
    BLP proposed the following:
    \begin{itemize}
      \item Own characteristics
      \item Average characteristics of other products produced by
        \emph{same} firm
      \item Average characteristics of products produced by
        \emph{competitors}
    \end{itemize}
    Latter two (proximity of given product to others) affects markup
    term, affects price.
    As you move across markets $jt$, competition in the form of
    different products with different characteristics \emph{vary}, which
    affect markup.

  \item Cost-based Instruments:
    These instruments affect marginal costs, which shifts price
    \begin{itemize}
      \item
        Assume $\E[\xi_{jt}|w_t]=0$ where $w_t$ includes characteristics
        (not in $x_t$ since we already built moments from them) that
        enter cost side only, but \emph{not} demand side.
        Then $\xi_{jt}$ is independent of $w_t$, allowing us to form
        instruments as functions of $w_t$.

      \item Price of inputs for each company, interacted with product
        dummies to generate variation by product within the same company

      \item Indirect measures of cost

        Example: Prices of the product in \emph{other} markets, e.g.
        price of cereal in Portland as instrument for price of cereal in
        Boston.

        Validity argument: after controlling for common effects for the
        product (common Cheerios effect), assume everything left over in
        $\xi_{jt}$ after controlling for these things is independent across
        markets.
        (Not valid if regional coordination between Boston and Maine prices)

        Example: local product managers who don't coordinate, so after
        controlling for the Cheerios effect, the price in Portland reflects
        the efforts of marketing manager in Portland, which is independent
        of price in Boston.
        It has identification power because marginal cost of producing
        Cheerios is common across markets, hence prices are correlated
        across markets by ``price equals MC plus markup.''
    \end{itemize}

  \item Dynamic panel:
    Assume $\xi_{jt}=\rho \xi_{jt-1}+\eta_{jt}$, moment condition
    $\E[\eta_{jt}|x_{t-1}]=0$.
\end{itemize}
Nested logit is a special case of RC, where characteristics are
\emph{segment dummies} with a \emph{very particular} distribution on
those dummies.

Connect elasticities to markups via Bertrand pricing model.
That's where all the implied markups come from.
Supply side side, where we can back out markup.


\clearpage
$\xi_{jt}$ is econometrically a residual that ensures observed market
share equals model market share.
Since only $\delta_{jt}$ (not $\mu_{ijt}$) is a \emph{linear} function
of $\xi_{jt}$ (so that $\xi_{jt}$ is effectively just an error term),
that's equivalent to playing around with $\delta_{jt}$ until observed
market share equals model market share.
And under weak conditions, we can invert the share relationship to write
$\delta_{jt}$ as a function of observed shares, characteristics, prices,
and $\theta_2$ (individual characteristic parameters).
Then once we have $\delta_{jt}$, which is a linear function of
$\xi_{jt}$ which acts like a residual, we can form a moment condition
and effectively regress $\delta_{jt}$ on $jt$-specific variables to
recover $\xi_{jt}$ and identify parameters.

Algo
\begin{itemize}
  \item Develop function mapping $(\delta_t,\theta_2)$ into shares:
    $\sigma_j(\delta_t,x_t,p_t;\theta_2)$.

    Assume that $\varepsilon_{ijt}$ so that things are in logit form,
    then compute $\sigma_j$ from expectation via simulation, drawing
    $(D_{it},v_{it})$ from some distribution

  \item Given a guess for $\theta_2$, search for $\delta_2$ such that
    $\sigma_j=s_j$, using the function from the first step.

    Do this by contraction mapping

  \item
    Use computed $\delta_t$ to compute $\xi_{jt}$ and form the GMM
    objective function as a function of total $\theta$.
    In particular, form error term $\xi_{jt}(\theta)$ as
    inverse share less $x_{jt}\beta_+\alpha p_{jt}$.

  \item Search for $\theta$ that minimizes objective function
\end{itemize}
Identification
\begin{itemize}
  \item Ideal experiment: Randomly vary prices and characteristics, see
    what people buy/switch to
  \item Instruments are trying to mimic this
\end{itemize}



\clearpage
\subsection{Sketch Notes}

\subsubsection{Simple Example}

\paragraph{Model}
Random utility
\begin{align*}
  u_{ijt}
  &=
  x_{jt}'\beta
  - \alpha p_{jt}
  + \xi_{jt}
  + \varepsilon_{ij}
\end{align*}
where
\begin{itemize}
  \item $i=1,\ldots,I$ agents
  \item $t=1,\ldots,T$ markets
  \item $j=1,\ldots,J$ products
  \item $x_{jt}$ vector, product $j$ characteristics
  \item $p_{jt}$ price of $j$ at $t$
  \item $\xi_{jt}=\xi_j + \xi_t + \Delta \xi_{jt}$,
    represents unobserved characteristic of $j$ slash demand shock at
    $t$ for $j$ slash measurement error in the price.
    Permanent component for product $j$ is $\xi_j$.
    Common shock at $t$ is $\xi_t$.
    Product-time specific shock for $j$ is $\xi_{jt}$.
  \item $\varepsilon_{ij}$ some logit error term
\end{itemize}
By logit error $\varepsilon_{ij}$, this multinomial choice problem
(determined by the random utilities $u_{ijt}$) implies market shares
$s_{jt}(x,\beta,\alpha,\xi)$ that we can match to true market shares
$S_{jt}$:
\begin{align*}
  S_{jt} = s_{jt}(x,\beta,\alpha,\xi)
  =
  \frac{%
    \exp(x_{jt}'\beta - \alpha p_{jt} + \xi_{jt})
  }{%
    \sum_{j'=1}^J \exp(x_{j't}'\beta - \alpha p_{j't} + \xi_{j't})
  }
\end{align*}
Normalize utility of outside good $j=0$ to zero, $u_{i0t}=0$, which
implies
\begin{align*}
  s_{0t}(x,\beta,\alpha,\xi)
  &=
  \frac{%
    \exp(0)
  }{%
    \sum_{j'=1}^J \exp(x_{j't}'\beta - \alpha p_{j't} + \xi_{j't})
  }
  \\
  -
  e_t
  :=
  \log
  s_{0t}(x,\beta,\alpha,\xi)
  &=
  -
  \log\left(
    \sum_{j'=1}^J \exp(x_{j't}'\beta - \alpha p_{j't} + \xi_{j't})
  \right)
\end{align*}
So then
\begin{align*}
  \log(s_{jt}(x,\beta,\alpha,\xi))
  &=
  x_{jt}'\beta - \alpha p_{jt} + \xi_{jt}
  + e_t
  \\
  \implies\quad
  \log(s_{jt}(x,\beta,\alpha,\xi))
  -
  \log(s_{0t}(x,\beta,\alpha,\xi))
  &=
  x_{jt}'\beta - \alpha p_{jt} + \xi_{jt}
\end{align*}
Note that we have data on the LHS, $S_{jt}-S_{0t}$.


\clearpage
\paragraph{Estimation}
Want to estimate regression
\begin{align*}
  S_{jt}-S_{0t}
  &=
  x_{jt}'\beta - \alpha p_{jt} + \xi_{jt}
\end{align*}
Approaches
\begin{itemize}
  \item
    Regression, but worried about correlation between $p_{jt}$ and
    $\xi_{jt}$
  \item
    Estimate FE model
    \begin{align*}
      S_{jt}-S_{0t}
      &=
      x_{jt}'\beta - \alpha p_{jt}
      + \xi_{j}
      + \xi_{t}
      + \Delta \xi_{jt}
    \end{align*}
    Better, but still worried about correlation between $p_{jt}$ and
    $\Delta \xi_{jt}$.
    Also worried about colinearity between $\xi_j$ and $x_{jt}$ if
    characteristics are time-invariant.

  \item
    Instruments.

    Supply shifter, i.e. something that changes costs.

    Measures of isolation in product space
    $z_{jtk}=\sum_{j'\neq j}x_{j'tk}$, which measures how much product
    $j$ contributes to the average of characteristic $k$.
\end{itemize}



\paragraph{Simple BLP Model}
Preferences are specified
\begin{align*}
  u(x_j,\xi_j,p_j,v_i;\theta_d)
\end{align*}
where $\theta_d$ are demand parameters.
In particular,
\begin{align*}
  u_{ij}
  &= x_j\beta_i - \alpha p_j + \xi_j + \varepsilon_{ij}
  \\
  \beta_{ij}
  &= \beta_k + \sigma_k \eta_{ik}
\end{align*}
where $\varepsilon_{ij}$ are logit, $\eta_{ik}$ are random, so we have
random coefficients $\beta_i$, which is the break with the pure logit
model.
Can rewrite
\begin{align*}
  u_{ij}
  &=
  \delta_j + v_{ij}
  \\
  \delta_j
  &=
  x_j\beta - \alpha p_j + \xi_j
  \\
  v_{ij}
  &=
  \sum_k  x_{jk} \sigma_k \eta_{ik}
  + \varepsilon_{ij}
\end{align*}
Let $A_j(\delta)$ given vector $\delta=(\delta_j)$ denote the set of
all error terms $v_{ij}$ consistent with $j$ being the utility
maximizing choice.
Then the model-implied market share for product $j$, conditional on the
$\delta$'s, is given by
\begin{align*}
  s_j(\delta(x,p,\xi),x,\theta)
  =
  \int_{A_j(\delta)} f(v)\;dv
\end{align*}
In words, the share for product $j$ is the probability mass associated
with $j$ being the optimal choice.
Given data $\tilde{s}_j$ on the shares,
want to pick parameters $\theta$ match match data and model-implied
shares:
\begin{align*}
  \tilde{s}_j
  =
  s_j(\delta(x,p,\xi),x,\theta)
\end{align*}
Conditional on $\theta$, $J$ equations in $J$ unknown $\xi$'s.
Of course don't know $\theta$. So have to find instrument for $\xi_j$.


Computation
\begin{itemize}
  \item Given $\sigma$ and $\delta$, compute market shares implied by
    model. Innermost step.
  \item Given $\sigma$, find $\delta$ to equate market shares, using
    contraction mapping.
  \item Given $\delta$, $\beta$, $\alpha$, form $\xi$ as residual.
  \item Form GMM moment condition, interacting $\xi$ residual with
    instruments.
    Estimate parameters via GMM.
\end{itemize}























%\clearpage
%\section{VARs}

%Three types of concepts, all distinct
%\begin{itemize}
  %\item Shock: Economically meaningful primitive exogeneous forces.
    %They have the following characteristics
    %\begin{itemize}
      %\item Exogenous with respect to other current and lagged endogenous
        %variables in the model. This is putting a finer point on
        %``primitive'' and ``exogenous''
      %\item Uncorrelated with each other so we can identify unique
        %causual effects
      %\item Represent unanticipated movements in exogenous variables or
        %news about future movements in exogeneous variables
    %\end{itemize}
  %\item Innovation: The residuals from a reduced-form VAR
  %\item Instrument
%\end{itemize}
%These three concepts are all generally distinct.
%It is only through the process of \emph{identification} that we
%link/equate innovations with the shocks

%Model
%\begin{align*}
  %Y_t
  %&= B(L)Y_t + \Omega \varepsilon_t
  %\qquad\text{where}\quad
  %\varepsilon_t \sim (0,D)
  %\\
  %B(L)
  %&= B_0 + \sum_{k=1}^p B_kL^k
%\end{align*}
%Corresponding reudced form
%\begin{align*}
  %A(L)Y_t
  %&= \eta_t
  %\qquad\text{where}\quad
  %\eta_t
  %\sim (0,\Sigma_\eta)
  %\\
  %A(L)
  %&= I-\sum_{k=1}^p A_kL^k
%\end{align*}
%Can then link reduced form innovations $\eta_t$ to the structural shocks
%$\varepsilon_t$ by rewriting
%\begin{align*}
  %(I-B_0)Y_t
  %&=
  %\sum_{k=1}^p B_k Y_{t-k}
  %+
  %\Omega \varepsilon_t
  %\\
  %Y_t
  %&=
  %\sum_{k=1}^p A_k Y_{t-k}
  %+
  %\eta_t
%\end{align*}
%From this, deduce that
%\begin{align*}
  %\eta_t
  %&=
  %(I-B_0)^{-1}\Omega\varepsilon_t
  %\\
  %\iff\quad
  %\eta_t
  %&= B_0\eta_t + \Omega \varepsilon_t
%\end{align*}

%Identification approaches
%\begin{itemize}
  %\item Triangularization/Cholesky: Impose zero restrictions
    %so that an endogenous variable does not respond to other endogenous
    %variables contemporaneously.
    %The variable ordered ``first'' responds to no other endogenous
    %variables.
    %The variable ordered ``last'' respond to everything else in the
    %system.

  %\item Nonzero restrictions, structural VAR: set a coefficient to some
    %number which is known for good theoretical reasons

  %\item Heteroscedasticity

  %\item High Frequency identification: Use daily data to isolate effect
    %of Fed announcements on rates. If you control for the Fed's
    %information set, then this is plausible identification of shock/news

  %\item
    %External Instruments/Proxy SVARs:
    %External series $Z_t$ (outside the endogenous variable vector $Y_t$)
    %is a valid instrument for identifying shock $\varepsilon_{ti}$ if
    %\begin{align*}
      %\E[Z_t\varepsilon_{ti}] &\neq 0 \\
      %\E[Z_t\varepsilon_{tj}] &= 0
      %\qquad
      %\forall j\neq i
    %\end{align*}
    %The first condition ensures relevance/usefullnes. The second
    %condition ensures exogeneity.
    %How to implement
    %\begin{enumerate}
      %\item Estimate reduced form VAR to get estimated residuals
        %$\{\hat{\eta}_t\}$
      %\item Regression $\eta_{tj}$ on $\eta_{ti}$ for $j\neq i$ using
        %$Z_t$ as the instrument.
        %These provide unbiased estimates of the ceofficients
    %\end{enumerate}

  %\item
    %Long Run Restrictions:
    %Moving average rep
    %\begin{align*}
      %Y_t = C(L)\eta_t
      %\qquad\text{where}\quad
      %C(L) = A(L)^{-1}
    %\end{align*}
    %Can write $Y_t$ as
    %\begin{align*}
      %Y_t = D(L)\varepsilon_t = C(L)H\varepsilon_t
    %\end{align*}
    %Then want to say that some shock has no effect on some variable in
    %the long run. This amounts to restricting $D^{ij}(1)=0$.
    %This can accommodate whether you want zero long run effect on level
    %or growth rate, depending on whether the variables included are
    %levels or growth rates.

  %\item Sign Restrictions

  %\item FAVARs: For including more information

  %\item DSGE
%\end{itemize}
%Jorda local projection method: For overcoming the negative effects of
%misspecification on estimated IRFs. In the usual way they are computed,
%there's a possibility that the errors would just be compounded.
%Jorda's solution is like iterated vs. direct forecasting.



\clearpage
\section{Unit Root Econometrics}






\clearpage
\section{Cochrane on Unit Roots}

\subsection{Facts about Unit Roots and Shit}

Cochrane's Time Series book has a nice little history of this
literature. He also mentiones Campbell and Perron

Random walk
\begin{align}
  y_t = y_{t-1} + \varepsilon_t
  \label{rw}
\end{align}
Spectral density of an AR(1) with $\phi\ra 1$ approaching random walk
\begin{align*}
  \lim_{\phi\ra 1}f(\omega)
  =
  \lim_{\phi\ra 1}
  \frac{\sigma^2}{1+\phi^2-2\phi \cos(\omega)}
  =
  \frac{\sigma^2}{2(1-\cos(\omega))}
\end{align*}
As $\omega\ra 0$, $f(\omega)\ra \infty$, so the spectral density is
super peaked close to $\omega=0$, i.e. at low frequency.

Random walk a special case of a unit root process. A unit root process
or difference stationary process or I(1) process generalizes the RW and
is any process
\begin{align}
  y_t &= \mu + y_{t-1} + a(L)\varepsilon_t
  \label{I1}
\end{align}
where $a(L)\varepsilon_t$ is stationary.
This is unit root because the implicit lag polynomial on $y_t$,
$(1-z)$, has a root/zero at $z=1$.

Trend stationary is special case of Model~\ref{I1}
\begin{align*}
  y_t &= \mu t + b(L)\varepsilon_t
\end{align*}
This arises when $a(L)$ in Model~\ref{I1} has a unit root that we can
factor out so that
\begin{align*}
  y_t
  &= \mu + y_{t-1} + a(L)\varepsilon_t
  \\
  (1-L)y_t
  &= \mu + (1-L)b(L)\varepsilon_t
  \\
  \iff\quad
  y_t
  &=
  \mu t
  +
  b(L)\varepsilon_t
\end{align*}
Hence, if the model is trend-stationary, it is \emph{also} I(1).
But compare what you get after first differencing the unit root and
trend stationary processes
\begin{align*}
  \Delta y_t
  &= \mu + a(L)\varepsilon_t\\
  \Delta y_t
  &=
  \mu + (1-L)b(L)\varepsilon_t
\end{align*}
In the case of Model~\ref{I1}, the $a(L)$ that remains is generally
invertible and you can get an AR rep for $\Delta y_t$.
But in the trend stationary case, the $(1-L)b(L)$ that remains is
\emph{not} invertible, so no AR rep available.

Rather than think of I(1) processes mechanically as a generalization of
the random walk, the game of studying these processes is figuring out
the implications for the level or long run forecast of a process.

Spectral density at frequency zero of the I(1) process is $a(1)$.
This determines the low frequency movements.
If a pure random walk, then $a(1)=1$.
If trend stationary, then $a(1)=0$.
Of course, intermediate possibilities.

By beveridge nelson, every I(1) process can be written as a sum of a RW
and a stationary process.
There are many ways to do such a decomposition but beveridge nelson is
nice.
In beveridge nelson, the random walk component today is the value if you
forecast the model forever into the future, then run back a linear
trend. The point today in that run-backward linear trend is the random
walk value.
In other words, it's the

OLS estimate of $\phi$ in the following model is downward biased
with too-tight standard errors when $\phi$ close to one:
\begin{align*}
  y_t = \phi y_{t-1} + \varepsilon_t
\end{align*}
So our $<1$ OLS estimates could actually have been generated by random
walks.

Suppose you have a random walk model and estimate it like it's something
trend stationary. This is also bad, and will lead to finding misleading
nonexistent linear trends that are actualy just random walk.

Suppose you regress a random walk on another random walk. The
coefficient estimate will be misleadingly high.



%\clearpage
%\subsection{How big is the Random Walk in GNP}

%Punchline: GNP does actually revert back to trend, but only over several
%years. So in the short run, GNP behaves like a unit root.
%So if you fit a model to the short run behavior, you will incorrectly
%infer long run persistence too that isn't actually there.

%Idea: ``Measure size of random walk component in GNP from the variance
%of its long differences.''
%Two competing models
%\begin{align*}
  %\text{Pure Random Walk:}&\quad
  %y_t
  %= bt + \sum_{j=0}^\infty a_j \varepsilon_{t-j}
  %\\
  %\text{Stationary about Trend:}&\quad
  %y_t
  %= \mu + y_{t-1} + \varepsilon_t
%\end{align*}
%Notice
%\begin{align*}
  %\text{Pure Random Walk}
  %\quad&\implies\quad
  %\Var(y_t-y_{t-k})
  %= k\sigma^2_\varepsilon
  %\\
  %\text{Stationary about Trend}
  %\quad&\implies\quad
  %\Var(y_t-y_{t-k})
  %= 2\sigma^2_y
%\end{align*}
%Can also form variance ratio
%\begin{align*}
  %R
  %&= \frac{\Var(y_t-y_{t-k})/k}{\Var(y_t-y_{t-1})}
%\end{align*}


%\clearpage
%\section{Great Mortgaging}

%Introduce ``long-run annual-frequency dataset on disaggregated
%(mortgage vs. business) bank credit for 17 advanced economies since
%1870.''
%Growth in credit has mostly been rapid growth in mortgage lending, and
%that is robust across countries.

%Questions:
%- We see greater bank lending to households relative to businesses.
  %Does this happen in low-growth economies?
%- Maybe mortgage lending is high private return to the banks but low
  %social return because it's not investing in technology or productive
  %assets. Need a mechanism for this to happen in GE
%- Aiyagari with shocks to the borrowing limit that is below zero
%- Why was mortgage loan growth so strong \emph{then}? Has to be
  %securitization and demand for higher yielding assets.
  %But the run up is still slightly after Solomon brothers did their
  %thing.
%- Why is mortgage lending so different from nonmortgage business
  %lending? Is it the size of the balance sheet or the composition (i.e.
  %the simple fact that banks mostly do that now)?
  %We see a run up in bank loans to GDP. But really it's the composition
  %that has changed.
%- Look at banks/credit unions and lenders that differ in the amount that
  %they lend to households vs. to businesses. Are the ones that lend to
  %households more fragile?


\clearpage
\section{Jump Processes}


\begin{defn}(Cadlag Function)
A function $f:[0,T]\ra\R^d$ is \emph{cadlag} if the $f$ is
right-continuous, and the lefthand limit $\lim_{\delta \ra 0}
f(t-\delta)$ exists for any point in the domain, though this lefthand
limit need \emph{not} equal the righthand limit.
This allows for jumps.
\end{defn}
\begin{defn}(Random, Stopping, Hitting Times)
A \emph{random time} $\tau$ is a nonnegative random variable.

A \emph{stopping time} with respect to filtration $\{\sF_t\}$ is a
random time that is also $\sF_t$-measurable for all $t$, i.e.
$\{\tau\leq t\}\in\sF_t$. In effect, this means that any instant, we can
tell whether or not the event (i.e. the process stopping) has happened.

Given process $X_t$, a \emph{hitting time} $\tau_A$ is a random variable
that encodes the first time $X_t$ hits open set $A$:
\begin{align*}
  \tau_A(\omega):=\argmin_{t} X_t(\omega)\in A
\end{align*}
\end{defn}


\begin{defn}(Counting Process)
Suppose we have an increasing sequence\footnote{%
  I assume ``increasing sequence'' means $T_n\leq T_{n+m}$ for all
  $m\geq 0$, realization by realization
}
of random times $T_n:\Omega\ra\R_+$ with
$P[\limn T_n=\infty]=1$.
Define the \emph{counting process} as $\N$-valued random variable $X_t$
that counts the number of random times (i.e. number of $T_n$'s)
occurring within $[0,t]$.
\begin{align*}
  X_t
  =
  \#\{
    n
    \;|\;
    T_n\leq t,
    \qquad n\geq 1
  \}
  =
  \sumninf
  \mathbf{1}_{\{T_n\leq t\}}
\end{align*}
$X_t$ is Cadlag by construction, and also piecewise constants with jumps
of one unit.
\end{defn}


\begin{defn}(Poisson Process)
The \emph{Poisson Process} $N_t$ is a particular counting process where
each random time $T_n$ is a partial sum of iid exponential RVs:
\begin{align*}
  T_n = \sumin \tau_i
  \qquad
  \tau_i\iid \text{Exp}(\lambda)
\end{align*}
Denote this process by $N_t\sim\text{Poisson}(\lambda t)$ since
\begin{align*}
  P[N_t=n]
  =
  e^{-\lambda t}
  \frac{(\lambda t)^n}{n!}
\end{align*}
$N_t$ is the only counting process with independent and stationary
increments.
\end{defn}

\begin{defn}(Random Measure)
Given  an increasing sequence of random times $T_n:\Omega\ra\R_+$,
define \emph{random measure} $\mu:\Omega\times(\R_+,\sB(\R_+))\ra \N$ on
the natural numbers:
%The sequence $T_n:\Omega\ra\R_+$ that we used to define a counting
%process $X_t$ to count the number of points in $[0,t]$ also
\begin{align*}
  \mu(\omega,A)
  =
  \#\{
    n
    \;|\;
    T_n(\omega)\in A\in\sB(\R_+),\;\; n\geq 1
  \}
\end{align*}
This measure is \emph{random} because $\mu$ is indexed by $\omega$ in
its first argument.
And for each $\omega\in\Omega$, $\mu(\omega,A)$ gives the number of
jumps (or jump times $T_n$) in the set $A$.
Of course, since jumps are random, each different $\omega\in\Omega$
implies a different time/realization for each $T_n(\omega)$, hence a
different answer for how many jumps occurred in $A$.
%We can of course take the expectation over $\Omega$ to get
%\begin{align*}
%\end{align*}

Since the sequence of random times $\{T_n\}$ can be used to define a
corresponding counting process $X_t$, we can offer an alternative
definition of $X_t$ using the random measure $\mu$:
\begin{align}
  X_t(\omega)
  =
  \mu(\omega,[0,t])
  =
  \int_0^t
  \mu(\omega,ds)
  \label{jumprelate}
\end{align}
Thus the number of jumps of $X_t$ in interval $[s,t]$ is given by
$\mu(\omega,[s,t])$.

For every counting process, there is a corresponding jump measure, and
vice versa.
\end{defn}

\begin{defn}
Let $\mu(\omega,A)$ be the associated jump measure for Poisson process
$N_t\sim\text{Poisson}(\lambda t)$.
Since jump measure $\mu(\omega,A)$ is random, we can take it's
expectation and use Expression~\ref{jumprelate} along with
$N_t\sim\text{Poisson}(\lambda t)$
to simplify
\begin{align*}
  \E[\mu(\omega,[0,t])]
  =
  \E[N_t(\omega)]
  =
  \lambda t
\end{align*}
We can think of $\mu$ as the derivative of $N_t$ in the following sense
\begin{align*}
  \frac{dN_t(\omega)}{dt}
  &=
  \mu(\omega,[t,t+dt])
  \qquad\text{where}\quad
  \mu
  = \sum_{n=1}^\infty \delta_{T_n(\omega)}
\end{align*}
i.e. $\mu$ is the sum of Dirac measures at all jump times.
\end{defn}

\begin{defn}
Let $(\Omega,\sF,P)$ be a probability space.
Let $(\R^d,\sG)$ be a a measurable space, and $\lambda$ a positive Radon
measure on that space.
Define a \emph{Poisson random measure}
\begin{align*}
  \mu:\Omega\times(\R^d,\sG)\ra \N
\end{align*}
such that for almost all $\omega\in\Omega$,
$\mu(\omega,\cdot)$ is a $\N$-valued Radon measure on $(\R^d,\sG)$
satisfiying, for any $A\in\sG$,
$\mu(\omega,A)<\infty$ and
\begin{align*}
  P[\mu(\omega,A)=n]
  =
  e^{-\lambda[A]}
  \frac{\big(\lambda[A]\big)^n}{n!}
\end{align*}
and for any disjoint measurable sets $A_1,\ldots,A_m\in\sG$, the RVs
$\mu(\omega,A_1),\ldots,\mu(\omega,A_m)$ are independent.

Can also associated a Poisson random measure with a sequence of points
$\{X_n(\omega)\}\ninf$ in $\R^d$ such that
\begin{align*}
  \mu(\omega,A)
  &=
  \sumninf \mathbf{1}_{\{X_n(\omega)\in A\}}
  \\
  \mu
  &=
  \sumninf \delta_{X_n(\omega)}
\end{align*}
\end{defn}

\clearpage
\subsection{Levy Processes}

\begin{defn}(Levy Process)
Cadlag process $X$ on $\R^d$ with $X_0=0$, satisfying the following three
properties
\begin{enumerate}[label=(\roman*)]
  \item Independent Increments:
    For any $s<t<u$, the RVs
    $X_u-X_t$ and $X_t-X_s$ are independent.
  \item Stationary Increments:
    The distribution of $X_{t+s}-X_t$ does not depend upon $t$
  \item Stochastic Continuity:
    For all $t,\varepsilon>0$,
    $\lim_{s\ra 0} P[|X_{t+s}-X_t|>\varepsilon]=0$.

    Note that this does not mean the process $X_t$ is strictly
    continuous, or that any finite interval $[0,T]$ only has a countable
    or finite number of jumps.
    Rather it only means that jumps do not happen at deterministic
    times, and that at any given time $t$, the probability of a jump is
    zero.
\end{enumerate}
\end{defn}







\clearpage
\section{Function Spaces}


$L^p$ space is set of functions with norm
$\left(\int |f(x)|^p dx\right)^{1/p}$.

$L^2$ space is also a Hilbert space.

Orthonormal basis $\phi_1,\phi_2,\ldots$ is any sequence of functions
with norm 1 that are orthogonal
\begin{align*}
  \int^b_a \phi_j^2(x)\;dx=1
  \qquad
  \qquad
  \int^b_a \phi_j(x)\phi_k(x)\;dx=0
  \qquad
  j\neq k
\end{align*}
Example: Fourier polynomial basis, Legendre basis (orthogonalized
polynomials), wavelets




\clearpage
\section{Statistics 705}







\subsection{Likelihood Function}

Notation: $L(\theta)$ for likelihood, $\ell(\theta)$ for log-likelihood.

Result:
Suppose we have two datasets $x_{1:N}$ and $y_{1:N}$.
Say $x_{1:N}\sim y_{1:N}$ if
$L(\theta|x_{1:N})\propto L(\theta|y_{1:N})$.
This defines an equivalence class for datasets/observations.
Moreover, the partition induced by the equivalence relation $\sim$ is
the minimal sufficient partition.

Proof:
If proportional, then ratio does not depend upon $\theta$.
Then datasets obs equivalent from perspective of likelihood
maximization.
Thus we can partition data into obs equivalent buckets.
Moreover, likelihood sufficient statistic so then

Likelihood function itself is a minimal sufficient statistic.

Proof:
The ratio result above, easy.

Can I compute the likelihood from this statistic? If yes, then the
statistic is sufficient.
Hence, minimal sufficient stat is minimal amount of information you need
to construct the likelihood.


Likelihood also forms a sufficient partition of the data.
Equivalence class formed by likelihood proportional for two datasets.


\begin{defn}
(Profile Likelihood)
Suppose we can partition $\theta=(\eta',\xi')'$.
The \emph{profile likelihood} for $\eta$ is defined as
\begin{align*}
  L(\eta) = \sup_\xi L(\eta,\xi)
\end{align*}
\end{defn}

\begin{defn}(Equivariant)
If $\eta=g(\theta)$ then $\hat{\eta}=g(\hat{\theta})$ where the hat
guys are the MLE estimates.
So no matter how you parameterize things, you get the same MLE. Nice
property.
\end{defn}


Result: MLE is equivariant.
Two cases
\begin{itemize}
  \item $g(\theta)$ invertible:
    Then can write $\eta=g(\theta)$ and $\theta=g^{-1}(\eta)$.
    Define $L^*(\eta)=L(g^{-1}(\eta))=L(\theta)$.
    Then for any $\eta$,
    \begin{align*}
      L^*(\hat{\eta})
      =
      \max_\eta
      L^*(\eta)
      =
      \max_\eta
      L(g^{-1}(\eta))
      =
      \max_\theta
      L(\theta)
      =
      L(\hat{\theta})
      \geq
      L(\theta)
      =
      L^*(g^{-1}(\theta))
      =
      L^*(\eta)
    \end{align*}
  \item If $g(\theta)$ not invertible, define
    profile likelihood.
    \begin{align*}
      L^*(\eta) =
      \sup_{\theta\,:\,g(\theta)=\eta}
      L(\theta)
      L(\theta)
    \end{align*}
    Do the same steps.
    In words, suppose multiple $\theta$ map to the same $\eta$, and we
    ask what is the MLE over $\eta$?
    The value we assign to the likelihood at a given $\eta$ is now
    associated with one of the $\theta$'s such that $\eta=g(\theta)$,
    and in particular, the one that induces maximal likelihood value.
\end{itemize}












\clearpage
\section{Causal Inference}

\href{http://www.stat.cmu.edu/~larry/=stat705/Lecture17.pdf}{Reference}








\clearpage
\section{Notation}

To standardize
\begin{itemize}
  \item $N$ and $T$ for total number of observations.
  \item No bold
  \item $x_{1:N}$ or $x_{1:T}$ for dataset
  \item Always put log in front for log-likelihood
  \item Always write likelihood function without data as argument,
    except Bayesian
  \item Use ${}_0$ to emphasize true parameter.
  \item ${}_N$ to emphasize asymptotics
  \item $;$ for likelihood, except in Bayesian context where I switch to
    $|$
\end{itemize}




\clearpage
\section{Semiparametric Efficiency}

\subsection{Parametric Efficiency, Reinterpreted}
This reinterpretation of parametric efficiency will enable the jump
to semiparametric efficiency.

Setup
\begin{itemize}
  \item  $\{p_\theta(y)\}_{\theta\in\Theta}$: Parametric model where
    $\Theta$ is an open subset of $\R^k$
  \item  $\theta_0$: True parameter
  \item $\psi_0=\psi(\theta_0)$: Scalar target estimand for known
    continuously differentiable function $\psi(\,\cdot\,)$
  \item $\ell_\theta:=\log p_\theta(y)$: Log-likelihood
  \item $s_\theta = d\ell_\theta/d\theta$:
    Score function, evaluated at $\theta$

  \item $I_{\theta_0}=\Var(s_{\theta_0})$:
    %$I_{\theta_0}
    %= \frac{ds_\theta}{d\theta'}\big|_{\theta=\theta_0}
    %= \frac{d^2\log p_\theta(y)}{d\theta d\theta'}\big|_{\theta=\theta_0}$:
    Information matrix
\end{itemize}
\paragraph{Standard Efficiency Results for Estimation of $\psi(\theta_0)$}
First, consider estimation of the likelihood parameter vector
$\theta_0$.
For any asymptotically normal and asymptotically regular estimator
sequence $\hat{\theta}_n$ such that
\begin{align*}
  n^{1/2}(\hat{\theta}_n-\theta_0)
  \quad
  \dto
  \quad
  \calN(0,V)
\end{align*}
it is the case, by standard efficiency arguments, that
\begin{align*}
  V \geq I_{\theta_0}^{-1}
\end{align*}
When our estimand is instead some function of the full likelihood
parameter, i.e. $\psi_0=\psi(\theta_0)$, for any asymptotically normal
and asymptotically regular estimator sequence $\hat{\psi}_n$ such that
\begin{align*}
  \sqrt{n}(\hat{\psi}_n-\psi(\theta_0))
  \quad\dto\quad
  \calN(0,W)
\end{align*}
it is the case that
\begin{align*}
  W \geq I_{\psi_0}^{-1} := \dot{\psi}_0'I_{\theta_0}^{-1}\dot{\psi}_0
  \qquad\text{where}\quad
  \dot{\psi}_0
  :=
  \frac{%
    d\psi(\theta)
  }{%
    d\theta
  }
  \bigg|_{\theta=\theta_0}
\end{align*}
To prove this, we simply reparameterize and invoke the standard
efficiency argument. In particular, find a one-to-one transformation of
likelihood parameter $\eta=\eta(\theta)$ such that
$e_1'\eta(\theta)=\psi(\theta)$.
Then invoke the standard efficiency argument to argue that the
asymptotic variance of any estimator of (now, after reparameterization)
likelihood parameter $\eta_0=\eta(\theta_0)$ is at least as large as
$I^{-1}_{\eta_0}$.
Because the first element of $\eta$ is $\psi(\theta)$, this gives an
efficiency bound for estimation of $\psi(\theta_0)$.
And because $\eta(\theta)$ is a one-to-one transformation of $\theta$,
we can relate $I_{\eta_0}$ and $I_{\theta_0}$ to deliver the bove bound.

What's more, given the asymptotically normal and asymptotically regular
estimator $\hat{\theta}_n$ described above, we have
the following estimator of $\psi(\theta_0)$, and its asymptotic
distribution by the delta method:
\begin{align*}
  \sqrt{n}(\psi(\hat{\theta}_n)-\psi(\theta_0))
  \quad\dto\quad
  \calN(0,
  \dot{\psi}_0'I_{\theta_0}^{-1}\dot{\psi}_0
  )
\end{align*}
Because this achieves the efficiency bound, $\psi(\hat{\theta}_n)$ is an
efficien estimator of $\psi_0=\psi(\theta_0)$.



\paragraph{Reinterpreted Efficiency Results for Estimation of $\psi(\theta_0)$}
\begin{itemize}
  \item $\theta_t$:
    A function of $t$ living in parameter space $\Theta$.
    In this parametric setting with $\Theta=\R^k$,
    $t\mapsto \theta_t$ defies a path through the space $\Theta$.
    Changing $t$ induces movement along the path through the space
    $\Theta$.

  \item $\psi_t:=\psi(\theta_t)$:
    Function/path in $\R$ for the estimand of interested induced by the
    path $\theta_t$.

  \item
    (\emph{Sets} $\calS_{\psi_0}$, $\psi(\calS_{\psi_0})$ \emph{of Paths}):
    There are many such paths $\theta_t$ (and associated $\psi_t)$
    through parameter space $\Theta$;
    therefore, to make progress, we restrict consideration to the
    following subset of paths
    \begin{align*}
      \calS_{\psi_0}
      :=
      \big\{
        \theta_t
        \,:\,
        \psi(\theta_t) = \psi_0 + t
        \quad
        \forall \text{$t$ small enough}
      \big\}
    \end{align*}
    In other words, $\calS_{\psi_0}$ collects the set of all paths
    $\theta_t$ through $\Theta$ whose associated induced $\psi_t$ passes
    through the truth $\psi_0=\psi(\theta_0)$, and in a way that
    $\psi_t=\psi_0+t$ for $t$ small.

    Note that any path $\theta_t$ through $\theta_0$ will
    \emph{necessarily} (and obviously) be in $\calS_{\psi_0}$.
    But there are also potentially \emph{additional} paths $\theta_t$
    that do not pass through $\theta_0$, but nonetheless satisfy the
    above condition $\psi(\theta_t)=\psi_0+t$ for $t$ small.
    For that reason, $\calS_{\psi_0}$ was (appropriately) subscripted
    by $\psi_0$ (our actual estimand), rather than $\theta_0$.

    Given $\calS_{\psi_0}$, we also define, in a slight abuse of
    notation,
    \begin{align*}
      \psi(\calS_{\psi_0})
      :=
      \{
        \psi(\theta_t)
        \;:\;
        \theta_t\in\calS_{\psi_0}
      \}
    \end{align*}
    Finaly, a note on what matters here.
    It does matter that we're restricting from the set of all possible
    paths $\theta_t$ through $\Theta$ to the set of paths in
    $\calS_{\psi_0}$, i.e.\ those with induced $\psi(\theta_t)$ passing
    through $\psi_0$.
    But conditional on that restriction, the fact that $t=0$ corresponds
    to the truth $\psi_0$ for every $\psi_t\in\psi(\calS_{\psi_0})$ is a
    harmless normalization.
    But what is restrictive again is that $\psi_t=\psi_0+t$ for $t$
    small enough for all $\psi_t\in\psi(\calS_{\psi_0})$ by
    construction/assumption.
    That, in in turn, implies the following result for all
    $\psi_t \in \psi(\calS_{\psi_0})$
    \begin{align*}
      \frac{d\psi_t}{dt}
      \bigg|_{t=0}
      &=
      \frac{d}{dt}
      \big[
        \psi_0+t
      \big]_{t=0}
      =1
      \\
      \frac{d\psi_t}{dt}
      \bigg|_{t=0}
      &=
      \frac{d\psi(\theta_t)}{dt}
      \bigg|_{t=0}
      =
      \frac{d\psi(\theta)}{d\theta'}
      \frac{d\theta_t}{dt}
      \bigg|_{t=0}
      =
      \dot{\psi}_0'
      \dot{\theta}_0
      =
      1
      \qquad\text{where}\quad
      \begin{cases}
        \dot{\psi}_0
        =
        \frac{d\psi(\theta)}{d\theta}
        \bigg|_{\theta=\theta_0}
        \\
        \dot{\theta}_0
        =
        \frac{d\theta_t}{dt}
      \end{cases}
    \end{align*}
    This property of the set of all paths in $\psi(S_{\psi_0})$ will be
    crucial for the results below.

  \item
    (\emph{Parametric Submodels Induced by} $\calS_{\psi_0}$ and $\psi(\calS_{\psi_0})$):
    Given the original model $\{p_{\theta}\}_{\theta\in\Theta}$ with
    distributions indexed by parameter $\theta$, truth $\theta_0$, and
    associated $\calS_{\psi_0}$,
    any path $\theta_t\in\calS_{\psi_0}$ then defines a particular
    \emph{parametric submodel} $\{p_{\theta_t}\}_{t\in \R}$ with
    distributions indexed by parameter $t$.
    Within this submodel, $t$ is the only unknown parameter,
    $\psi(\theta_t)=\psi_0+t$ by assumption that
    $\theta_t\in\calS_{\psi_0}$, and therefore
    estimation of target $\psi_0=\psi(\theta_0)$
    amounts to estimation of $t$ where the truth is $t=0$.

    This parametric submodel naturally has an associated log-likelihood
    at $t$, score at $t$, and information matrix, now with $t$
    representing the parameter:
    \begin{align*}
      \ell_t
      &:= \log p_{\theta_t}(y)
      \qquad\quad
      s_t
      :=
      \frac{d\ell_t}{dt}
      \qquad\quad
      I_0
      :=
      \Var(s_0)
    \end{align*}
    What's more, because all of these quantities are derived from the
    likelihood in the original model, we can relate them.
    First the score,
    \begin{align*}
      s_0
      =
      \frac{d\ell_t}{dt}
      \bigg|_{t=0}
      =
      \frac{d\ell_{\theta_t}}{dt}
      \bigg|_{t=0}
      =
      \frac{d\ell_{\theta}}{d\theta'}
      \frac{d\theta_t}{dt}
      \bigg|_{t=0}
      =
      s_{\theta_0}'
      \dot{\theta}_0
      =
      \dot{\theta}_0'
      s_{\theta_0}
      \qquad\text{where}\quad
      \dot{\theta}_0
      :=
      \left[
      \frac{d\theta_t}{dt}
      \right]_{t=0}
    \end{align*}
    Note that $\dot{\theta}_0$, which is the tangent vector for the path
    $\theta_t$ at $t=0$, is particular to the path $\theta_t$.
    Different paths will have different tangent vectors.

    Next, the information
    \begin{align*}
      I_0
      =
      \Var(s_0)
      =
      \Var\left(
      \dot{\theta}_0'
      s_{\theta_0}
      \right)
      =
      \dot{\theta}_0'
      \Var\left(
      s_{\theta_0}
      \right)
      \dot{\theta}_0
      =
      \dot{\theta}_0'
      I_{\theta_0}
      \dot{\theta}_0
    \end{align*}
    Thus the efficiency bound for estimating $t$
    (which is equivalent to estimating $\psi_0$)
    in the parametric submodel induced by $\theta_t$ is given by
    \begin{align*}
      I_0^{-1} =
      \big(
      \dot{\theta}_0'
      I_{\theta_0}
      \dot{\theta}_0
      \big)^{-1}
    \end{align*}
    This will be useful later on for characterizing the efficiency
    bound.

  \item
    (\emph{Tangent Space of Original Model}):
    From the previous bullet point,
    \emph{any} parametric submodel $\{p_{\theta_t}\}_{t\in\R}$
    built from some $\theta_t\in\calS_{\psi_0}$
    has an efficiency bound for estimation of $t$ (equivalently,
    $\psi_0$) entirely characterized by tangent vector $\dot{\theta}_0$
    and $I_{\theta_0}$, with the latter common across all submodels.
    Therefore, we can summarize the set of efficiency bounds over all
    submodels by the set of tangent vectors $\dot{\theta}_0$ for each
    $\theta_t\in\calS_{\psi_0}$ at $t=0$.
    The smallest linear subspace of $\Theta$ that contains all such
    tangent vectors is called the \emph{tangent space} of the model
    $\{p_\theta\}_{\theta\in\Theta}$.

    This is important because we will be able to find extrema of the
    efficiency bound over parametrics all submodels more simply by
    simply finding extrema over all vectors in the tangent space, which
    will be a standard nonlinear optimization problem.
    We now take up this task.


  \item
    (\emph{Maximum Efficiency Bound over All Submodels}):




\end{itemize}



\clearpage
\section{Regression Models}

\subsection{Getting the Data}

We have data $\{Y_i,X_i\}_{i=1}^N$.
To do statistics, this data has to be random somehow, but in exactly
what way?
What mechanism generated the sequence $\{Y_i,X_i\}_{i=1}^N$?
And in what way can that randomness lead to a regression model?
It turns out, there are several options and perspectives.

First, let's talk about how $\{Y_i,X_i\}_{i=1}^N$ come into our
possession.
\begin{itemize}
  \item (\emph{Generating from the DGP}):
    Think of this as rolling the dice and getting an outcome, something
    that we can repeat as many time as we'd like, in order to generate
    otucomes directly from the DGP.
    For example, we might
    \begin{itemize}
      \item Run experiment which generates $(Y_i,X_i)$ jointly
      \item Run experiment $N$ times, setting $\{X_i\}_{i=1}^N$, then
        let $\{Y_i\}_{i=1}^N$ be realized given $\{X_i\}_{i=1}^N$
    \end{itemize}

  \item (\emph{Sampling}):
    There is a big population pool of units out there with realized
    values for $(Y,X)$, and we choose $N$ of them somehow via a sampling
    mechanism.
    The sampling mechanism can be simple or complicated.
    Examples include
    \begin{itemize}
      \item We randomly chose $N$ units from the population, with or
        without replacement.
      \item We do some form of cluster sampling in which choose $G$
        clusters and then sample from the clusters to hit $N$ total
        units in our sample.
      \item We fix the $\{X_i\}_{i=1}^N$ that will be in our dataset,
        then for each value of $X_i$, draw from the conditional
        distribution of $Y_i|X_i$ at that level of covariates.
    \end{itemize}
\end{itemize}
Note that these two perspectives are not so different and can be
collapsed together.
In particular,
the act of randomly sampling $(Y_i,X_i)$ from a population with some
empirical distribution
is equivalent to
generating $(Y_i,X_i)$ from a DGP with some distribution.
This is especially obvious in the limiting case in which we imagine the
population from which we sample to be infinitely large, implying that
the empirical distribution of outcomes is arbitrarily close to the
underlying DGP distribution that generated those outcomes.

Now, suppose we write down
\begin{align*}
  y_i=X_i\beta + u_i
  \qquad\text{or, stacking observations,}\qquad
  y=X\beta + u
\end{align*}
What does this mean, what are the assumptions?
What is the interpretation?



\clearpage
\subsection{Linear Regression Model, Fixed $X$}

This perspective is common in introductory statistics.
View the $\{X_i\}_{i=1}^N$ as fixed, then write
\begin{align}
  y = X\beta + u
  \qquad
  \E[u]=0
  \quad
  \Var(u)=\Sigma
  \label{classicalstat}
\end{align}
With $X$ fixed,
$y$ is random solely because of $u$.
All this model really says at this point is that expected outcomes
display a linear relationship with the following variance:
\begin{align*}
  \E[y]=X\beta
  \qquad\text{and}\qquad
  \Var(y)=\Sigma
\end{align*}
Comments
\begin{itemize}
  \item (\emph{Classical vs. Generalized Model}):
    Above is the \emph{generalized} linear regression model, which is
    distinct from the \emph{classical} linear regression that further
    assumes \emph{normality} and \emph{homoskedasticity}
    \begin{align*}
      y=X\beta+u
      \quad\text{where}\quad
      u\sim\calN(0,\sigma^2I_N)
      \qquad\implies\qquad
      y\sim \calN(X\beta,\sigma^2 I_N)
    \end{align*}


  \item (\emph{Randomness}):
    The randomness in outcomes can arise from the following mechanisms.
    \begin{itemize}
      \item (\emph{Repeated Experiments or Measurement Error}):
        Suppose that, even though we set/fix $X$ ahead of time, because
        of measurement error in measuring outcomes for a given set of
        units or uncontrolled random shocks in repeated runs of the same
        experiment (both of which manifest in the random $u$), observed
        outcomes $y$ are random.\footnote{%
          Measurement error on the RHS is a whole different beast that
          requires special methods.
          We're considering specifically measurement error for the
          outcomes.
        }
        Therefore, the randomness in $u_i$ is over repeated measurement
        or replications of the experiment, always holding $X$ always
        fixed.

        Therefore, $X\beta$ characterizes the linear relationship in
        expected outcomes $\E[y]$,
        absent measurement or experimental error.

      \item (\emph{Repeated Sampling}):
        Suppose there is a pool of units at each level of the fixed
        covariates in $X$.
        If we resample one unit at each level of $X_i$ (or sample from
        some DGP, which is more or less equivalent, as discussed above),
        we get a different set of units and thus random outcomes.

        Therefore, $X\beta$ characterizes the linear relationship in
        expected outcomes $\E[y]$,
        across repeated samples or DGP draws, with $X$ fixed.
    \end{itemize}
    Therefore, $X\beta$ is the portion of outcomes that is
    systematically explained by $X$, that survives repeated measurement,
    replication, or sampling.
    Random $u_i$ captures all other unobserved determinants of the
    outcome and drives all randomness in outcomes.

  \item (\emph{$\E[u]=0$ and Linearity}):
    This assumption is equivalent to $\E[y]=X\beta$ for some $\beta$,
    i.e. a linear pattern in expected outcomes.
    Therefore, $\E[u]=0$ is just the statement that we believe there
    exists a linear pattern in expected outcomes.
    Importantly, it is \emph{not} the assumption that $\beta$ represents
    a causal marginal effect for each unit; see point below.
    %\begin{align*}
      %\E[y]=X\beta
      %\qquad\implies\qquad
      %\E[y_i]=X_i\beta
      %\qquad\implies\qquad
      %\frac{\partial}{\partial X_i}
      %\E[y_i]
      %=
      %\beta
    %\end{align*}

    While, given our single sample $\{y_i,X_i\}_{i=1}^N$, we cannot truly
    know whether there exists a linear relationship in expected outcomes
    \emph{over repeated runs of the experiment or measurement or samples},
    we can check plausibility by plotting the data.
    If the scatterplot is highly nonlinear, linearity is a pretty
    obviously bad assumption, and this suggests including additional
    controls or powers of $X_i$ so that the model is ultimately linear
    in parameters and covariates.

    Note: If we adopt a model perspective, as described below, the
    assumption $\E[u_i]=0$ serves an additional purpose of ensuring
    identification of a within-unit causal marginal effect parameter, as
    we now describe.

  \item
    (\emph{Model and its Identification}):
    Suppose we're willing to make a strong assumption.
    In particular, suppose that there is linearity with slope $\beta$
    not just in \emph{expected} outcomes \emph{across} the values of the
    covariates that are in fixed $X$.
    Instead, further suppose there is linearity in \emph{actual}
    outcomes \emph{within} any unit $i$, if we could
    \emph{hypothetically} manipulate the value of $X_i$ holding
    everything else (i.e. $u_i$) fixed, and it is \emph{common} and
    equal to some $\beta$ for all units.
    In other words, we can imagine that, if we could \emph{freeze} $u_i$
    and manipulate $X_i$, we'd have for unit $i$
    \begin{align*}
      \forall i\qquad
      \frac{\partial y_i}{\partial X_i}
      =
      \beta
      \quad\implies\quad
      y_i(X_i) | u_i = X_i\beta + u_i
    \end{align*}
    where $y_i(X_i)|u_i$ is a set of potential outcomes that would
    obtain under different counterfactual values of $X_i$, holding $u_i$
    fixed.
    Therefore,
    $\beta$ is special as it captures a marginal causal effect
    that is \emph{common/identical/constant} for all units.

    First, this is restrictive not because the rate of change as
    expressed by $\beta$ appears to be \emph{constant} across values of
    $X$. That can be relaxed by replacing continuous $X_i$ with dummies
    for the values it takes on or interacting $X_i$ with such dummies.
    What is restrictive is that
    \emph{it's the same $\beta$ for all units}.

    Second, the assumption of a common marginal effect $\beta$ for all
    units is totally untestable because we only ever observe a single
    outcome and covariate pair $(y_i,X_i)$ for each unit and we cannot
    manipulate $X_i$ holding $u_i$ fixed, as stated.
    We could never verify this assumption,
    and so it is quite strong.
    But suppose we're willing to swallow it because we have some model
    or strong belief that the above statement does accurately describe
    counterfactuals.
    Could we ever estimate it?  Yes, under additional assumptions, as we
    now discuss.

    Suppose the above linear relationship holds for all $i$ and that $u_i$
    is realized
    \begin{enumerate}[label=(\roman*)]
      \item Completely separately from whatever deterministic
        rule/procedure sets $X_i$ to its fixed value, and
      \item Such that $\E[u_i]=0$, no matter what $X_i$ is set to.
    \end{enumerate}
    Then $\E[y]=X\beta$.
    In words, if we have linearity with marginal effect $\beta$ for
    \emph{individual} outcomes and $u_i$ with $\E[u_i]=0$
    realized completely separately from the deterministic mechanism
    that sets $X_i$, we then immediately have linearity of
    \emph{average} outcomes with the very same slope $\beta$.
    And because $u_i$ is realized separately from however we set $X_i$
    and because it satisfies $\E[u_i]=0$, differences across $X_i$ are
    attributable to the effect of $X_i$, not changes in $\E[u_i]$,
    so we can identify the structural marginal effect parameter for
    individuals from the slope of average outcomes in the data.
    And so we see that the assumption $\E[u_i]=0$ (which is assumed true
    for any $X_i$) becomes absolutely crucial not just for stating the
    linearity assumption, but for identification, i.e. matching an
    observable/estimable quantity in the data with the parameter of a
    structural model.
    Said another, combined with the assumption of common constant
    marginal effects, $\E[u_i]=0$ is the assumption that ``The slope you
    see is the parameter you want.''

    Now this was maybe a bit of an odd and awkward perspective.
    First, because we usually think about fixing $X_i$, running the
    experiment, and then $u_i$ is realized.
    This says instead that $u_i$ (measurement, experimental, or an
    individual's idiosyncratic error) is realized,
    and we think about varying $X_i$.
    Second, I worked very hard not to use the words ``independent'' or
    ``dependent'' when describing the relationship between $X_i$ and
    $u_i$.
    That's because $X$ is fixed and varying $X_i$ is a deterministic
    exercise.
    And deterministic objects are not RVs whose correlation with $u_i$
    we can consider.
    And this is rare in economics, where the RHS variables $X_i$ are
    often random objects themselves that we cannot control/fix to
    whatever we want as in an experiment.
    But we can always condition on them, which is the perspective taken
    below. We will still have linearity in the $X_i$, but we will treat
    the $X_i$ as random.

    Alternatively, suppose that $u_i$ is realized in a manner
    \emph{related} to the deterministic mechanism setting $X_i$ in which
    case $\E[u_i]\neq 0$.
    That is, \emph{if} we could freeze $u_i$, we would observe a
    marginal effect $\beta$ as we vary $X_i$; \emph{however},
    we could never actually vary $X_i$ while holding $u_i$ fixed---even
    on average---due to the underlying physical phenomenon.
    Then we cannot identify $\beta$ using OLS because
    $\E[y_i]=X_i\beta + \E[u_i]$ with the second term nonzero and
    possibly pushing the slope of expected outcomes away from the
    marginal effect $\beta$.
    This is when switching to a conditional-on-$X$ and unconditional
    perspective comes into play, because we could possibly use IV
    methods if we can find an instrument that pushes $X_i$ around
    but leaves $u_i$.

    Finally, a word about identification again.
    We can only ever identify in the data a common portion that captures
    \emph{systematic} variation across units.
    For example, suppose that the marginal effect is
    $\beta_i=\beta+v_i$, where $v_i$ is mean zero random noise
    independent of everything else.
    A regression model still holds, but we could only ever identify
    $\beta$ from the data.

  \item
    This perspective in which $X$ is fixed has its problems because
    often in economics, $X$ is itself random and distributed according
    to some DGP or sampling procedure.
    The fixed $X$ approach makes passing to unconditional asymptotics
    impossible, and makes the asymptotics more difficult because we
    would have to specify how $X$ evolves deterministically as we add
    observations, rather than letting some random mechanism or
    distribution do that work for us.

  \item
    (\emph{Estimation, Inference and Efficiency}):
    Assuming linearity $\E[y]=X\beta$,
    we want an estimator $\hat{\beta}$ and want to characterize the
    finite-sample distribution of that estimator.
    Leading estimators are the OLS, WLS, GLS estimators.
    \begin{itemize}
      \item (\emph{Conditional Mean and Variance}):
        All of these estimators are linear functions of $y$ whose mean
        and variance we can easily compute given any $\Sigma$.
        To say more about the distribution of these estimators, we need
        to assume a particular distribution for the errors, not just the
        variance $\Sigma$.

      \item
        (\emph{Gauss-Markov, OLS Efficiency}):
        If errors are homoskedastic as in the classical linear regression
        model, i.e. $\Sigma=\sigma^2 I_N$, then OLS is the best
        (lowest-variance) linear unbiased estimator of ${\beta}$.

      \item
        (\emph{GLS Efficiency}):
        If the errors are non-homoskedastic but $\Sigma$ is known, GLS
        is the best linear unbiased estimator of $\beta$.

      \item
        (\emph{Inference under Normal Errors}):
        If the errors are normal, the OLS and GLS estimators are also
        normal, and their mean and variance fully characterize their
        respective distributions.
        Given that, we can deduce the finite-sample distributions of various
        statistics, and use them for inference.
    \end{itemize}

\end{itemize}




\clearpage
\subsection{Linear Regression Model, Random $X$}
In economics, often don't want to treat $X$ as a fixed/deterministic
object, even if we believe there is a linear relationship between $X$
and the average outcomes of $y$ \emph{conditional} on $X$.
This could be either because
\begin{enumerate}
  \item We randomly \emph{jointly} sample $(y_i,X_i)$
  \item $y_i$ and $X_i$ are \emph{jointly} generated by some underlying
    DGP that we're trying to do inference about in a non-experimental
    setting in which we can't fix $X$.
    This is the proper way to think about \emph{selection},
    \emph{simultaneity}, \emph{endogeneity}, etc. where $y_i$ and $X_i$
    are possibly \emph{both} outcomes that depend upon some unobserved
    characteristic.
\end{enumerate}
Either way, $X$ is random as well.
So then we should write
\begin{align}
  y = X\beta + u
  \qquad
  \E[u|X]=0
  \quad
  \Var(u|X)=\Sigma(X)
  \label{classicalecon}
\end{align}
Conditional on random $X$, outcomes $y$ are random solely because of
$u$.
All this model really says is that conditional-on-$X$ expected outcomes
display a linear relationship with the following slope and variance,
\begin{align*}
  \E[y|X]=X\beta
  \qquad\text{and}\qquad
  \Var(y|X)=\Sigma(X)
\end{align*}
We can also impose stronger assumptions, namely that $\beta$ represents
a constant marginal/structural/treatment effect common to all units,
which is stronger than just ``linearity of $\E[y|X]$.''
See discussion below.


\subsubsection{Setup}

\paragraph{Classical vs. Generalized Model}
Above is the \emph{generalized} linear regression model, which is
distinct from the \emph{classical} linear regression that further
assumes conditional \emph{normality} and conditional
\emph{homoskedasticity}
\begin{align*}
  y=X\beta+u
  \quad\text{where}\quad
  u|X\sim\calN(0,\sigma^2I_N)
  \qquad\implies\qquad
  y|X\sim \calN(X\beta,\sigma^2 I_N)
\end{align*}
\paragraph{$X$ Randomness, Unconditional Perspective, and Inference Perspective}
Once we allow ourselves to think of $X$ as random, we can start to
define things like $\E[X_i]$, $\E[X_iX_i']$, $\E[X_iy_i]$, where the
expectation is taken over the distribution of random $X_i$.
In other words, we can also take an \emph{uncondtional} perspective
in which we compute expectations over the \emph{joint} distribution
of $(y_i,X_i)$.
A few comments.

The unconditional perspective is most useful for \emph{asymptotics}
and \emph{time series} regressions.
It is less natural to describe asymptotics in the fixed $X$ approach,
because you need to describe how the fixed sequence of $X$'s evolve
deterministically, and you get different answers for different
sequences.
If $X$ is random, just let the distribution of the $X_i$ do it for
you and appeal to a LLN to converge to a unique limit.
Also, in time series, if the RHS variable is correlated over time,
it's impossible to take this deterministic $X$ view and work out
asymptotics.
Finally, if the unconditional joint distribution of $(y_i,X_i)$ is
well defined, then we can make a statement like ``Regression
converges to this unique quantity'' even if the conditional
expectation $\E[y|X]$ is generally nonlinear.

That said, even though an unconditional perspective offers lots of
convenience for inference,
if the model is correctly specified in the sense of conditional
linearity $\E[y|X]=X\beta$ and we know the distribution of the error
terms,
we can deduce the \emph{conditional}-on-$X$ distribution of
$\widehat{\beta}$, which is generally \emph{better} for inference about
$\beta$ than using the unconditional distribution of that same estimator
$\widehat{\beta}$.
And that's not just because the unconditional distribution is based
on an asymptotic approximation.
If we knew the exact finite sample unconditional distribution of
$\hat{\beta}$, that's still not as good as working with the
conditional-on-$X$ distribution by ancillarity arguments.
Although, in economics, we're generally less worried about
the loss of efficiency for regression models and favor unconditional
inference because
\begin{enumerate}
  \item We're worried about nonlinearity $\E[y|X]$ and hence
    misspecification but still want to conduct inference about the OLS
    estimand.
    So using the assumption $\E[y|X]=X\beta$ in our inference would be
    invalid.
  \item We're not comfortable specifying $\Sigma(X)$ or providing an
    unbiased estimator of it, but we do think we can consistently
    estimate the part of the asymptotic variance of $\widehat{\beta}$
    that depends upon $\Sigma(X)$.
\end{enumerate}
\paragraph{$u|X$ Randomness}
The randomness in observed outcomes $y$ now arises from \emph{both}
randomness in $X$, now a RV, and randomness in $u$ that survives
still after conditioning on $X$.
The conditional randomness $u|X$ can be due to the following
mechanisms:
\begin{itemize}
  \item (\emph{Repeated Experiments or Measurement Error}):
    Same logic as in conditional case, i.e.\ randomness in $u$
    represents measurement or uncontrolled experimental
    error.\footnote{%
      Measurement error on the RHS is a whole different beast that
      requires special methods.
      We're considering specifically measurement error for the
      outcomes.
    }
    The conditional randomness in $u|X=x$ is then over repeated
    measurement or replications of the experiment, \emph{if} we
    could ensure that $X=x$ across them (although we know that $X$
    is truly random).

    Therefore, $X\beta$ characterizes the linear relationship in
    conditional expected outcomes $\E[y|X]$,
    absent conditional-on-$X$ measurement or experimental error.

  \item (\emph{Repeated Sampling}):
    Suppose there is a pool of units at each level of the fixed
    covariates in $X$.
    \emph{If} we could resample or generate from the DGP such that
    $X$ is fixed across repeated samples (although we know that $X$
    is truly random), we would get a different set of units/draws
    with different $u_i$ even conditional on $X_i$.

    Therefore, $X\beta$ characterizes the linear relationship in
    expected outcomes $\E[y|X=x]$,
    across repeated samples or DGP draws if we could ensure $X=x$
    across those samples/draws.
\end{itemize}
Therefore, $X\beta$ is the portion of outcomes that is
systematically explained by $X$, that survives repeated measurement,
replication, or sampling of the $u$ terms conditional on that $X$.
Random $u_i$ captures all other unobserved determinants of the
outcome and drives all conditional-on-$X$ randomness in outcomes.

\paragraph{$\E[u|X]=0$ and Linearity}
This assumption is equivalent to $\E[y|X]=X\beta$
\emph{for some $\beta$},
i.e. a linear pattern in conditional expected outcomes.
Therefore, at this point, $\E[u|X]=0$ is just the statement that we
believe there exists a linear pattern in conditional expected outcomes.
Importantly, it is \emph{not} the assumption that $\beta$ represents
a causal marginal effect for each unit; see point below.
%\begin{align*}
  %\E[y]=X\beta
  %\qquad\implies\qquad
  %\E[y_i]=X_i\beta
  %\qquad\implies\qquad
  %\frac{\partial}{\partial X_i}
  %\E[y_i]
  %=
  %\beta
%\end{align*}

While, given our single sample $\{y_i,X_i\}_{i=1}^N$, we cannot truly
know whether there exists a linear relationship in conditional
expected outcomes
\emph{over repeated runs of the experiment or measurement or samples
with $X$ held fixed},
we can check plausibility by plotting the data.
If the scatterplot is highly nonlinear, linearity is a pretty
obviously bad assumption, and this suggests including additional
controls or powers of $X_i$ so that conditional expected outcomes
are ultimately linear in parameters and covariates.

Note: If we adopt a model perspective, as described below, the
assumption $\E[u_i|X_i]=0$ serves an additional purpose of ensuring
identification of a within-unit causal marginal effect parameter, as
we will soon describe.
Moreover, $\E[u_i|X_i]=0$ could fail \emph{even if} the relationship
looks linear. This would imply that the slope we observe is not the
parameter we want.


\subsection{Linear Causal Regression Model}

Suppose we're willing to make a strong assumption.
In particular, suppose that there is linearity with slope $\beta$
not just in conditional \emph{expected} outcomes \emph{across}
$X_i$ values.
Instead, further suppose there is linearity in \emph{actual}
outcomes \emph{within} any unit $i$, if we could
\emph{hypothetically} manipulate the value of $X_i$ holding
everything else (i.e. $u_i$) fixed, and it is \emph{common} and
equal to some $\beta$ for all units.
In other words, we can imagine that, if we could \emph{freeze} $u_i$
and manipulate $X_i$, we'd have for unit $i$
\begin{align*}
  \forall i\qquad
  \frac{\partial y_i}{\partial X_i}
  =
  \beta
  \quad\implies\quad
  y_i(X_i) | u_i = X_i\beta + u_i
\end{align*}
where $y_i(X_i)|u_i$ is a set of potential outcomes that would
obtain under different counterfactual values of $X_i$, holding $u_i$
fixed.
Therefore,
$\beta$ is special as it captures a marginal causal effect
that is \emph{common/identical/constant} for all units.

First, this is restrictive not because the rate of change as
expressed by $\beta$ appears to be \emph{constant} across the
support of $X$. That can be relaxed by replacing continuous $X_i$
with dummies
for the values it takes on or interacting $X_i$ with such dummies.
What is restrictive is that
\emph{it's the same $\beta$ for all units}.

Second, the assumption of a common marginal effect $\beta$ for all
units is totally untestable because we only ever observe a single
outcome and covariate pair $(y_i,X_i)$ for each unit and we cannot
manipulate $X_i$ holding $u_i$ fixed, as stated.
We could never verify this assumption,
and so it is quite strong.
But suppose we're willing to swallow it because we have some model
or strong belief that the above statement does accurately describe
counterfactuals.
Could we ever estimate it?  Yes, under additional assumptions, as we
now discuss.

Suppose the above linear relationship holds for all $i$ and that $u_i$
is \emph{mean-independent} of $X_i$, i.e.
\begin{align*}
  \E[u_i|X_i]=0
  \qquad\forall X_i
\end{align*}
Then we have a linear CEF, $\E[y_i|X_i]=X_i\beta$ and
$\E[y|X]=X\beta$.
In words, if we have linearity with marginal effect $\beta$ for
\emph{individual} outcomes and $u_i$ mean-independent of $X_i$ (i.e.
$\E[u_i|X_i]=0$), we then immediately have linearity of
conditional-on-$X$ \emph{average} outcomes with the very same slope
$\beta$.
And because $u_i$ is mean-independent of $X_i$ with $\E[u_i|X_i]=0$,
differences across $X_i$ are attributable to the effect of $X_i$,
not changes in $\E[u_i|X_i]$ across values of $X_i$.
Therefore, we can identify the structural marginal effect parameter
for individuals from the slope of $\E[y|X]$ in the data.
And so we see that the assumption $\E[u_i|X_i]=0$
becomes absolutely crucial not just for stating the conditional
linearity assumption, but for identification, i.e. matching an
observable/estimable quantity in the data with the parameter of a
structural model.
Said another, combined with the assumption of common constant
marginal effects, $\E[u_i]=0$ is the assumption that ``The slope you
see is the parameter you want.''

Alternatively, suppose that $u_i$ is correlated with $X_i$ so that
$\E[u_i|X_i]\neq 0$.
That is, \emph{if} we could freeze $u_i$, we would observe a
marginal effect $\beta$ as we vary $X_i$ for a given unit;
\emph{however}, we could never actually vary $X_i$ while holding
$u_i$ fixed---even on average---due to $\E[u_i|X_i]\neq 0$.
Then we cannot identify $\beta$ using OLS because
$\E[y_i|X_i]=X_i\beta + \E[u_i|X_i]$ with the second term nonzero
and possibly pushing the slope of expected outcomes away from the
marginal effect $\beta$.
This is a \emph{failure of exogeneity} that could be because of
simultaneity, omitted variables, endogeneity, selection, etc.
The process determining $(y_i,X_i)$ induces correlation in $u_i$ and
$X_i$ such that, on average, changes in $X_i$ are associated both
with the direct effect of $X_i$ and changes in the conditional mean
of $u_i$.
That means that even if we see a linear pattern in the data, the
slope might not be identified with the marginal effect parameter
$\beta$; it might equal $\beta$ plus some other term due to this
failure of exogeneity and the inability to isolate the pure
within-individual marginal effect parameter $\beta$.

Note that failure of exogeneity does not mean that we are out of
luck entirely.
We can possibly use IV, fixed effect regressions, etc.
that use different approaches to identify the marginal effect
parameter in the data.
For example, in IV, we look for an instrument that is correlated
with $X_i$ but uncorrelated with $u_i$, which can provide an
estimate of the marginal effect parameter $\beta$.



\clearpage
\subsection{Estimation, Inference and Efficiency}

First, assume linearity in conditional expected outcomes,
$\E[y|X]=X\beta$.
Leading estimators are the OLS, WLS, GLS estimators.
They can all be written as
\begin{align*}
  \hat{\beta}(W)
  = (X'WX)^{-1}X'Wy
  = (X'WX)^{-1}X'W(X\beta + u)
  = \beta + (X'WX)^{-1}X'Wu
\end{align*}
OLS takes $W=I_N$, WLS takes $W$ arbitrary positive definite for
some matrix $W$ that is fixed conditional on $X$, while GLS takes
$W=\Sigma(X)^{-1}$.

\subsubsection{Finite Sample and Limiting Distributions}

(\emph{Conditional Unbiasedness and Consistency of $\hat{\beta}$'s}):
All of the estimators are linear functions of $y$ whose
conditional-on-$X$ mean we can easily compute.
Regardless of the variance structure $\Sigma(X)$,
the assumption $\E[y|X]=X\beta$ (equivalently $\E[u|X]=0$)
ensures they are all unbiased and therefore consistent as well.

(\emph{Conditional Variance of $\hat{\beta}$'s, its Limit, and Variance Estimators}):
All of the estimators are linear functions of $y$ whose
conditional-on-$X$ variance we can easily compute given
any $\Sigma(X)$.
Most common choices of $\Sigma(X)$ are
\begin{enumerate}
  \item Homoskedastic, $\Sigma(X)=\sigma^2 I_N$:
    Conditional variance of OLS is
    \begin{align*}
      \Var\big(\hat{\beta}\,\big|\,X\big)
      = \sigma^2(X'X)^{-1}
    \end{align*}
    In finite samples, $s^2$ is a conditional-on-$X$ unbiased
    estimator of $\sigma^2$.
    Asymptotically, the above variance converges to some limit,
    which we can consistently estimate with $s^2(X'X)^{-1}$.


  \item Diagonal $\Sigma(X)$, with possible heteroskedasticity.
    Conditional variance of OLS is
    \begin{align*}
      \Var\big(\hat{\beta}\,\big|\,X\big)
      = (X'X)^{-1}
        \left[
          \sum_{i=1}^N
          \Var(u_i|X_i)
          X_iX_i'
        \right]
        (X'X)^{-1}
    \end{align*}
    Asymptotically, the above variance converges to some limit,
    which we can consistently estimate with the usual EHW
    heteroskedasticity-robust variance estimator.

  \item Block diagonal, which arises from clusters of
    observations that are related.
    Conditional variance of OLS is
    \begin{align*}
      \Var\big(\hat{\beta}\,\big|\,X\big)
      = (X'X)^{-1}
        \left[
          \sum_{g=1}^G
          X_g'
          \Var(u_g|X_g)
          X_g
        \right]
        (X'X)^{-1}
    \end{align*}
    where $u_g$ and $X_g$ stack all observations in the $g$th
    cluster, and $\Var(u_g|X_g)$ is the $g$th block on the
    diagonal of $\Sigma(X)$.
    Asymptotically, the above variance converges to some limit,
    which we can consistently estimate with the usual cluster-
    and heteroskedasticity-robust variance estimator:
    \begin{align*}
      \widehat{\Var}\big(\hat{\beta}\,\big|\,X\big)
      =
      \frac{G(N-1)}{(G-1)(N-K)}
        (X'X)^{-1}
        \left[
          \sum_{g=1}^G
          X_g'
          \widehat{u}_g
          \widehat{u}_g'
          X_g
        \right]
        (X'X)^{-1}
    \end{align*}
    Note that each of the $G$ terms $\widehat{u}_g \widehat{u}_g'$ have
    rank 1, so that the estimator has at most rank $G$.
    This means that we cannot test joint hypotheses with more than $G$
    restrictions, and that the Wald test for testing such joint
    hypotheses has poor performance, and the wild cluster bootstrap is
    preferred.

    Results
    \begin{itemize}
      \item Bester et al (2011):
        Under restrictive conditions, with $N$ increasing and $G$ fixed,
        $t$-stats for testing $\beta_j=0$ are $t(G-1)$.
      \item Djogbenou et al (2019):
        Under rather weak conditions, with $G$ increasing with $N$ and
        (and $N_g$ allowed to increase as well, but not too fast),
        $t$-stats are asymptotically normal.
        $G$ increasing is necessary if we want consistency of OLS under
        arbitrary within-cluster correlation.
        $G$ fixed cannot deliver consistency unless correlation
        structure within structure dies out as $N\ra\infty$.
    \end{itemize}
    Alternatively, we can use the estimator
    advocated by Bell and McCaffrey (2002) and
    Imbens and Kolesar (2016)
    \begin{align*}
      \widehat{\Var}\big(\hat{\beta}\,\big|\,X\big)
      =
        (X'X)^{-1}
        \left[
          \sum_{g=1}^G
          X_g'
          M_{gg}^{-1/2}
          \widehat{u}_g
          \widehat{u}_g'
          M_{gg}^{-1/2}
          X_g
        \right]
        (X'X)^{-1}
    \end{align*}
    where $M_{gg}^{-1/2}$ is the $g$th block of the annihilator matrix.
    This has better finite sample properties.
    Expensive and potentially unstable way to compute when clusters are
    large because requires finding the inverse symmetric square root of
    $M_{gg}$, see MacKinnon and Webb (2018) and Jackson (2020).


  \item
    Multiway clustering:
    Two dimensions along with observations are correlated, e.g.
    states and time period.
    Each observation belongs to one cluster in each dimension.

    Cameron et al (2011) and Thompson (2011) for multiway;
    although no asymptotic validity.
    Davezies et al (2020) has alternative multiway estimator with
    asymptotic validity proof.
    Menzel 2018 with a bootstrap procedure.




  \item Dense, but decaying as in time series.
    Suppose that the errors $u$ are realizations of some weakly
    dependent process.
    Then the variance of the OLS estimator converges to the
    long-run variance, which we can consistently estimate with
    Newey-West and other time series estimators.
\end{enumerate}

\subsection{Inference Perspectives}

(\emph{Conditional Inference under Normal Errors}):
Under correct specification and conditionally-on-$X$ normal
errors, the OLS and GLS estimators are also conditionally-on-$X$
normal, and their mean and variance fully characterize the
respective distributions.
Given that, we can also deduce the finite-sample
conditional-on-$X$ exact distributions of various statistics for
any $N$, and use them for inference.

Because of ancillarity arguments and because conditional
linearity $\E[y|X]=X\beta$ is the strongest assumption that we
put on the data (and can rely heavily upon for tighter inference
or even more efficient estimation through GLS),
if we are really willing to assume the model is correctly
specified (linearity) and errors are conditionally normal,
we should use this conditional-on-$X$ distributions of
the OLS and GLS estimators for inference, rather than their
unconditional distribution.

(\emph{Unconditional Inference using Asymptotics}):
Again, this is generally not preferred when we're assuming
correct specification, i.e. linearity $\E[y|X]=X\beta$, and
normality of the errors.
But if we're unsure about the conditional distribution of the
errors, we might just appeal to the unconditional asymptotic
distribution of the estimators.
This approach is also necessary if we are unsure about
conditional linearity, as discussed in the next set of bullet
points.

Dependending upon the structure of $\Sigma(X)$, we can derive
the finite-sample conditional-on-$X$ variance of $\hat{\beta}$.
If there is enough independence in $\Sigma(X)$, it's limit will
converge to some asymptotic variance, and we can construct an
appropriate consistent estimator for that asymptotic variance.


\subsection{Efficiency}

\begin{itemize}
  \item
    (\emph{Gauss-Markov, OLS Efficiency}):
    If errors are conditional-on-$X$ homoskedastic as in the
    classical linear regression model, i.e.
    $\Sigma(X)=\sigma^2 I_N$, then OLS is the best
    (lowest conditional-on-$X$ variance) linear (conditional-on-$X$)
    unbiased estimator of ${\beta}$ for any $N$ and asymptotically
    as a result.

  \item
    (\emph{GLS Efficiency}):
    If the errors are non-homoskedastic but $\Sigma(X)$ is known,
    GLS (equivalently, WLS using weight matrix $\Sigma(X)^{-1}$) is
    the best (lowest conditional-on-$X$ variance) linear
    (conditional-on-$X$) unbiased estimator of ${\beta}$ for any
    $N$.
    If $\Sigma(X)=\widehat{\Sigma}(X;\gamma)$ has parametric form
    and $\gamma$ is consistently estimable, then
    feasible GLS (equivalently, WLS using weight matrix
    ${\Sigma}(X;\hat{\gamma})^{-1}$) is asymptotically equivalent to
    GLS using true but generally unknown $\Sigma(X)$.
\end{itemize}


\subsection{Nonlinear CEF}

Next, suppose that conditional expected outcomes $\E[y|X]$ are not
necessarily linear.
Then we can only do unconditional inference using the asymptotic
distribution. Some results.
\begin{itemize}
  \item (\emph{Consistency}):
    Under iid sampling, OLS is consistent for the OLS estimand,
    $\beta=\E[X_iX_i']^{-1}\E[X_iY_i]$.
    But because of the misspecification, GLS and WLS are generally
    not consistent for this $\beta$.
    Instead, they are consistent for some other quantity, which is
    generally less interpretable and is similar to the OLS estimand
    but with weights within the expectations.
\end{itemize}





\clearpage
\paragraph{Rubin Causal Model}
We now consider what happens if we adopt a potential outcome model and
consider doing regression to estimate some sort of average treatment
effect.
\begin{itemize}
  \item
    (\emph{Appropriateness of Regression as an Estimation Strategy}):
    Regression is not automatically an appropriate estimation approach
    in the the Rubin Potential Outcome framework.
    To see why, note that OLS and GLS approaches are estimation procedures
    designed \emph{specifically} to exploit \emph{assumed linearity} in
    expected or conditional-on-$X$ expected outcomes, which possibly results
    from a marginal effect \emph{common} to all units.
    But these kinds of linearity and constant effect assumptions are not at
    all assumed in the Rubin Causal model, which makes it possible that
    regression might be wholly inappropriate.
    So we must always \emph{closely inspect} the regression estimand in
    order to discern whether this estimand gives a useful and desried
    summary of generally heterogeneous treatment effects.

    To to stress:
    in causal inference, regression is not really a \emph{model} but
    rather an estimation \emph{procedure}, i.e. a thing you do that may
    or may not have desirable properties

  \item
    (\emph{Randomness}):
    One of the biggest points of departure in the Rubin causal model
    from the classical and generalized linear regression models comes
    from the nature of the randomness.

    In particular, we can take a pure design-based approach in which
    the only randomness comes from \emph{assignment}.
    Potential outcomes for all units $\{Y_i(1),Y_i(0)\}_{i=1}^N$ are
    fixed, but randomness in treatment assignment implies randomness in
    the RHS variables $\{X_i\}_{i=1}^N$ and, as a result observed
    $\{Y_i\}_{i=1}^N$.
    In contrast to the classical and generalized regression models
    above, there is \emph{zero} conditional-on-$X$ randomness.
    All randomness comes from assignment.
    Thus conditional on treatment, the observed outcome is
    \emph{entirely} deterministic and equal to the potential outcomes
    under treatment or control for the $i$th unit.
    The residual is also conditional-on-$X$ deterministic.

    This is an important source of randomness, that is sometimes
    obscured if we take an unconditional perspective.
    In this perspective, the $N$ units are sampled from some population
    or DGP and the potential outcomes $Y_i(0),Y_i(1)$ themselves have
    some distribution.
    Then, there are two distinct sources of randomness:
    in assignment and in potential outcomes.
\end{itemize}


\clearpage
\paragraph{Pure Unconditional Descriptive Model}
Suppose that we don't believe in linearity at all, but we still consider
doing regression, viewing outcomes and covariates $(y,X)$ as jointly
random.
Then you are just summarizing the joint relationship of the data.
\begin{itemize}
  \item Here, $\beta$ is defined from the mechanism/DGP that generates
    the sample $(y,X)$.
    The residual term is implied.
\end{itemize}





\clearpage
\section{Recent Progress on OLS Regression}
Given data $\calD_n = \{Y_i,X_i\}_{i=1}^n$,
we can always compute OLS estimates
\begin{align*}
  \hat{\theta}
  :=
  \argmin_\theta
  \frac{1}{n}
  \sumin
  (Y_i-X_i'\theta)^2
  =
  (X'X)^{-1}X'Y
  =
  (X'X)^{-1}
  \sumin
  X_iY_i
\end{align*}
In the particular setting of causal inference, we suppose that
$X_i=(D_i,W_i')'$, where $D_i$ is some treatment variable of interest
(generally just a binary indicator) in which case we write
$\hat{\theta}= (\hat{\beta},\hat{\gamma}')'$.
Under regularity conditions, these estimates will converge to
\emph{some estimand}.
The question is what is this estimand?
Is it what we want?
And the answer to that question depends in many ways on our setting,
goals, and assumptions.

We generally run the regression with one of two potential goals in mind.
\begin{enumerate}
  \item
    (\emph{Prediction \& CEF Approx.}):
    Finding the best linear predictor of $Y_i$ given $X_i$ or, closely
    related\footnote{%
      Recall the CEF is the best predictor of $Y_i$ given $X_i$
      generally in a minimum MSE sense.
    }
    and often of greater importance for econometric, modeling, and
    inference purposes, the best linear approximation of the CEF,
    defined
    \begin{align*}
      \mu(x):=\E^{sp}[Y_i|X_i=x]
    \end{align*}
    where $\E^{sp}$ indicates that the expectation is taken over the
    joint superpopulation distribution over outcomes and covariates
    $(Y,X)$.
    To be as general as possible, we allow this CEF to be a
    \emph{nonlinear} function;
    therefore, we will not assume that outcomes are generated by a
    \emph{linear DGP defined by} some parameter vector $\theta$
    and shock $\varepsilon_i$, e.g.
    \begin{align}
      Y_i
      &=
      %D_i\beta
      %+
      %W_i'\gamma
      %+
      %\varepsilon_i
      %=
      X_i'\theta
      +
      \varepsilon_i
      \label{regeq}
    \end{align}
    Rather, $\theta$ and $\varepsilon_i$ will be
    \emph{defined from the DGP} using projections---an enormously
    important distinction.
    In effect, we allow for misspecification in the sense that the CEF
    may not be linear. We must then take extra care to interpret or
    estimator correctly and conduct appropriate inference.

    Defining $\theta$ as the best linear approximation to generally
    nonlinear $\mu(x)$ requires care precisely because of the possible
    nonlinearity in $\mu(x)$.
    Linear regresion will essentially draw a straight line through the
    the function $\mu(x)$, weighting a given point $x$ by some
    distribution for the $X_i$.
    If the function $\mu(x)$ were truly linear, the distribution we use
    for weighting doesn't matter for the fit because the slope is
    constant across the full support of $X_i$ and so we'll estimate the
    very same slope (on average or in the limit) given any set of
    weights.
    But with nonlinear $\mu(x)$, it will matter whether we choose to fit
    the line weighting by the unconditional superpopulation distribution
    of $X_i$ or the conditional empirical distribution given by the
    data matrix $X$.
    So remember that the estimand depends upon the distribution of $X_i$
    that we use for weighting.

    Our choice of weights and estimand then directly determine the type
    of inference about $\hat{\theta}$ that we conduct---namely,
    whether or not we condition on regressors $X$ in our
    sample when thinking about sampling variability of our
    estimators---and the center of either the finite-sample or (more
    typically) the limiting distribution of our estimator.
    But regardless of whether we condition on the regressors or not,
    analysis proceeds the same way, by making sampling assumptions and
    appealing to large $n$ asymptotics to derive an approximate finite
    sample distribution for $\hat{\theta}$.
    But here's more about the two inference perspectives.
    \begin{enumerate}[label=(\alph*)]
      \item Conditional Inference Perspective
        \begin{itemize}
          \item Regression estimand provides the best linear
            approximation to CEF \emph{conditional} on the distribution
            of $X$ in our sample.
            So if the sample $X$ is quite different from the population,
            the estimand might have little exernal validity.

          \item Takes sample $X$ as given and hold fixed over repeated
            samples.
            Sampling uncertainty driven by variability in outcomes
            $Y_i$ given $X_i$.
            Because we condition on $X$, can even allow for arbitrary
            correlation among regressors across units.

          \item
            When deriving the asymptotic distribution, note that the
            data matrix $X$ and the empirical distribution impled by $X$
            change with $n$.
            So we then generally have a \emph{sequence}
            of estimands, changing with $n$ rather than some fixed
            estimand defined off the (unchanging) superpopulation
            distribution, as in unconditional inference.
            But we can still derive an asymptotic distribution, albeit
            using different sampling and regularity conditions.

          \item Typical starting point of regression; perspective
            that underlies Gauss-Markov.

        \end{itemize}

      \item Unconditional inference
        \begin{itemize}
          \item Regression will deliver the best linear approximation to
            the CEF over the \emph{unconditional} distribution of $X_i$
            in the superpopulation.
          \item Do not condition on the $X$ observed in the
            sample.
            Sampling uncertainty driven by variability in $Y|X=x$
            for a given $x$ \emph{and} the variability in drawn $X$.
        \end{itemize}
    \end{enumerate}

  \item
    (\emph{Causal Inference}):
    We would like to assign to the regression estimands some
    \emph{causal} interpretation, i.e. show that they equal some
    meaningful and interpretable weighted average treatment effect, with
    treatment effects defined in terms of potential outcomes a la the
    Rubin Causal Model.

    Sampling variability in estimators may be driven solely by
    (conditional-on-$W_i$) random assignment, i.e.
    \emph{design-based uncertainty}, or by \emph{both} design-based
    uncertainty and sampling-based uncertainty.
    This will have direct implications for inference.
\end{enumerate}
EHW Variance Estimator:
Define
\begin{align*}
  %\hat{\theta}
  %&=
  %\argmin_\theta
  %\sumin
  %(Y_i-X_i'\theta)
  %=
  %(X'X)^{-1}X'Y
  %\\
  %\hat{\beta}
  %&=
  %(\widetilde{D}'\widetilde{D})^{-1}\widetilde{D}'Y
  %\qquad\text{where}\quad
  %%\E[D_i|Y(D),W]=W'\delta
  %\widetilde{D}
  %=
  %D-H_WD
  %\\
  %\hat{\varepsilon}_i
  %&=
  %Y_i-X_i'\hat{\theta}
  %\\
  \hat{V}_{EHW}
  &=
  n(X'X)^{-1}
  \left(
  \sum_i \hat{\varepsilon}^2_i X_iX_i'
  \right)
  (X'X)^{-1}
  \qquad
  \quad
  \hat{V}_{EHW,11}
  =
  n
  \frac{%
    \sumin \hat{\varepsilon}_i^2 \tilde{D}_i^2
  }{%
    \left(\sumin \tilde{D}_i^2\right)^2
  }
\end{align*}
We will consider under which assumptions this is too large, too small,
or just right.



\clearpage
\subsection{Estimands}
First let's define some estimands.
These are all candidates for the limiting $\theta$ for which
$\hat{\theta}$ is consistent under some set of assumptions and
regularity conditions.
For estimands constructed from the sample $\{Y_i,X_i\}_{i=1}^n$ and
corresonding covariate matrix $X$ at hand, I add an $n$ subscript to
emphasize that the estimand will change with $n$ if we take an
asymptotic perspective, which is useful to remember.
\begin{itemize}
  \item (\emph{Descriptive, Unconditional Estimand}):
    Assume that our sample $\calD_n$ is drawn from some superpopulation.
    Then we can define an estimand constructed from the joint
    superpopulation distribution over outcomes and covariates
    $(Y,X)$.
    We use $\E^{sp}$ to denote that teh expectation is taken with
    respect to that superpopulation distribution.
    \begin{align*}
      \theta_{du}
      &:=
      \argmin_{\theta}
      \E^{sp}[(Y_i-X_i'\theta)^2]
      \\
      &\hphantom{:}=
      \argmin_{\theta}
      \E^{sp}[(\mu(X_i)-X_i'\theta)^2]
      \qquad
      \text{LIE}
      \\
      &\hphantom{:}=
      \E^{sp}[X_iX_i']^{-1}
      \E^{sp}[X_iY_i]
      =
      \E^{sp}[X_iX_i']^{-1}
      \E^{sp}[X_i\mu(X_i)]
      \qquad
      \text{Solving FOCs, LIE}
    \end{align*}
    where $\E^{sp}$ indicates that the expectation is taken over the
    joint superpopulation distribution over outcomes and covariates
    $(Y,X)$.
    The subscript $du$ indicates that this is a \emph{descriptive},
    \emph{unconditional} estimand.
    Descriptive because we do not assign it a causal interpretation;
    rather, it simply captures one measure of association between
    outcomes $Y$ and covariates $X$.
    Unconditional because it is defined using the superpopulation
    distribution, not the sample at hand.


  \item
    (\emph{Descriptive, Conditional on $X$ Estimand}):
    Condition on the sample data matrix $X$, define the following
    estimand as the best linear approximation to the CEF for samples
    with identical $X$.
    Adding the argument $X$ emphasizes this point.
    \begin{align*}
      \theta_{dc,n}(X)
      &=
      \argmin_{\theta}
      \frac{1}{n}
      \sum_i
      (\mu(X_i)-X_i'\theta)^2
      =
      (X'X)^{-1}X'\mu(X)
    \end{align*}
    The subscript $dc$ indicates again that this is a \emph{descriptive}
    (non-causal), \emph{conditional} on $X$ estimand.


  \item
    (\emph{Causal, Superpopulation Estimand}):
    Assume $X_i=(D_i,W_i')'$.
    Define the following where the expectation $\E^{D,sp}$ is taken over
    both the random assignment mechanism for $D_i$ and the joint
    superpopulation distribution over
    %potential outcomes, treatment, and covariates
    $(Y_i(d),D_i,W_i)$.
    \begin{align*}
      \theta_{cs}
      =
      (\beta_{cs},\gamma_{cs}')'
      &:=
      \argmin_{\theta}
      \E^{D,sp}[(Y_i-X_i'\theta)^2]
      =
      \E^{D,sp}[X_iX_i']^{-1}
      \E^{D,sp}[X_iY_i]
    \end{align*}
    where $\E^{sp,D}$ indicates that the expectation is taken over
    sampling from the joint superpopulation distribution over outcomes
    and covariates $(Y,X)$ and over random assignment.
    This is a causal estimand because we will make assumptions on the
    assignment mechanism for $D_i$ which allows us to assign a
    causal interpretation to $\beta_{cs}$.

  \clearpage
  \item
    (\emph{Design-Based Finite Sample Estimand}):
    Define the following estimand where the conditional expectation
    $\E^D$ is taken over the random assignment mechanism for $D$
    alone---no random sampling, potential outcomes are fixed for the
    sample at hand---while conditioning on the full set of potential
    outcomes $Y(D)$ and covariates $W$ in the sample.
    %$Y_i=Y_i(D_i)$ is the realized outcome that depends upon random $D_i$.
    \begin{align*}
      \theta_{cf,n}
      &:=
      \argmin_{\theta}
      \E^D\left[
        \sum_{i=1}^n
        (Y_i-X_i'\theta)^2
        \,\bigg|\,Y(D),W
      \right]
      =
      \E^D
      \left[
      {X}_i{X}_i'
      \,|\,
      Y(D),W
      \right]^{-1}
      \E^D
      \left[
      {X}_iY_i
      \,|\,
      Y(D),W
      \right]
    \end{align*}
\end{itemize}
Each (generally distinct) estimand definition in turn defines a
(generally unique) error:
\begin{align*}
  \varepsilon_{\ell,i}
  &:=
  Y_i-X_i'\theta_{\ell}
  \qquad
  \ell\in\{(du), (dc,n), (cs), (cf,n)\}
\end{align*}
From there, we can rearrange and sub into the OLS formula to rewrite the
estimator in preparation for asymptotic analysis:
\begin{align*}
  \sqrt{n}
  (
  \hat{\theta}
  -
  \theta_{\ell}
  )
  =
  (X'X/n)^{-1}
  \frac{1}{\sqrt{n}}
  \sumin
  X_i
  \underbrace{%
    (Y_i-X_i'\theta_{\ell})
  }_{\varepsilon_{\ell,i}}
\end{align*}
Under different sampling and regularity assumptions on the terms in the
sum, we can then derive corresponding limiting distributions.


\clearpage
\subsection{Assumptions for Inference}

\paragraph{Sampling Assumptions}
These are necessary for characterizing
\emph{sampling-based uncertainty}, where randomness in our estimators is
induced by random sampling, as opposed to design-based uncertainty
(although these two kinds of uncertainty can often both be relevant).
If we assume $n\ra\infty$, the randomness induced by sampling can be
approximated by a normal law according to some CLT, which we can use for
inference about regression estimands.
The assumptions will help ensure that we can apply some CLT.
\begin{enumerate}[label=(\roman*)]
  \item[S1.]
    (\emph{Random Sampling}):
    $(Y_i,X_i)$ iid from superpop.

    This ensures we have external validity for extrapolating from sample
    to superpopulation.

    Note that this assumption might still be used for
    conditional inference.
    It simply says how the $X$ that we condition on were
    generated---namely, independently and identically distributed across
    units.
    This is a bit stronger than needed (although it makes the
    asymptotic distributions of estimators easier to derive since we can
    use the Lindeberg-Levy iid CLT); therefore, the next condition is
    also presented as a relaxation that is still nonetheless sufficient
    for asymptotically normal limiting distributions of estimators under
    conditional inference.

    Similarly, this assumptions might still be used for causal
    inference on top of the inherent design-based uncertainty that's
    already there.

  \item[S2.]
    (\emph{Conditional Sampling}):
    Conditional on $X$, the $Y_i$ are independent with
    mean $\mu(X_i)$.

    Relative to S1, the $X_i$ can now be correlated arbitrarily across
    units, rather than iid.

\end{enumerate}
\paragraph{Regularity Assumptions to Apply CLTs under Sampling}
\begin{enumerate}
  \item[R1.] For unconditional inference
    (which only makes sense under S1)
    \begin{enumerate}[label=(\roman*)]
      \item $\E[X_iX_i']^{-1}$ exists and full rank
      \item $(Y_i,X_i)$ have finite 4th moments
    \end{enumerate}
  \item[R2.] For conditional inference under S1.
    This is slightly weaker than R1, but sufficient for consistency and
    asymptotic normality if we wish only to do conditional on $X$
    inference.
    \begin{enumerate}[label=(\roman*)]
      \item $X_i$ has finite 2nd moment
      \item $\Var(Y_i|X_i)<\infty$
    \end{enumerate}
  \item[R3.] For conditional inference under S2
    \begin{enumerate}[label=(\roman*)]
      \item $X'X/n$ and $\calV_{dc,n}$ each converge to some positive
        definite limits
      \item $\E[|Y_i-\mu(X_i)|^{2+\eta}|X]$ bounded for some $\eta>0$
        and
        $\max_i H_{ii}\ra 0$ or $\max_i \tilde{H}_{ii}\ra 0$
        for inference on $\theta_{dc}$ or $\beta_{dc}$ respectively.
        The assumptions ensure that we can invoke the Lindberg-Feller
        (or really, the Lyapunov) CLT.
    \end{enumerate}
\end{enumerate}

\clearpage
\paragraph{Assignment Mechanism Assumptions}
These assumptions on the the assignment mechanism are needed to assign
the regression estimands a causal interpretation and to characterize the
\emph{design-based uncertainty} inherent in our regression estimators.

Throughout, we restrict to
\emph{binary treatment},\footnote{%
  Binary treatment can be relaxed, but it
  makes proofs easier.
  Otherwise, instead of a weighted average of $\tau_i$'s, our
  estimands might be a weighted average of derivatives.
}
which implies realized outcomes derived from potential outcomes as
follows:
\begin{align*}
  Y_i = Y_i(D_i)=Y_i(0)+D_i\tau_i
  .
\end{align*}
Assumptions we will employ:
\begin{enumerate}
  \item[C1.]
    (\emph{Random Assignment in Superpopulation}):
    The propensity score is a linear function of one's own covariates
    $W_i$ and does not depend upon own or others' potential outcomes:
    \begin{align*}
      P[D_i=1|Y_i(1),Y_i(0),W_i]
      =
      P[D_i=1|W_i]
      =
      \E[D_i|W_i]
      =W_i'\delta
    \end{align*}
  \item[C2.]
    (\emph{Random Assignment in Finite Population}):
    Conditional on $Y(D),W$ (the full set of potential outcomes and
    regressors for all units in sample), $D_i$ independent across
    $i$ and
    \begin{align*}
      P[D_i=1|Y(D),W]
      =E[D_i|Y(D),W]
      =E[D_i|W_i]
      =W_i'\delta
    \end{align*}
    By independence, $P[D_i=1|Y(D),W]$ is enough to characterize the
    \emph{joint} distribution $P[D|Y(D),W]$ of treatment assignments.
\end{enumerate}
Note
\begin{itemize}
  \item
    These assumptions ensure that controlling for $W_i$ \emph{linearly}
    is enough to ensure as good as random assignment, hence OLS will
    recover a causal estimand.
  \item
    If we instead assume that controlling for $W_i$
    is enough but \emph{only} if controlled for
    \emph{nonparametrically} (i.e. the unconfoundedness assumption),
    we should dispense with linear regression altogether and
    instead use nonparametric regression adjustments or propensity
    score methods to construct a consistent estimator of some weighted
    average of causal effects that has a clear interpretation.
    Otherwise, OLS estimates \emph{some} weighted average of causal
    effects, with strange, uninterpretable weights.
  \item
    If, even worse, it's not even enough to control for covariates, we
    need to take an IV approach and content ourselves with some
    weighted average of LATEs.
\end{itemize}
\paragraph{Regularity Assumptions for Inference under Strictly Design-Based Uncertainty}
\begin{itemize}
  \item $n^{-1}\sumin \lVert W_i\rVert^{4+\eta}$ bounded
  \item $n^{-1}\sumin \E[Y_i|Y(D),W]^{4+\eta}$ bounded
  \item $n^{-1}\sumin \E[D_i^{4+\eta}|W_i]$ bounded
  \item $\E[X'X|W]/n$ coverges to a positive definite limit.
\end{itemize}


\clearpage
\subsection{Sampling Based Inference}

\paragraph{Unconditional Inference under iid Sampling of $(Y_i,X_i)$ from Superpop.}
Under S1 and R1, we are consistent for the estimand $\theta_{du}$,
and can apply Lindeberg-Levy to obtain
\begin{align*}
  \sqrt{n}(\hat{\theta}-\theta_{du})
  =
  (X'X/n)^{-1}
  \frac{1}{\sqrt{n}}
  \sumin
  X_i
  \underbrace{%
    (Y_i-X_i'\theta_{du})
  }_{\varepsilon_{du,i}}
  &
  \; \dto\;
  \calN\big(
    0,\,
    \underbrace{%
    \E^{sp}[X_iX_i']^{-1}
    \;
    \E^{sp}\big[\varepsilon^2_{du,i}\,X_iX_i'\big]
    \;
    \E^{sp}[X_iX_i']^{-1}
    }_{\calV_{du}}
  \big)
\end{align*}
We see from the term in the sum why we need finite fourth moments:
to apply the LLN for consistency and Lindeberg-Levy for asymptotic
normality.

Additionally, under further regularity conditions $\hat{V}_{EHW}$ is
consistent for $\calV_{du}$.


\paragraph{Quasi-Conditional Inference, iid Sampling of $(Y_i,X_i)$ from Superpopulation}
%This is considered in Abadie et al in ``Inference for Misspecified
%Models with Fixed Regressors.''
Under S1 and R2, we are consistent for the estimand
$\theta_{dc,n}(X)=(X'X)^{-1}X'\mu(X)$,
and obtain the following limiting distribution of our estimator by
the Lindeberg-Levy CLT, which we can apply since the terms of the
sum are mean zero and (under S1) iid:
\begin{align*}
  \sqrt{n}(\hat{\theta}-\theta_{dc,n}(X))
  &=
  (X'X/n)^{-1}
  \frac{1}{\sqrt{n}}
  \sum_i
  X_i
  %\underbrace{%
    (Y_i-\mu(X_i))
  %}_{\varepsilon_{cf,i}}
  \; \dto\;
  \calN\big(
    0,
    \underbrace{%
    \E^{sp}[X_iX_i']^{-1}
    \E^{sp}[\Var(Y_i|X_i)X_iX_i']
    \E^{sp}[X_iX_i']^{-1}
    }_{\calV_{dc}}
  \big)
\end{align*}
And because $\varepsilon_{dc,n,i}=Y_i-X_i'\theta_{dc,n}$, it's clear
that $\Var(Y_i|X_i)=\Var(\varepsilon_{dc,n,i}|X_i)$, which we can use to
rewrite the middle expectation in $\calV_{dc}$.

A note about these asymptotics.
The random sampling induces a random sequence of
$\calD_n=\{Y_i,X_i\}_{i=1}^n$ and thus a random sequence of
estimands, $\theta_{dc,n}(X)$ each built from $\calD_n$.
And so $\sqrt{n}(\hat{\theta}-\theta_{dc,n}(X))$ is a difference of two
random objects, unlike $\sqrt{n}(\hat{\theta}-\theta_{du})$ where
$\theta_{du}$ is a fixed object defined from the superpopulation
distribution.
But deriving the asymptotic distribution under random sampling
assumption S1 is still easy since the terms in the sum are still
independent, mean-zero RVs.
And then we can see from the term in the sum why we only need R2
rather than R1 to apply the LLN and Lindeberg-Levy.

We can also relate $\calV_{du}$ and $\calV_{dc}$---both asymptotic
variances under random sampling assumption S1.
In particular, it can be shown that
\begin{align*}
  \E[\varepsilon^2_{du,i}|X_i]
  &=
  \Var(Y_i|X_i) + (\mu(X_i)-X_i'{\theta}_{du})^2
\end{align*}
Therefore,
\begin{align*}
  \calV_{du}
  &=
  \E[X_iX_i']^{-1}
  \;
  \E\big[\varepsilon^2_{du,i}\,X_iX_i'\big]
  \;
  \E[X_iX_i']^{-1}
  =
  \E[X_iX_i']^{-1}
  \;
  \E\big[\E[\varepsilon^2_{du,i}|X_i]\,X_iX_i'\big]
  \;
  \E[X_iX_i']^{-1}
  \\
  &=
  \E[X_iX_i']^{-1}
  \;
  \E\big[\Var(Y_i|X_i)\,X_iX_i'\big]
  \;
  \E[X_iX_i']^{-1}
  +
  \E[X_iX_i']^{-1}
  \;
  \E\big[(\mu(X_i)-X_i'\theta_{du})^2\,X_iX_i'\big]
  \;
  \E[X_iX_i']^{-1}
  \\
  &=
  \calV_{dc}
  +
  \E[X_iX_i']^{-1}
  \;
  \E\big[(\mu(X_i)-X_i'\theta_{du})^2\,X_iX_i'\big]
  \;
  \E[X_iX_i']^{-1}
\end{align*}
Since $\hat{V}_{EHW}$ is consistent for $\calV_{du}$ under random
sampling S1, it is clear from the above expression that
EHW standard errors will be \emph{too large} for conditional inference
unless the true (generally nonlinear) regression function $\mu(X_i)$ is,
in fact, linear.
This suggests using the difference between $\calV_{du}$ and
$\calV_{dc}$ as one measure of nonlinearity in $\mu(X_i)$.

Abadie et al (2014) propose an alternative variance estimator based on
nearest neighbor matching that is consistent for $\calV_{dc}$ and hence,
more appropriate (not conservative).



\begin{enumerate}

  \item
    (\emph{Conditional Inference, Independent Conditional Sampling of $Y_i|X_i$}):
    Rather than use S1 which requires the $X_i$ to be iid, we can weaken
    to conditional sampling S2.
    In particular, under under S2 and R3,
    \begin{align*}
      \sqrt{n}(\hat{\theta}-\theta_{dc,n}(X))
      &=
      (X'X/n)^{-1}
      \frac{1}{\sqrt{n}}
      \sum_i
      X_i
      %\underbrace{%
        (Y_i-\mu(X_i))
      %}_{\varepsilon_{cf,i}}
      \\
      &\sim
      \;
      \calN\big(
        0,
        \underbrace{%
          n(X'X)^{-1}
          \left(
          \sum_i
          \Var(Y_i|X_i)\,X_iX_i'
          \right)
          (X'X)^{-1}
        }_{=:\calV_{dc,n}}
      \big)
      +
      o_p(1)
    \end{align*}
    To prove, rewrite in preparation of applying the Lindeberg-Feller
    CLT:
    \begin{align*}
      \sqrt{n}(\hat{\theta}-\theta_{dc,n}(X))
      %&=
      %(X'X/n)^{-1/2}
      %\sumin
      %(X'X)^{-1/2}
      %X_i
      %(Y_i-\mu(X_i))
      %\\
      &=
      \sumin
      \sqrt{n}
      (X'X)^{-1}
      X_i
      (Y_i-\mu(X_i))
    \end{align*}
    We already have independence of the terms in the sum.
    To apply the Lindeberg-Feller CLT, we must also verify that the sum
    of the variances of the terms of the sum converge to some limit.
    Since we're doing conditional-on-$X$ inference, the variances will
    also be conditional on $X$.
    \begin{align*}
      %\sumin
      %\Var\left(
      %(X'X)^{-1/2}
      %X_i
      %(Y_i-\mu(X_i))
      %\;\big|\;
      %X
      %\right)
      %&=
      %(X'X)^{-1/2}
      %\left(
      %\sumin
      %\Var\left(
      %Y_i
      %\,|\,
      %X
      %\right)
      %X_i
      %X_i'
      %\right)
      %(X'X)^{-1/2}
      %\\
      \sumin
      \Var\left(
      \sqrt{n}
      (X'X)^{-1}
      X_i
      (Y_i-\mu(X_i))
      \;\big|\;
      X
      \right)
      &=
      n
      \sumin
      (X'X)^{-1}
      \Var\left(
      Y_i
      \,\big|\,
      X
      \right)
      X_i
      X_i'
      (X'X)^{-1}
      =
      \calV_{dc,n}
    \end{align*}
    We assume that this converges to some limit.
    Together with the assumption that $X'X/n$ converges to some limit,
    a simple sufficient condition for this is that, say,
    $\Var(Y_i|X_i)<C$ for some constant $C$.

    Together with the other regularity conditions,
    by Lindeberge-Feller CLT,
    \begin{align*}
      \sqrt{n}(\hat{\theta}-\theta_{dc,n}(X))
      &=
      (X'X/n)^{-1/2}
      \sumin
      (X'X)^{-1/2}
      X_i
      (Y_i-\mu(X_i))
      &\dto
      \calN\left(
      0,\,
      \lim_{n\ra\infty}
      \calV_{dc,n}
      \right)
    \end{align*}


\end{enumerate}




\clearpage
\subsection{Causal Inference}

\begin{enumerate}
  \item
    (\emph{Alternative Estimator Expressions}):
    For proving that some estimand is, in fact, a weighted average of
    causal effects, it is convenient to define the following expression
    \begin{align*}
        \ddot{D}_i
        &:=
        D_i-W_i'\delta
        \\
        \ddot{X}_i
        &:=
        (\ddot{D}_i,W_i')'
    \end{align*}
    where, recall, $\delta$ is the parameter vector characterizing the
    propensity score in Assumptions C1 and C2.
    This makes $\ddot{D}$ mean zero.

    Recall that we defined the regression estimands
    \begin{align*}
      \theta_{cs}
      =
      (\beta_{cs},
      \gamma_{cs}')'
      &:=
      \E^{D,sp}[X_iX_i']^{-1}
      \E^{D,sp}[X_iY_i]
      \\
      \theta_{cf,n}
      =
      (\beta_{cf,n},
      \gamma_{cf,n}')'
      &:=
      \E^D\left[ {X}_i{X}_i' \,|\, Y(D),W \right]^{-1}
      \E^D \left[ {X}_iY_i \,|\, Y(D),W \right]
    \end{align*}
    Note that we can show
    \begin{align*}
      \beta_{cs}
      &=
      e_1'
      \E^{D,sp}[\ddot{X}_i\ddot{X}_i']^{-1}
      \E^{D,sp}[\ddot{X}_iY_i]
      \\
      \gamma_{cs}
      &=
      \hphantom{e_1'}
      \E^{D,sp}[{W}_i{W}_i']^{-1}
      \E^{D,sp}[{W}_i(Y_i-D_i\beta_{cs})]
      \\
      \beta_{cf,n}
      &=
      e_1'
      \E^{D}[\ddot{X}_i\ddot{X}_i'\,|\,Y(D),W]^{-1}
      \E^{D}[\ddot{X}_iY_i\,|\,Y(D),W]
      \\
      \gamma_{cf,n}
      &=
      \hphantom{e_1'}
      \E^{D}[{W}_i{W}_i'\,|\,Y(D),W]^{-1}
      \E^{D}[{W}_i(Y_i-D_i\beta_{cf,n})\,|\,Y(D),W]
      \\
      &=
      \hphantom{e_1'}
      (W'W)^{-1}
      \sumin
      {W}_i
      \E^{D}[(Y_i-D_i\beta_{cf,n})\,|\,Y(D),W]
    \end{align*}
    Notice that for design-based inference about $\theta_{cf,n}$, only
    $D_i$ or $\ddot{D}_i$ (or $X_i$ and $\ddot{X}_i$ which contains it)
    sit in the expectation since covariates and potential outcomes are
    fixed for the current sample.


  \item
    (\emph{Causal Inference under iid Sampling from Superpopulation}):
    Suppose that Assumptions S1 and R1 hold.
    Then, as argued above,
    \begin{align*}
      \sqrt{n}(\hat{\theta}-\theta_{du})
      =
      (X'X/n)^{-1}
      \frac{1}{\sqrt{n}}
      \sumin
      X_i
      \underbrace{%
        (Y_i-X_i'\theta_{du})
      }_{\varepsilon_{du,i}}
      &
      \; \dto\;
      \calN\big(
        0,\,
        \underbrace{%
        \E[X_iX_i']^{-1}
        \;
        \E\big[\varepsilon^2_{du,i}\,X_iX_i'\big]
        \;
        \E[X_iX_i']^{-1}
        }_{\calV_{du}}
      \big)
    \end{align*}
    Additionally under C1, $\E=\E^{D,sp}$ so that
    \begin{align*}
      \theta_{cs}=\theta_{du}
      \qquad
      \qquad
      \calV_{cs}=\calV_{du}
    \end{align*}
    If we further assume binary treatment, we can obtain the
    following expression for $\beta_{cs}=\beta_{du}$, which gives the
    estimand a causal interpretation as a weighted average of causal
    effects with known weights:
    \begin{align*}
      \beta_{cs}
      =
      \beta_{du}
      =
      \E[\lambda(W_i)\tau(W_i)]
      \qquad\text{where}\quad
      \tau(w)
      &=
      \E[\tau_i|W_i=w]
      \\
      \lambda(w)
      &=
      \frac{%
        \Var(\ddot{D}_i|W_i=w)
      }{%
        \E[\Var(\ddot{D}_i|W_i=w)]
      }
      =
      \frac{%
        \Var({D}_i|W_i=w)
      }{%
        \E[\Var({D}_i|W_i=w)]
      }
    \end{align*}
    To prove, use the definition of $\beta_{cs}$, which means computing
    the following moments under Assumption C1:
    \begin{align*}
      \E[\ddot{D}_iY_i]
      &=
      \E\big[
        \ddot{D}_i
        \big(Y_i(0)+D_i\tau_i\big)
      \big]
      =
      \E\big[
        \E
        \big[
        \ddot{D}_i
        \big(Y_i(0)+D_i\tau_i\big)
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
      \big]
      \\
      &=
      \E\big[
        \E
        \big[
        \ddot{D}_iY_i(0)
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
      \big]
      +
      \E\big[
        \E
        \big[
        \ddot{D}_iD_i\tau_i
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
      \big]
      \\
      &=
      \E\big[
        \E
        \big[
        \ddot{D}_i
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
        \cdot
        \E
        \big[
        Y_i(0)
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
      \big]
      +
      \E\big[
        \E
        \big[
        \ddot{D}_i
        D_i
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
        \cdot
        \E
        \big[
        \tau_i
        \,|\,
        Y_i(0),Y_i(1),W_i
        \big]
      \big]
      \\
      &=
      \E\big[
        \E
        \big[
        \ddot{D}_i
        \,|\,
        W_i
        \big]
        \cdot
        \E
        \big[
        Y_i(0)
        \,|\,
        W_i
        \big]
      \big]
      +
      \E\big[
        \E
        \big[
        \ddot{D}_i
        D_i
        \,|\,
        W_i
        \big]
        \cdot
        \E
        \big[
        \tau_i
        \,|\,
        W_i
        \big]
      \big]
      \\
      &=
      \E\big[
        0
        \cdot
        \E
        \big[
        Y_i(0)
        \,|\,
        W_i
        \big]
      \big]
      +
      \E\big[
        \E
        \big[
        \ddot{D}_i^2
        \,|\,
        W_i
        \big]
        \cdot
        \tau(W_i)
      \big]
      \\
      &=
      \E\big[
        \Var
        \big(
        \ddot{D}_i
        \,|\,
        W_i
        \big)
        \cdot
        \tau(W_i)
      \big]
      \\
      \E[\ddot{X}_i\ddot{X}_i']
      &=
      \E
      \begin{bmatrix}
        \ddot{D}_i^2
        &
        \ddot{D}_iW_i'
        \\
        \ddot{D}_iW_i
        &
        W_iW_i'
      \end{bmatrix}
      =
      \E
      \left[
      \E
      \left[
      \begin{matrix}
        \ddot{D}_i^2
        &
        \ddot{D}_iW_i'
        \\
        \ddot{D}_iW_i
        &
        W_iW_i'
      \end{matrix}
      \;
      \bigg|
      \;
      W_i
      \right]
      \right]
      =
      \begin{pmatrix}
        \E[\Var(\ddot{D}_i|W_i)]
        &
        0
        \\
        0
        &
        \E[W_iW_i']
      \end{pmatrix}
      \\
      {\theta}_{cs}
      &=
      \E[\ddot{X}_i\ddot{X}_i']^{-1}
      \E[\ddot{X}_i{Y}_i]
      =
      \begin{pmatrix}
        \E[\Var(\ddot{D}_i|W_i)]^{-1}
        &
        0
        \\
        0
        &
        \E[W_iW_i']^{-1}
      \end{pmatrix}
      \begin{pmatrix}
        \E[\ddot{D}_iY_i]
        \\
        \E[W_iY_i]
      \end{pmatrix}
      \\
      \beta_{cs}
      &=
      \E\left[
        \frac{%
          \Var(\ddot{D}_i|W_i)
        }{%
          \E[\Var(\ddot{D}_i|W_i)]
        }
        \tau(W_i)
      \right]
    \end{align*}
    Finally, notice $\Var(\ddot{D}_i|W)=\Var(D_i|W_i)$.

    A few remarks
    \begin{itemize}
      \item With no controls and binary treatment, assignment is truly
        random and so $\beta_{cs}=\E[\tau_i]$, i.e. no weighting.
        Moreover, the variance expression reduces to
        \begin{align*}
          \calV_{du}
          &=
          \frac{S_0^2}{n_0/n}
          +
          \frac{S_1^2}{n_1/n}
          +
          o_p(1)
        \end{align*}

      \item If we would like to estimate unweighted $\E[\tau_i]$,
        we cannot simply do standard OLS regression since it converges
        to $\beta_{cs}=\E[\lambda(W_i)\tau(W_i)]$, as argued.
        Instead, we must reweight because of the selection.


      \item However, the OLS estimand is optimal in the following sense:
        Among all weighted average treatment effects
        $\E[\tilde{\lambda}(W_i)\tau(W_i)]$ where $\tilde{\lambda}(w)$
        is some weighting function we may choose,
        under homoskedasticy $\Var(Y_i|D_i,W_i)=\sigma^2$,
        the OLS estimand with its particular weighting function
        $\lambda(w)$ derived above has the smallest asymptotic variance
        among all weighting functions $\tilde{\lambda}(w)$.

        For intuition, notice from the expression for the weights that
        we upweight those values $w$ such that $\Var(D_i|W_i=w)$ is
        largest (the denominator just normalizes the weights).
        This might seem counterintuitive, but note the variance is
        maximized when binary $D_i$ has probability close to 0.5.
        Thuse we upweight those values of $w$ for which the proportion
        of treatment and control is most balanced, i.e. those values of
        $w$ for which we can most precisely estimate the conditional
        average treatment effect $\E[\tau_i|W_i=w]$.

        Under homoskedasticity of outcomes, this weighting scheme is a
        good thing to do because the precision of our estimates for
        $\E[\tau_i|W_i=w]$ is \emph{solely} determined by the balance
        between treatment and control, not also the conditional variance
        of outcomes.
        Therefore, homoskedasticy is necessary for the estimand to be
        optimal.
        Otherwise, under conditional heteroskedasticity, we'd also want
        to use the conditional variance of outcomes/treatment effects to
        determine the weights in the estimand because there's no use
        upweighting a value $w$ with good balance if the conditional
        heteroskedasticity at that value of $w$ is large.
        Therefore, with heteroskedasticity, the optimal (minimum
        asymptotic variance) weighted average treatment effect estimand
        would take into account both $\Var(D_i|W_i=w)$ and the
        conditional variance $\Var(Y_i|D_i,W_i)$, while the optimal
        estimator would accordingly weight the observations, i.e. be a
        WLS estimator rather than OLS.
    \end{itemize}


  \item
    (\emph{Causal Inference, Strictly Design Based Uncertainty}):
    If we consider only design-based uncertainty, we don't need any
    sampling assumptions, only an assumption on the assignment
    mechanism.
    In particular, assuming binary treatment and C2, $\beta_{cf}$ can
    also be assigned a causal interpretation as a weighted average of
    casual effects with known weights.
    After substituting in and working out the expectations,
    we get an expression that is simply the sample analog of what we had
    in Result 4 (which is unsurprising since the sample is now the
    population):
    \begin{align*}
      \beta_{cf,n}
      &:=
      \sumin
      \left(
      \frac{%
        \sigma^2_D(W_i)
      }{%
        \sumjn \sigma^2_D(W_j)
      }
      \right)
      \tau_i
      \qquad\text{where}\quad
      \sigma^2_D(W_i)
      :=
      \Var(D_i|W_i)
    \end{align*}
    Recall that $\tau_i$ is fixed, the only uncertainty is in the
    assginment vector $D$.

\end{enumerate}

\clearpage
blah

\clearpage
For causal inference, it will also be useful to define the following,
based on recentering $D_i$, for some fixed real vector
$\delta$,\footnote{%
  We will discuss this vector later when we get to the causal inference
  results.
  But for now, just take $\delta$ as some given fixed vector; the
  definitions can still be stated.
}
For causal inference on the superpopulation taking into account
uncertainty from both random assignment and sampling, define the
following estimands constructed from the joint superpopulation
distribution over $(Y_i,X_i)$.
Later, we will show $\theta_{cs}=\theta_{du}$ (i.e. these can be
motivated as OLS estimands) and that these have a causal interpretation.
\begin{align*}
    %\ddot{\theta}_{cs}
    %=
    (\beta_{cs},\ddot{\gamma}_{cs}')'
    &:=
    \E[\ddot{X}_i\ddot{X}_i']^{-1}\E[\ddot{X}_iY_i]
    \\
    \gamma_{cs}
    &:=
    \E[W_iW_i']^{-1}
    \E[W_i(Y_i-D_i\beta_{cs})]
    \\
    \theta_{cs}
    &:=
    (\beta_{cs},\gamma_{cs})
\end{align*}
Next, define the following quantities, where again, the expectations in
the expectation are taken over random assignment only, not sampling.
Later, we will show $\theta_{cf}=\theta_{df,n}$ (i.e. these can be
motivated as OLS estimands) and that these have a causal interpretation.
\begin{align*}
    %\ddot{\theta}_{cf}
    %=
    (\beta_{cf},\ddot{\gamma}_{cf}')'
    &:=
    \E\left[
    \ddot{X}_i\ddot{X}_i'
    \,|\,
    Y(D),W
    \right]^{-1}
    \E
    \left[
    \ddot{X}_iY_i
    \,|\,
    Y(D),W
    \right]
    \\
    &\hphantom{:}=
    \begin{pmatrix}
      \E[
      \ddot{D}_i^2
      \,|\,
      Y(D),W
      ]
      &
      \E[
      \ddot{D}_i
      \,|\,
      Y(D),W
      ]
      W_i'
      \\
      \E[
      \ddot{D}_i
      \,|\,
      Y(D),W
      ]
      W_i
      & W_iW_i'
    \end{pmatrix}^{-1}
    \begin{pmatrix}
    \E
    \left[
    \ddot{D}_iY_i(D_i)
    \,|\,
    Y(D),W
    \right]
    \\
    W_i
    \E
    \left[
    Y_i(D_i)
    \,|\,
    Y(D),W
    \right]
    \end{pmatrix}
    \\
    \gamma_{cf}
    &:=
    \left[
    \sumin
    W_iW_i'
    \right]^{-1}
    \left[
    \sumin
    W_i
    \E\big[
    (Y_i-D_i\beta_{cf})
    \,|\,
    Y(D),W
    \big]
    \right]
    \\
    &\hphantom{:}=
    (W'W)^{-1}
    \left[
    \sumin
    W_i
    \E\big[
    (Y_i(D_i)-D_i\beta_{cf})
    \,|\,
    Y(D),W
    \big]
    \right]
    \\
    \theta_{cf}
    &:=
    (\beta_{cf},\gamma_{cf})
    \\
    \varepsilon_{cf,i}
    &:=
    Y_i-X_i'\theta_{cf}
    =
    Y_i
    -D_i\beta_{cf}
    -W_i'\gamma_{cf}
\end{align*}
%\begin{align*}
    %\gamma_{cf}
    %&:=
    %(W'W)^{-1}
    %W'\E[(Y-D\beta_{cf}) \,|\,W,Y(0)]
    %\\
    %&=
    %(W'W)^{-1}
    %\sumin
    %W_i\E[(Y_i-D_i\beta_{cf})\,|\,W,Y(0)]
    %\\
    %=
    %(W'W)^{-1}
    %\sumin
    %W_i
    %\big(
    %Y_i(0)
    %+
    %\E[D_i|W,Y(0)]
    %\cdot(\tau_i-\beta_{cf})
    %\big)
%\end{align*}



\clearpage

\clearpage
\paragraph{Results}
\begin{enumerate}

  \item


  \item
    Moreover, note that
    \begin{itemize}
      \item ${\beta}_{cs}=\beta_{du}$
        because $\ddot{D}_i$ is simply a recentering of $D_i$ using
        a linear function of covariates $W_i$ already in the regression.
        In other words,
        the coefficient on $\ddot{D}_i$ in the regression of $Y_i$ on
        $\ddot{X}_i$ equals the coefficient on $D_i$ in the regression of
        $Y_i$ on $X_i$.
      \item $\gamma_{cs}=\gamma_{du}$.
        This follows because
        \begin{align*}
          Y_i = D_i\beta_{du}+W_i'\gamma_{du} + \varepsilon_{du,i}
        \end{align*}
        Therefore, regressing $Y_i-D_i\beta_{du}$ on $W_i$ alone will
        recover the same parameter $\gamma_{du}$ that we get from regressing
        $Y_i$ on $X_i=(D_i,W_i')'$.
      \item
        $\theta_{cs}=(\beta_{cs},\gamma_{cs}')'=(\beta_{du},\gamma_{du}')'=\theta_{du}$
        by the previous bullet points.
    \end{itemize}

  \item
    First note that the definition of
    $\theta_{cf}=(\beta_{cf},\gamma_{cf}')'$ can be motivated as
    the regression estimand $\theta_{df,n}$.
    In particular,
    \begin{itemize}
      \item ${\beta}_{cf}=\beta_{df,n}$
        because $\ddot{D}_i$ is simply a recentering of $D_i$ using
        a linear function of covariates $W_i$ already in the regression.
      \item $\gamma_{cf}=\gamma_{df,n}$.
        This follows because
        \begin{align*}
          Y = D\beta_{df,n}+W'\gamma_{df,n} + \varepsilon_{df,n}
        \end{align*}
        Therefore, regressing $Y_i-D_i\beta_{df,n}$ on $W_i$ alone will
        recover the same parameter $\gamma_{df,n}$ that we get from
        regressing $Y_i$ on $X_i=(D_i,W_i')'$.
      \item
        $\theta_{df,n}=(\beta_{df,n},\gamma_{df,n}')'=(\beta_{cf},\gamma_{cf}')'=\theta_{cf}$
        by the previous bullet points.
    \end{itemize}


\end{enumerate}






\clearpage
Ideas
\begin{itemize}
  \item Start with inference about the mean under treatment.
    Can get unbiased estimator for this.
    For inference, there's the probability that a center treats both, vs
    treated by different centers.

  \item Rewrite sums from $i=1,\ldots,n$ as sum over clusters or pseudo
    clusters
  \item There is an equivalence class of clusters defined by distance.
    This location will ensure that a given pair is treated.
    This set of locations will ensure that a given pair is treated.
  \item Guido when to cluster paper, see what it says about causal
    inference.
\end{itemize}



\clearpage
\section{Other CLTs}

\subsection{de Jong CLT}

Mixingale: asymptotically weak dependence

Objects
\begin{itemize}
  \item $n$ is sample size, $t$ is index within a sample of a given size
    $n$

  \item $\calH_{n,t}$ is an array of $\sigma$-fields that is increasing
    in $t$ for each $n$.
    That is, as index $t$ within a sample increases, we get more
    information.

  \item $X_{nt}$ is a triangular array of RVs defined on
    $(\Omega,\sF,P)$

  \item Let $\lVert X\rVert_p=\E[|X|^p]^{1/p}$

  \item Triangular array $\{X_{nt},\calH_{nt}\}$ is a $L_2$ mixingale
    if, for $m\geq 0$, we have
    \begin{enumerate}
      \item
        The MSE betweeen $X_{nt}$ and its expectation given information
        up to time $t+m$
        \begin{align*}
          \lVert
          X_{nt} -\E[X_{nt}|\calH_{n,t+m}]
          \rVert_2
          &\leq
          a_{nt}\psi(m+1)
        \end{align*}

      \item
        \begin{align*}
          \lVert
          \E[X_{nt}|\calH_{n,t-m}]
          \rVert_2
          &\leq
          a_{nt}\psi(m)
        \end{align*}
    \end{enumerate}
    and $\psi(m)\ra\infty$ as $m\ra\infty$.

\end{itemize}


\clearpage
\section{Misc}

Identification defn: Define param of interest and provide conds under
which it is uniquely estimable in some objective sense (superpop or
finite sample)


\clearpage
\section{Causal Inference}

\subsection{Introduction}

Outline
\begin{itemize}
  \item Potential Outcomes:
    \begin{itemize}
      \item Definition of potential outcomes
      \item They are random and have some joint distribution.
    \end{itemize}


  \item Causal Effects/Estimands
    \begin{itemize}
      \item Unit causal effects, generally heterogeneous.
        In contrast to linear model.
      \item Average causal effects
    \end{itemize}

  \item Identification
    \begin{itemize}
      \item Missing data problem, need assumptions.
        Example: Selection bias, confounded causal effect.
    \end{itemize}
    Two strategies
    \begin{itemize}
      \item Assumptions on DGP.
        Functional form and homogeneity assumptions, like linearity or constant treatment effects across individuals and/or time

      \item Assumptions on the assignment mechanism:
        Make assumptions about how individuals are selected for
        treatment.
    \end{itemize}

  \item
    Estimation:
    Almost an afterthought. The real difficulty is in getting to
    identification.
\end{itemize}



\clearpage
\subsection{Potential Outcomes}

SUTVA:
Stable unit treatment value assumption, i.e.
$(Y_{0i},Y_{1i})\perp D_j$ so no ``interference'' across
individuals.
Potential outcomes for $i$ unaffected by treatment of other
units $j$.



\clearpage
\subsection{Causal Effects/Estimands}

Quantities of Interest, defined in terms of potential outcomes.
\begin{itemize}
  \item ATE, ATET, CATE
    \begin{align*}
      \alpha_{ATE}
      &=\E[Y_1-Y_0]
      \\
      \alpha_{ATET}
      &=\E[Y_1-Y_0|D=1]
      \\
      \alpha_{CATE}(x)
      &=\E[Y_1-Y_0|X=x]
    \end{align*}
  \item QTE: $\alpha_{QTE,\tau}=Q_\tau(Y_1)-Q_\tau(Y_0)$
\end{itemize}
Note:
These objects are always well-defined and do not require a DGP or
regressio equation because, for any observation $i$,  we can always
think of there existing some potential outcomes.
So it's always possible to define these conditional moments of
potential outcomes.
The challenge lies in \emph{identification}, i.e. connecting these
unobserved outcomes $Y_1$ and $Y_0$ to observed outcomes $Y$.

Sometimes useful to decompose
\begin{align*}
  Y_{i0} &= \mu_0 + v_{i0} \\
  Y_{i1} &= \mu_1 + v_{i1} \\
  \mu_0 &= \E[Y_{i0}] \\
  \mu_1 &= \E[Y_{i1}] \\
  0 &= \E[v_{i0}] \\
  0 &= \E[v_{i1}] \\
\end{align*}
where the expectation is taken over $i$.
This is conventient for formulating the average treatment effect in
terms of means and shocks, which is often useful for establishing
regression estimators of ATE.



\clearpage
\subsection{Identification}



\clearpage
\subsection{Assignment Mechanism}

Procedure that determines which units selected for treatment.
\begin{itemize}
  \item Random assignment: $D_i$ independent of observed and
    unobserved characteristics
    \begin{align*}
      (Y_1,Y_0)\perp D
    \end{align*}
    If $Y=h(D,U)$, means $U\perp D$.

  \item Selection on Obs:
    Individual select into treatment based on observed
    characteristics only
    \begin{align*}
      (Y_1,Y_0)\perp D | X
    \end{align*}
    Example:
    Threshold crossing model
    \begin{align*}
      D = \mathbf{1}\{g(X)>c\}
    \end{align*}
    Note that under selection on observables, also have by
    Rosenbaum \& Rubin (1983)
    \begin{align*}
      (Y_1,Y_0)\perp D |p(X)
    \end{align*}
    Like selection on observables, this result (``selection on
    propensity score'') can be used for identification of treatment
    effects as will be described below.


  \item Selection on unobservables:
    Individual select into treatment partially based on some
    unobserved characteristics (e.g. potential outcomes), but we
    observe some randomly assigned variable that partially
    influences selection, so instrument.

  \item
    Roy model:
    Individuals know their potential outcomes,
    select into treatment $D_i=\mathbf{1}\{Y_{1i}>Y_{0i}\}$
    hence $Y_i=\max\{Y_{0i},Y_{1i}\}$

Example: Roy model. If people know their ability $X$ is high $X=c$
(large), there is a well-defined potential outcome under $D=1$ and
$D=0$ at that $X=c$, but we never observe $D=0$ for high-ability
people, so there's no data at $X=c$ and $D=0$ and $\E[Y|X=c,D=0]$ is
not defined, even though $\E[Y_0|X=c,D=0]$ is.

\end{itemize}
Note:
Often possible to weaken these assumptions to mean independence of
potential outcomes and $D_i$ (also for conditional on $X$ case).
If we only want to identify the average causual effect, that's often
enough.





\clearpage
\section{Fisher Randomization}

Can use Wilcoxon rank test to detect whether treatment tends to increase
or decrease the value of observations
\begin{itemize}
  \item Order the units, give everybody a rank equal to their number in
    the order.
  \item Look at the absolute difference in the average rank of the
    control and the average rank of the treated units.
\end{itemize}
Can use KS test to detect whether treatment tends to change any aspect
of the distribution.
\begin{itemize}
  \item Compute empirical CDFs
  \item Take sup of difference over support
\end{itemize}
(Not Even Really) Model-Based Statistics
\begin{itemize}
  \item This works even if the model isn't a valid causal model or DGP,
    because we just use it as a descriptive device.

  \item Suppose we have a flexible model that can be estimated on both
    treatment and control data to get a set of parameters

  \item We can look at the difference in the parameters across treatment
    and control.

  \item We can also rerandomize and reestimate in the usual Fisher way.

  \item Again, this does not rely on models being good descriptions of
    the economy, the causal mechanism, whatever.
    It just relies on the models being good descriptions.

  \item
    So suppose that we can get a flexible regression model that fits
    well to the data, high $R^2$ for both treated and control.
    Then we can test whether the parameter characterizing those models
    is super different
\end{itemize}
Can also do confidence intervals for the value of a constant treatment
effect.

Geometry of the problem
\begin{itemize}
  \item No treatment effect means all observations lie on 45 degree line
    through origin
  \item Constant treatment effects means all observations lie on a 45
    degree line that is shifted upwards relative to the 45 degree line
    through the origin
  \item Positive but heterogeneous treatment effects means all points
    lie above the 45 degree line through the origin somehow
  \item Random assignment means, starting from the points in the cloud,
    some points get sent down to the $x$-axis, while others get sent
    over to the $y$-axis.
    Testing for any treatment effect whatsoever means trying to divine
    the fact that not all points lie on a 45 degree line (not
    necessarily through the origin).

    We don't observe the full distributions that correspond to sending
    everyone down or left.
    That's the missing data problem.
    But under randomization, we can get a pretty good estimate of those
    distributions.

  \item
    We can ask
    ``What array of points lying above the 45 degree line corresponds to
    the toughest or easiest to distinguish set of possible treatment
    effects?''
    We could do that for each possible statistic.

  \item
    We can say:
    Okay, I have the marginals.
    What are the possible joints consistent with those marginals?
    The joints consist of a copula/regression line through the
    scatterplot of $Y(1)$ against $Y(0)$ plus a measure of dispersion
    about the copula.
    Those are the two things that fully characterize.
    So maybe I can reduce the problem to just considering those things,
    and see how the statistics behave as I vary those.
\end{itemize}





\clearpage
\section{Imbens and Rubin}

We have a dataset of $N$ units $\{Y_i,X_i\}_{i=1}^N$ where
$X_i$ is a vector of pre-treatment covariates that we may or may not
have access to.
Given binary treatment,
associated with each unit is a a set of potential outcomes,
e.g. $(Y_i(0),Y_i(1))$ for unit $i$.
Two inference perspectives given this set of $N$ units.
\begin{itemize}
  \item Finite population:
    The $N$ units
    This is the population of interest.
    The estimand is the average unit-treatment effect in this fixed,
    finite population.
    \begin{align*}
      \tau_{FS}
      &:=
      \frac{1}{N}
      \sumiN
      [Y_i(1)-Y_i(0)]
    \end{align*}
    Rewrite this notation to emphasize dependence upon the finite
    population potential outcomes.

  \item
    Superpopulation:
    \begin{itemize}
      \item Suppose that we think of the $N$ units in our sample as
        belonging to some infinite (or extremely large) superpopulation
        of units, each with their own set of potential outcomes.
        The superopulation is often taken to be infinite (or extremely
        large) because then we'll never have a significant fraction of
        the population in our sample and we won't need to adjust for
        that possibly in estimation.

      \item
        The superpopulation of units can be characterized by their
        distribution over potential outcomes, and we can define
        estimands that are moments of that superpopulation distribution.
        For example, if the superpopulation is some large countable
        collection of $N_{sp}>>N$ individuals, we can define the average
        unit-level treatment effect over the superpopulation
        distribution, which is generally distinct from $\tau_{FS}$, as
        follows
        \begin{align*}
          \tau_{SP}
          &:=
          \frac{1}{N_{sp}}
          \sum_{i=1}^{N_{sp}}
          [Y_i(1)-Y_i(0)]
        \end{align*}
        Rewrite this notation to emphasize dependence upon the
        superpopulation distribution. This is a functional.
        The distribution can be an empirical distribution or a
        probability law.

        The potential outcomes $(Y_i(0),Y_i(1))$ are taken to be fixed
        for all units.
        We make no homogeneity, parametric, or distributional
        assumptions on potential outcomes like constant treatment
        effect.
        We simply take the superpopulation distribution over
        all potential-outcomes as given.

        Alternatively, if we think that think that the superpopulation
        is generated iid according to some superpopulation probability
        law (model), in which case we hope to do inference about this
        superpopulation law, we can instead define
        \begin{align*}
          \tau_{SP}
          &:=
          \E_{SP}[Y(1)-Y(0)]
        \end{align*}
        where the expectation is taken over the joint superpopulation
        distribution for $(Y(1),Y(0))$ that generates outcomes.

      \item
        If our sample was generated from the superpopulation by some
        known sampling mechanism---e.g.  simple random sampling,
        clustered sampling, or some other sampling mechanism---we can
        do inference on estimands/moments defined in terms of the
        superpopulation.

      \item
        The act of sampling from the superpopulation generates a
        distribution over the full sample sample and the potential
        outcomes $\{Y_i(0),Y_i(1)\}_{i=1}^N$, i.e. the sample is a
        random object rather than fixed.
        %Said another way,
        %$(Y_i(0),Y_i(1))$ for any given $i$, so we don't treat them as
        %fixed for any given $i$.

      \item
        The easiest case is simple random sampling and the results will
        be presented for this case.
        But note that the results below for the superpopulation case
        will only generally hold under simple random sampling (SRS) and
        generally do \emph{not} hold under alternative sampling schemes.
        So ``under SRS'' means exactly that: generally only under SRS.

        Clustered random sampling will induce a different sampling
        distribution for the full sample and the full set of potential
        outcomes $\{Y_i(0),Y_i(1)\}$, which generally implies quite
        different properties of estimators than what we would get under
        SRS.

      \item
        SRS from the infinite superpopulation induces a distribution on
        the full sample $\{Y_i(1),Y_i(0)\}_{i=1}^N$.
        This implies we can compute the following expectation with
        respect to that distribution for any fixed $i=1,\ldots,N$.
        \begin{align*}
          \E_{SRS}[Y_i(1)-Y_i(0)]
        \end{align*}
        In particular, the distribution is such that
        \begin{itemize}
          \item
            The potential outcomes for
            $(Y_i(0),Y_i(1))$
            are independent of and identically distributed to those of
            $(Y_j(0),Y_j(1))$
            for any $j\neq i$.
          \item For any fixed $i$, $(Y_i(1),Y_i(0))$ has distribution
            (across repeated samples) equal to the superpopulation
            distribution.
        \end{itemize}
        This implies
        \begin{align*}
          \E_{SRS}[Y_i(1)-Y_i(0)]
          =
          \E_{SP}[Y_i(1)-Y_i(0)]
          =
          \tau_{SP}
        \end{align*}
    \end{itemize}
\end{itemize}
Definitions
\begin{itemize}
  \item
    For the finite population with potential outcomes
    $\{Y_i(1),Y_i(0)\}$, we can define
    \begin{align*}
      \tau_{FS}
      &:=
      \frac{1}{N}
      \sumiN
      [Y_i(1)-Y_i(0)]
      \\
      S_c^2
      &=
      \frac{1}{N-1}
      \sumiN
      (Y_i(0)-\bar{Y}(0))^2
      \\
      S_t^2
      &=
      \frac{1}{N-1}
      \sumiN
      (Y_i(1)-\bar{Y}(1))^2
      \\
      S_{ct}^2
      &=
      \frac{1}{N-1}
      \sumiN
      (Y_i(1)-Y_i(0)-(\bar{Y}(1)-\bar{Y}(0)))^2
      \\
      &=
      \frac{1}{N-1}
      \sumiN
      (Y_i(1)-Y_i(0)-\tau_{fs})^2
    \end{align*}

  \item
    Given the superpopulation distribution over potential outcomes, we
    can define
    \begin{align*}
      \tau_{sp}
      &:=
      \E_{sp}[Y(1)-Y(0)]
      \\
      \sigma^2_{ct}
      &:=
      \Var_{sp}(Y(1)-Y(0))
      \\
      \sigma^2_{c}
      &:=
      \Var_{sp}(Y(0))
      \\
      \sigma^2_{t}
      &:=
      \Var_{sp}(Y(1))
    \end{align*}
    If the superpopulation is finite with $N_{sp}$, these are averages
    over the $N_{sp}$ units.

\end{itemize}
Estimators
\begin{align*}
  \hat{\tau}
  &=
  \overline{Y}_t^{obs}
  -
  \overline{Y}_c^{obs}
  \\
  s_c^2
  &=
  \frac{1}{N_c-1}
  \sum_{i\,:\,W_i=0}
  (Y_i^{obs}-\bar{Y}_c^{obs})^2
  \\
  s_t^2
  &=
  \frac{1}{N_t-1}
  \sum_{i\,:\,W_i=1}
  (Y_i^{obs}-\bar{Y}_t^{obs})^2
  \\
  \hat{V}^{neyman}
  &=
  \frac{s_c^2}{N_c}
  +
  \frac{s_t^2}{N_t}
  \\
  \hat{V}^{\rho_{ct}=1}
  &=
  \frac{s_c^2}{N_c}
  +
  \frac{s_t^2}{N_t}
  -
  \frac{(s_t-s_c)^2}{N}
  \\
  \hat{V}^{const}
  &=
  s^2
  \left(
  \frac{1}{N_c}
  +
  \frac{1}{N_t}
  \right)
\end{align*}
Results
\begin{itemize}
  \item
    If the only uncertainty is random assignment,
    \begin{align*}
      \E_W[\hat{\tau}]
      &= \tau_{FS}
      \\
      \Var_W(\hat{\tau})
      &=
      \frac{S_c^2}{N_c}
      +
      \frac{S_t^2}{N_t}
      -
      \frac{S_{ct}^2}{N}
      \\
      &=
      \frac{N_t}{N\cdot N_c}
      S_c^2
      +
      \frac{N_c}{N\cdot N_t}
      S_t^2
      +
      \frac{2}{N}
      \rho_{ct}
      S_cS_t
    \end{align*}
    Under, additionally, constant treatment effect, it is then the case
    that
    \begin{align*}
      \rho_{ct}&=1
      \\
      S_c^2&=S_t^2
      \\
      S_{ct}
      &= 0
      \\
      \Var_W(\hat{\tau})
      &=
      \frac{S_c^2}{N_c}
      +
      \frac{S_t^2}{N_t}
      \\
      \E_W[\hat{V}^{neyman}]
      &=
      \Var_W(\hat{\tau})
    \end{align*}
    Under heterogeneous treatment effects,
    \begin{align*}
      \Var_W(\hat{\tau})
      &\leq
      \hat{V}^{\rho_{ct}=1}
      \leq
      \hat{V}^{Neyman}
    \end{align*}
    Hence, $\hat{V}^{\rho_{ct}=1}$ is generally conservative but also
    smaller than $\hat{V}^{neyman}$.
    It's smaller because it uses the extra information in the difference
    $s_t-s_c$, which is generally nonzero in expectation when treatment
    effects are nonconstant.
    However, Neyman is often preferred because of its additionally
    applicability to the superpopulation case.

    $\hat{V}^{const}$ is valid and better than Neyman if treatment
    effects are truly constant.
    But it is not robust to departures from this undesirable assumption.


  \item
    Suppose we take a superpopulation perspective so that we would like
    to conduct inference about the average unit-level treatment effect
    in the superpopulation, with uncertainty driven by both random
    assignment and random sampling.
    Letting $\E$ denote the expectation over both simple random sampling
    and the assignment mechanism,
    Then under SRS,
    \begin{align*}
      \E[\hat{\tau}]
      &=
      \E\left[
        \E_W[
        \hat{\tau}
        \;|\;\{Y_i(1),Y_i(0)\}_{i=1}^N
        ]
      \right]
      \\
      \text{By random assignment}
      \quad
      &=
      \E\left[
        \tau_{fs}
      \right]
      \\
      \text{Definition}
      \quad
      &=
      \E\left[
        \frac{1}{N}
        \sumiN
        [Y_i(0)-Y_i(1)]
      \right]
      \\
      &=
      \frac{1}{N}
      \sumiN
      \E\left[
        Y_i(0)-Y_i(1)
      \right]
      \\
      \text{SRS}
      \quad
      &=
      \E\left[
        Y(0)-Y(1)
      \right]
      \\
      &= \tau_{SP}
    \end{align*}


\end{itemize}






\subsection{Identification}

\begin{thm}
\emph{(Without Covariates)}
Under Random assignment, $(Y_0,Y_1)\perp D$,
\begin{align*}
  \alpha_{ATE}
  =
  \alpha_{ATET}
  &=
  \E[Y|D=1]
  -
  \E[Y|D=0]
  \\
  P[Y_d\leq y]
  &=
  P[Y_d\leq y|D=d]
  =
  P[Y\leq y|D=d]
  \\
  \alpha_{QTE}(\tau)
  &=
  Q_\tau(Y_1)
  -
  Q_\tau(Y_0)
  =
  Q_\tau(Y|D=1)
  -
  Q_\tau(Y|D=0)
\end{align*}
\end{thm}
\begin{proof}
To prove identification of $\alpha_{ATE}$, start with definition
\begin{align*}
  \alpha_{ATE}
  &:=
  \E[Y_1-Y_0]
  \\
  \text{Randomization,}
  \;(Y_0,Y_1)\perp D
  \quad
  &=
  \E[Y_1|D=1]
  -
  \E[Y_0|D=0]
  \\
  Y=Y_1D+Y_0(1-D)
  \qquad
  &=
  \E[Y|D=1]
  -
  \E[Y|D=0]
\end{align*}
\end{proof}



\begin{thm}
\emph{(With Covariates)}
Suppose $(Y_1,Y_0,X)\perp D$.
Let $\plim \hat{\alpha}$ denote the true, unknown population coefficient
on $D$ in a regression of $Y$ on $D$, covariates $X$, and a
constant.\footnote{%
  We know that OLS will be consistent for $\plim \hat{\alpha}$ under
  regularity conditions.
}
Then
\begin{align*}
  \plim
  \hat{\alpha}
  =
  \alpha_{ATE}
  .
\end{align*}
\end{thm}
\begin{rmk}
Even though random assignment ensures that we can estimate the ATE by
simply computing the difference in means, we might nonetheless like to
estimate by running a regression with covariates if the covariates help
predict outcomes.
This will, in general, substantially reduce our standard errors when it
comes time to do inference about the ATE.
Use heteroscedasticity-robust standard errors to allow for unequal
variances.

Also, this might seem like an estimation result since we're talking
about regression, but it's really an identification result.  In
particular, we know that the probability limit of an OLS estimator
corresponds to some element of the population linear projection vector.
This theorem says that \emph{that element equals $\alpha_{ATE}$}, our
object of interest.

Also note that even though we're running linear regression, we
\emph{are not} assuming linearity of the model or a common treatment
effect across units.
The OLS estimand equals ATE even in a world with heterogeneous treatment
effects.
\end{rmk}
\begin{proof}
Suppose we have data $\{Y_i,D_i,X_i\}$ where $X_i$ is a scalar.
Define the follow vector of covariates and population projection
coefficients
\begin{align*}
  W_i =
  \begin{pmatrix}
    D_i \\
    1 \\
    X_i
  \end{pmatrix}
  \qquad
  \begin{pmatrix}
    \alpha \\
    c \\
    \gamma
  \end{pmatrix}
  :=
  \E[W_iW_i']^{-1}
  \E[W_iY_i]
\end{align*}
Note, we're not at all assuming that $Y_i$ is generated by a linear
model. We just assume that the data $\{Y_i,D_i,X_i\}$ joint
distribution---could be anything (subject to regularity conditions)
and highly nonlinear.
From that joint distribution, we \emph{define} projection
coefficients.

By LLN and Slutsky, OLS will be consistent for this population
coefficient vector, i.e.
\begin{align*}
  (W'W)^{-1}W'Y
  \quad\pto\quad
  \E[W_iW_i']^{-1}
  \E[W_iY_i]
\end{align*}
The question is `` Under random assignment, what is $\alpha$, i.e.
what is the OLS coefficient on $D_i$ consistent for?''
We will show that it's consistent for $\alpha_{ATE}$.

To compute the population coefficient vector that we're consistent
for, start with
\begin{align*}
  \E[W_iW_i']
  &=
  \begin{pmatrix}
    \E[D_i^2 ] & \E[D_i] & \E[D_i X_i] \\
    \E[D_i   ] & \E[1  ] & \E[X_i    ] \\
    \E[D_iX_i] & \E[X_i] & \E[X_i^2]
  \end{pmatrix}
  =
  \begin{pmatrix}
    \E[D_i^2 ]     & \E[D_i] & \E[D_i] \E[X_i] \\
    \E[D_i   ]     & 1       & \E[X_i] \\
    \E[D_i]\E[X_i] & \E[X_i] & \E[X_i^2]
  \end{pmatrix}
\end{align*}
The second equality followed crucially from random treatment
assignment,
%$D_i\perp X_i$,
hence $\E[D_iX_i]=\E[D_i]\E[X_i]$.
That's the key implication of random assignment that will deliver the
result.

To compute the inverse (or at least the part of the inverse relevant
for determining $\alpha$), recall the matrix block inversion formula
\begin{align*}
  \begin{pmatrix}
    A & B \\
    C & D
  \end{pmatrix}^{-1}
  &=
  \begin{pmatrix}
    (A-BD^{-1}C)^{-1}
    & - (A-BD^{-1}C)^{-1} BD^{-1}
    \\
    - & -
  \end{pmatrix}
\end{align*}
For us, $A=\E[D_i^2]=\E[D_i]$ in the upper left.
So first compute,
\begin{align*}
  BD^{-1}
  &=
  \begin{pmatrix}
    \E[D_i] & \E[D_i] \E[X_i]
  \end{pmatrix}
  \begin{pmatrix}
    1       & \E[X_i] \\
    \E[X_i] & \E[X_i^2]
  \end{pmatrix}^{-1}
  %\\
  %&=
  %\frac{\E[D_i]}{\E[X_i^2]-\E[X_i]^2}
  %\begin{pmatrix}
    %1 & \E[X_i]
  %\end{pmatrix}
  %\begin{pmatrix}
    %\E[X_i^2] & -\E[X_i] \\
    %-\E[X_i]  & 1
  %\end{pmatrix}
  %\\
  %&=
  =
  \E[D_i]
  \begin{pmatrix}
    1 & 0 \\
  \end{pmatrix}
  =
  P[D_i=1]
  \begin{pmatrix}
    1 & 0 \\
  \end{pmatrix}
\end{align*}
Finally, putting everything together,
\begin{align*}
  (A-BD^{-1}C)^{-1}
  &=
  \left(
  \E[D_i]
  -
  \E[D_i]
  \begin{pmatrix}
    1 & 0 \\
  \end{pmatrix}
  \begin{pmatrix}
    \E[D_i] \\ \E[D_i] \E[X_i]
  \end{pmatrix}
  \right)
  %=
  %\left(
  %\E[D_i]
  %-
  %\E[D_i]^2
  %\right)^{-1}
  %= \frac{1}{\E[D_i](1-\E[D_i])}
  =
  \frac{1}{P[D_i=1](1-P[D_i=1])}
\end{align*}
So then
\begin{align*}
  \begin{pmatrix}
    \alpha \\
    c \\
    \gamma
  \end{pmatrix}
  =
  \E[W_iW_i']^{-1}
  \E[W_iY_i]
  &=
  \begin{pmatrix}
    \frac{1}{P[D_i=1](1-P[D_i=1])}
    &
    - \frac{1}{(1-P[D_i=1])}
    & 0
    \\
    - & - & - \\
    - & - & - \\
  \end{pmatrix}^{-1}
  \begin{pmatrix}
    \E[Y_iD_i] \\
    \E[Y_i] \\
    \E[Y_iX_i]
  \end{pmatrix}
  \\
  \implies\quad
  \alpha
  &=
  \frac{\E[Y_iD_i]}{P[D_i=1](1-P[D_i=1])}
  - \frac{\E[Y_i]}{(1-P[D_i=1])}
\end{align*}
Almost there. Expand
\begin{align*}
  \E[Y_iD_i]
  &=
  \E[Y_iD_i|D_i=1]
  P[D_i=1]
  +
  \E[Y_iD_i|D_i=0]
  (1-P[D_i=1])
  \\
  &=
  \E[Y_i|D_i=1]
  P[D_i=1]
  \\
  \E[Y_i]
  &=
  \E[Y_i|D_i=1]
  P[D_i=1]
  +
  \E[Y_i|D_i=0]
  (1-P[D_i=1])
  \\
  &=
  \E[Y_i|D_i=1]
  P[D_i=1]
  +
  \E[Y_i|D_i=0]
  (1-P[D_i=1])
\end{align*}
So then
\begin{align*}
  \alpha
  &=
  \frac{%
    \E[Y_i|D_i=1]
    P[D_i=1]
  }{P[D_i=1](1-P[D_i=1])}
  -
  \frac{%
    \E[Y_i|D_i=1]
    P[D_i=1]
    +
    \E[Y_i|D_i=0]
    (1-P[D_i=1])
  }{1-P[D_i=1]}
  \\
  &=
  \E[Y_i|D_i=1]
  -
  \E[Y_i|D_i=0]
  \\
  &=
  \E[Y_{1i}|D_i=1]
  -
  \E[Y_{0i}|D_i=0]
  \\
  &=
  \E[Y_{1i}]
  -
  \E[Y_{0i}]
  =
  \alpha_{ATE}
\end{align*}
where the simplification to the last line followed from random
treatment assignment.
\end{proof}


\clearpage
\subsection{Estimation}

Estimation of $\alpha_{ATE}=\alpha_{ATET}$ is simple:
Just use the difference in means between treated and untreated and
assume unequal variances when constructinng standard errors.
Can also estimate that difference in means by OLS, using
heteroscedasticity-robust standard errors to allow for unequal
variances.



\clearpage
\section{Unconfoundedness}


\begin{defn}
(Propensity Score)
Define
\begin{align*}
  p(X)
  &:=
  P[D=1|X]
\end{align*}
Note:
This is the \emph{true} propensity score.
Not an estimator, but the exact true function.
\end{defn}

\begin{lem}
For exact, true propensity score $p(X)$,
\begin{align*}
  P[D=1|X,p(X)]
  =
  P[D=1|p(X)]
  \qquad\iff\qquad
  D\perp X \;|\; p(X)
\end{align*}
\end{lem}
\begin{rmk}
This will be used in the proof of the next theorem, but it is also a
useful practical result.
Because we sometimes adopt a parametric model for the propensity score
function, and this independence result can be used to test whether our
model for the propensity score well-approximates the true propensity
score function, or whether we need to come up with a more robust,
nonparametric estimator.
\end{rmk}

\begin{thm}
\emph{(Propensity Score Matching)}
\begin{align*}
  (Y_1,Y_0) \perp D \;|\; X
  \quad\implies\quad
  (Y_1,Y_0) \perp D \;|\; p(X)
\end{align*}
\end{thm}
\begin{proof}
By LIE and simple conditioning,
\begin{align*}
  P[D=1\,|\,Y_1,Y_0,p(X)]
  &=
  \E[D\,|\,Y_1,Y_0,p(X)]
  \\
  &=
  \E\big[
    \E[D\,|\,Y_1,Y_0,p(X),X]
    \;\big|\;Y_1,Y_0,p(X)
  \big]
  \\
  &=
  \E\big[
    \E[D\,|\,p(X),X]
    \;\big|\;Y_1,Y_0,p(X)
  \big]
  \\
  &=
  \E\big[
    P[D=1\,|\,p(X),X]
    \;\big|\;Y_1,Y_0,p(X)
  \big]
  \\
  &=
  \E\big[
    p(X)
    \;\big|\;Y_1,Y_0,p(X)
  \big]
  \\
  &=
  p(X)
  \\
  P[D=1\,|\,p(X)]
  &=
  \E[D\,|\,p(X)]
  \\
  &=
  \E\big[
    \E[D\,|\,p(X),X]
    \,|\,
    p(X)
  \big]
  \\
  &=
  \E\big[
    P[D=1\,|\,p(X),X]
    \,|\,
    p(X)
  \big]
  \\
  &=
  \E\big[
    p(X)
    \,|\,
    p(X)
  \big]
  \\
  &=
  p(X)
\end{align*}
These two results together imply that
\begin{align*}
  P[D=1|Y_1,Y_0,p(X)] = P[D=1|p(X)]
\end{align*}
i.e. independence between $D$ and $(Y_1,Y_0)$ conditional on $p(X)$.
\end{proof}






\clearpage
\subsection{Identification}

\begin{thm}
\emph{(Identification of ATE and CATE)}
Assume
\begin{enumerate}
  \item Selection on observables: $(Y_1,Y_0)\perp D \,|\, X$
  \item $p(X):=P[D=1|X]\in (0,1)$ with probability 1.
    Note that this probability is an RV because $X$ is random, hence the
    ``with probability 1.''
\end{enumerate}
Then
\begin{align*}
  \alpha_{CATE}(x)
  &=
  \E[Y|X=x,D=1]
  -
  \E[Y|X=x,D=0]
  \\
  \alpha_{ATE}
  &=
  \int
  \big\{
  \E[Y|X,D=1]
  -
  \E[Y|X,D=0]
  \big\}
  \;
  dP(X)
  =
  \int
  \alpha_{CATE}(X)
  \;
  dP(X)
\end{align*}
\end{thm}
\begin{proof}
First, start with the definitions of ATE and CATE, which are always a
well-defined expressions involving potential outcomes
\begin{align*}
  \alpha_{CATE}(x)
  &:=
  \E[Y_1-Y_0|X=x]
  =
  \E[Y_1|X=x]
  -
  \E[Y_0|X=x]
  \\
  \alpha_{ATE}
  &:=
  \E[Y_1-Y_0]
  =
  \E[\E[Y_1-Y_0|X]]
  =
  \E[\alpha_{CATE}(X)]
  =
  \int
  \big\{
  \E[Y_1|X]
  -
  \E[Y_0|X]
  \big\}
  \;
  dP(X)
\end{align*}
Next, by selection on observables, and $Y=Y_1 D + Y_0(1-D)$,
\begin{align}
  \E[Y_1|X]
  &=
  \E[Y_1|X,D=1]
  =
  \E[Y|X,D=1]
  \\
  \E[Y_0|X]
  &=
  \E[Y_0|X,D=0]
  =
  \E[Y|X,D=0]
  \label{outcomes}
\end{align}
for all $X$ in the support of $P[X|D=1]$ and $P[X|D=0]$, respectively.
We have now related moments of
\emph{unobserved potential outcomes}
and
\emph{observed realized outcomes}.


To finish up, we need to be careful about the support.
In particular, for CATE, we'd like to use the above results to say that
\begin{align}
  \alpha_{CATE}(x)
  ;=
  \E[Y_1-Y_0|X=x]
  =
  \E[Y|X=x,D=1]
  -
  \E[Y|X=x,D=0]
  \label{CATE}
\end{align}
However, we need to ensure the RHS is well-defined because, in general,
$\E[Y|X=x,D=d]$ is only well-defined for all $x$ in the support of
$P[X|D=d]$ and might not be well-defined for all $x$ in the support of
$P[X=x]$.
That's because, for a given value of $X$, we might only see $D=1$ or
$D=0$ because of complete selection into or out of treatment based on
$X$.

So use the assumption $P[D=1|X]\in (0,1)$.
Then Expressions~\ref{outcomes} are well-defined at any given $X$ in the
support of $P[X=x]$ and Expression~\ref{CATE} is well-defined.

Identification at each $X$ carries over to identification of the
average \emph{over} $X$, so we don't need any additional assumptions
to identify $\alpha_{ATE}$ relative to $\alpha_{CATE}$.
We do, however, need \emph{all} of the assumptions that allow
identification of $\alpha_{CATE}$ to identify $\alpha_{ATE}$;
there's no scope for relaxing them.
This is because selection is only random \emph{conditional} on
observables.
So we need to \emph{condition} on $X$ to correctly compute
$\alpha_{ATE}$, hence the same identification conditions are
required.

Similar arguments for identifying full conditional distribution
of each potential outcome.
\end{proof}



\begin{thm}
\emph{(Identification of ATET under Weaker Assumptions)}
Assumptions
\begin{enumerate}
  \item $Y_0\perp D|X$
  \item $P[D=1|X]< 1$ with prob 1,
    equivalent to $P[D=0|X]=1-P[D=1|X]\in (0,1]$
  \item $P[D=1]>0$
\end{enumerate}
Then
\begin{align*}
  \alpha_{ATET}
  &=
  \int
  \big\{
  \E[Y|X,D=1]
  -
  \E[Y|X,D=0]
  \big\}
  \;dP(X|D=1)
\end{align*}
\end{thm}
\begin{proof}
First, start with the definition, which is always well-defined,
\begin{align*}
  \alpha_{ATET}
  &=
  \E[Y_1-Y_0|D=1]
  =
  \E\big[
  \E[Y_1-Y_0|X,D=1]
  \;\big|\;D=1
  \big]
  =
  \int
  \E[Y_1-Y_0|X,D=1]
  \;dP(X|D=1)
\end{align*}
where the distribution $P[X|D=1]$ and hence ATET are well-defined
because $P[D=1]>0$, i.e. we will observe treated observations.

Next, because $Y_0\perp D|X$, we can say that
\begin{align*}
  \E[Y_0|X,D=1]
  =
  \E[Y_0|X]
  =
  \E[Y_0|X,D=0]
\end{align*}
Hence, we can rewrite
\begin{align*}
  \alpha_{ATET}
  &=
  \int
  \big\{
  \E[Y_1|X,D=1]
  -
  \E[Y_0|X,D=0]
  \big\}
  \;dP(X|D=1)
\end{align*}
To connect moments involving unobserved potential outcomes to moments
involving observed realized outcomes, by $Y=DY_1 + (1-D)Y_0$,
\begin{align*}
  \E[Y_0|X,D=0]
  &=
  \E[Y|X,D=0]
  \\
  \E[Y_1|X,D=1]
  &=
  \E[Y|X,D=1]
\end{align*}
These expectations are well-defined over the set of all $x$ in the
support of $P[X=x|D=0]$ and $P[X=x|D=1]$, respectively.
But by Assumption 2, the first line of expectations are well-defined
over the set of all $x$ in the support of $P[X=x|D=1]$ as well.
Hence, putting everything together,
for all $X$ in the support of $P[X|D=1]$,
\begin{align*}
  \E[Y_1-Y_0|X,D=1]
  &=
  \E[Y|X,D=1]
  -
  \E[Y|X,D=0]
\end{align*}
\end{proof}





\clearpage
\subsubsection{Propensity Score Approaches}


\begin{thm}
\emph{(via Propensity Score)}
Because $(Y_1,Y_0)\perp D|p(X)$, by the same logic as conditioning
on the full $X$ vector,
\begin{align*}
  %\E[Y_1-Y_0|p(X)]
  %&=
  %\E[Y_1|p(X),D=1]
  %-
  %\E[Y_0|p(X),D=0]
  %\\
  %\implies\quad
  \alpha_{ATE}
  &=
  %\E[Y_1-Y_0]
  %=
  \int
  \big\{
  \E[Y|p(X)=q,D=1]
  -
  \E[Y|p(X)=q,D=0]
  \big\}
  dP(q)
\end{align*}
\end{thm}



\begin{thm}
\emph{(Weighting)}
\begin{align*}
  \alpha_{ATE}
  &=
  \E\left[
    Y
    \frac{D-p(X)}{p(X)(1-p(X))}
  \right]
  \qquad
  \qquad
  \alpha_{ATET}
  =
  \frac{1}{P[D=1]}
  \E\left[
    Y
    \frac{D-p(X)}{(1-p(X))}
  \right]
\end{align*}
\end{thm}
\begin{proof}
Start from
\begin{align*}
  \E\left[
    Y
    \frac{D-p(X)}{p(X)(1-p(X))}
    \bigg|
    \,X
  \right]
  &=
  \sum_{d\in \{0,1\}}
  \E\left[
    Y
    \frac{D-p(X)}{p(X)(1-p(X))}
    \bigg|
    \,X,D=d
  \right]
  P[D=d|X]
  \\
  &=
  \E\left[
    Y
    \big|
    \,X,D=1
  \right]
  -
  \E\left[
    Y
    \big|
    \,X,D=0
  \right]
\end{align*}
For ATE, take outer expectation over $X$, i.e. integrate w.r.t.
$dP(X)$:
\begin{align*}
  \E\left[
    Y
    \frac{D-p(X)}{p(X)(1-p(X))}
  \right]
  &=
  \int
  \E\left[
    Y
    \frac{D-p(X)}{p(X)(1-p(X))}
    \bigg|
    \,X
  \right]
  \;dP(X)
  \\
  \text{From equality above}
  \quad
  &=
  \int
  \E\left[
    Y
    \big|
    \,X,D=1
  \right]
  -
  \E\left[
    Y
    \big|
    \,X,D=0
  \right]
  dP(X)
  =
  \alpha_{ATE}
\end{align*}
Last equality was shown above in proof of ATE ID under selection on
observables.

For ATET, integrate conditional (on $X$) expectation w.r.t.
measure $dP(X|D=1)$
\begin{align*}
  \int
  \E\left[
    Y
    \frac{D-p(X)}{p(X)(1-p(X))}
    \bigg|
    X
  \right]
  dP(X|D=1)
  &=
  \int
  \big\{
  \E[
    Y
    |
    X,D=1
  ]
  -
  \E[
    Y
    |
    X,D=0
  ]
  \big\}
  dP(X|D=1)
  =
  \alpha_{ATET}
\end{align*}
To finish, next note that
\begin{align*}
  f(X|D=1)
  =
  \frac{P(D=1|X)f(X)}{P[D=1]}
  \quad\implies\quad
  dP(X|D=1)
  =
  \frac{P(D=1|X)}{P[D=1]}
  dP(X)
  =
  \frac{p(X)}{P[D=1]}
  dP(X)
\end{align*}
This lets us simplify the integral on the LHS
\begin{align*}
  \int
  \E\left[
    Y
    \frac{D-p(X)}{p(X)(1-p(X))}
    \bigg|
    X
  \right]
  dP(X|D=1)
  &=
  \int
  \E\left[
    Y
    \frac{D-p(X)}{p(X)(1-p(X))}
    \bigg|
    X
  \right]
  \frac{p(X)}{P[D=1]}
  dP(X)
  \\
  &=
  \frac{1}{P[D=1]}
  \int
  \E\left[
    Y
    \frac{D-p(X)}{(1-p(X))}
    \bigg|
    X
  \right]
  dP(X)
  \\
  &=
  \frac{1}{P[D=1]}
  \E\left[
    Y
    \frac{D-p(X)}{(1-p(X))}
  \right]
\end{align*}
which completes the proof.
\end{proof}




\clearpage
\subsection{Estimation}

Having discussed \emph{identification} under selection on observables,
now consider \emph{estimation} of ATE/ATET.
Approaches include regression and matching.
Propensity score methods can be used in both cases.

Regression vs. matching approaches differ in the order of
averaging. They both estimate the same thing because of
linearity. Suppose want to compute ATE.
\begin{itemize}
  \item Matching: Take difference of potential outcomes (realized and
    imputed) for each individual to get individual treatment effects,
    average across individuals.
    This requres imputing the unobserved potential outcome for each
    individual.
  \item Regression: Compute average potential outcomes across
    individuals, take difference.
\end{itemize}
In both cases, since averaging over many individuals, the noise will
cancel.





\subsubsection{Regression-Type Estimators}

Estimation approaches are on the following key identification results
under selection on observables:
\begin{align*}
  \alpha_{ATE}
  &=
  \int
  \big\{
  \E[Y|X,D=1]
  -
  \E[Y|X,D=0]
  \big\}
  dP(X)
  \\
  \alpha_{ATET}
  &=
  \int
  \big\{
  \E[Y|X,D=1]
  -
  \E[Y|X,D=0]
  \big\}
  dP(X|D=1)
\end{align*}
We see that we need to estimate $\mu_d(X) = \E[Y|X=x,D=d]$,
then construct
\begin{align*}
  \hat{\alpha}_{ATE}
  &=
  \frac{1}{N}
  \sumiN
  \big\{
  \hat{\mu}_1(X_i)
  -
  \hat{\mu}_0(X_i)
  \big\}
  \qquad
  \qquad
  \alpha_{ATET}
  =
  \frac{1}{N_1}
  \sum_{D_i=1}
  \big\{
  \hat{\mu}_1(X_i)
  -
  \hat{\mu}_0(X_i)
  \big\}
\end{align*}
Regression-type estimation approaches
\begin{itemize}
  \item Nonparametric estimator of $\mu_d(X) = \E[Y|X,D=d]$
  \item OLS:
    In general, this is restrictive (parametric), imposing linearity and
    relying on extrapolation \emph{unless} we saturate the model in $X$.
    Absent saturation, we're as nonparametric as the previous approach,
    but this might still be employed nonetheless.
    So now, we'll just assume there is some regression specification
    that the researcher is comfortable with.

    If $D$ and $X$ enter separately in the regression equation, ATE and
    ATET are just the coefficient on $D$.
    If we include interactions and nonlinear terms in an effort to be
    more nonparametric, then we form $\hat{\mu}_1(X_i)$ and
    $\hat{\mu}_0(X_i)$ for each observation $X_i$ and average as before.
    We can't just read off the coefficient.

  \item Subclassification/Stratification:
    Even more restrictive, suppose potential outcomes vary only at a
    discrete set of values for the regressors.
    Specifically, assume $X$ takes values in discrete cells
    $\{x^1,x^2,\ldots,x^K\}$.
    Then construct
    \begin{align*}
      \implies\quad
      \hat{\alpha}_{ATE}
      &=
      \frac{1}{N}
      \sumiN
      \big\{
      \hat{\mu}_1(X_i)
      -
      \hat{\mu}_0(X_i)
      \big\}
      =
      \sum_{k=1}^K
      \frac{N^k}{N}
      (\bar{Y}^k_1-\bar{Y}^k_0)
      \\
      \alpha_{ATET}
      &=
      \frac{1}{N_1}
      \sum_{D_i=1}
      \big\{
      \hat{\mu}_1(X_i)
      -
      \hat{\mu}_0(X_i)
      \big\}
      =
      \sum_{k=1}^K
      \frac{N^k_1}{N_1}
      (\bar{Y}^k_1-\bar{Y}^k_0)
    \end{align*}
    Equivalent to regressing on a fully set of dummies for the
    values of $X$ plus all interactions with $D$.


\end{itemize}




\clearpage
\subsubsection{Matching Estimators}

Imputing other potential outcome for each individual, average across
individuals.
Selection on observables ensures that we can impute the other
unobserved potential outcome well.
\begin{itemize}
  \item ATET by nearest:
    Letting $j(i)$ denote the obs s.t.\ $X_{j(i)}$ is
    closest to $X_i$, construct
    \begin{align*}
      \hat{\alpha}_{ATET}
      &=
      \frac{1}{N_1}
      \sum_{D_i=1}
      (Y_i-Y_{j(i)})
    \end{align*}
  \item ATET by $M$ nearest:
    \begin{align*}
      \hat{\alpha}_{ATET}
      &=
      \frac{1}{N_1}
      \sum_{D_i=1}
      \left(
      Y_i
      -
      \frac{1}{M}
      \sum_{m=1}^M
      Y_{j_m(i)}
      \right)
    \end{align*}
  \item ATE by $M$ nearest:
    \begin{align*}
      \hat{\alpha}_{ATE}
      &=
      \frac{1}{N}
      \left\{
      \sum_{D_i=1}
      \left(
      Y_i
      -
      \frac{1}{M}
      \sum_{m=1}^M
      Y_{j_m(i)}
      \right)
      +
      \sum_{D_i=0}
      \left(
      \frac{1}{M}
      \sum_{m=1}^M
      Y_{j_m(i)}
      -
      Y_i
      \right)
      \right\}
      \\
      &=
      \frac{1}{N}
      \sum_{i=1}^N
      (2D_i-1)
      \left(
      Y_i
      -
      \frac{1}{M}
      \sum_{m=1}^M
      Y_{j_m(i)}
      \right)
    \end{align*}
\end{itemize}
Choices for measuring closeness
\begin{itemize}
  \item Euclidean distance:
    $\lVert X_i-X_j\rVert=\sqrt{\sum_{n=1}^k
    (X_{in}-X_{jn})^2}=\sqrt{(X_i-X_j)'(X_i-X_j)}$
  \item Normalized Euclidean distance:
    First standardize covariates to all have variance 1, then use
    Euclidean distance
  \item Mahalanobis distance:
    $\lVert X_i-X_j\rVert= \sqrt{(X_i-X_j)'\hat{\Sigma}_X^{-1}(X_i-X_j)}$
  \item
    Propensity Score:
    Estimate propensity score
    $p(X)=P[D=1|X]$ by logit, probit, etc.
    Then match based on $\hat{p}(X)$.
\end{itemize}
\clearpage
Standard errors for matching estimators:
\begin{itemize}
  \item In large samples, matching estimators are asymptotically
    normal
    \begin{align*}
      \sqrt{N_1}(\hat{\alpha}_{ATET}-\alpha_{ATET})
      \quad&\dto\quad
      \calN(0,\sigma^2_{ATET})
      \\
      \sqrt{N}(\hat{\alpha}_{ATE}-\alpha_{ATE})
      \quad&\dto\quad
      \calN(0,\sigma^2_{ATE})
    \end{align*}
  \item For matching \emph{without} replacement, we can use the
    usual variance estimator
    \begin{align*}
      \hat{\sigma}^2_{ATET}
      =
      \frac{1}{N_1}
      \sum_{D_i=1}
      \left(
      Y_i
      -
      \frac{1}{M}
      \sum_{m=1}^M
      Y_{j_m(i)}
      -
      \hat{\alpha}_{ATET}
      \right)^2
    \end{align*}
  \item For matching \emph{with} replacement, Abadie \& Imbens
    (2006)

  \item Nonparametric bootstrap does \emph{not} work for matching,
    Abadie \& Imbens (2008)
\end{itemize}
Weighting Estimators:
Can then construct estimators
\begin{align*}
  \hat{\alpha}_{ATE}
  &=
  \frac{1}{N}
  \sumiN
  Y_i
  \frac{D_i-\hat{p}(X_i)}{\hat{p}(X_i)(1-\hat{p}(X_i))}
  =
  \frac{1}{N_1}
  \sum_{D_i=1}
  \frac{N_1/N}{\hat{p}(X_i)}
  Y_i
  -
  \frac{1}{N_0}
  \sum_{D_i=0}
  \frac{N_0/N}{1-\hat{p}(X_i)}
  Y_i
  \\
  \hat{\alpha}_{ATET}
  &=
  \frac{N}{N_1}
  \frac{1}{N}
  \frac{1}{\sumiN}
  Y_i
  \frac{D_i-\hat{p}(X_i)}{(1-\hat{p}(X_i))}
\end{align*}
Construct standard errors via
\begin{itemize}
  \item Two-step GMM if $\hat{p}(X_i)$ is parametric
  \item Newey (1994) two-step approach if $\hat{p}(X_i)$ is
    nonparametric
  \item Bootstrap the entire two-step procedure.
\end{itemize}




\clearpage
\section{Instrumental Variables Approaches}

\subsection{Introduction}

Notation
\begin{itemize}
  \item Potential Outcomes $(Y_i(0), Y_i(1))$ as a function of treatment
  \item Potential Treatment function $D_i(z)$ as a function of
    instrument
  \item $P(w) = \E[D_i|Z_i=w]$, conditional treatment probability given
    instrument
\end{itemize}
The identification problem (see \cite{imbensangrist1994LATE} for discussion):
\begin{align*}
  \E[Y_i|Z_i=z]
  -
  \E[Y_i|Z_i=w]
  &=
  \E\big[
    (D_i(z)-D_i(w))
    (Y_i(1)-Y_i(0))
  \big]
  \\
  &=
  P[D_i(z)-D_i(w)=1]
  \E\big[
    (Y_i(1)-Y_i(0))
    \;|\;
    D_i(z)-D_i(w)=1
  \big]
  \\
  &\quad
  -
  P[D_i(z)-D_i(w)=-1]
  \E\big[
    (Y_i(1)-Y_i(0))
    \;|\;
    D_i(z)-D_i(w)=-1
  \big]
\end{align*}
Notice that even if $Y_i(1)-Y_i(0)>0$ for all $i$, we can get a zero or
negative outcome.

Solutions to the identification problem:
\begin{itemize}
  \item Manski Bounds:
    Abandon point identification entirely, derive bounds
  \item
    Assume constant treatment effect:
    If $Y_i(1)-Y_i(0)=\alpha$ for all $i$, then
    \begin{align*}
      \E[Y_i|Z_i=z]
      -
      \E[Y_i|Z_i=w]
      &=
      [P(z)-P(w)]\alpha
    \end{align*}
    More generally, we might adopt the traditional linear econometric
    framework:
    \begin{itemize}
      \item Data generated by
        \begin{align*}
          Y = \mu + \alpha D + X'\beta + u
        \end{align*}
        Then $Y_{1i}-Y_{0i}=\alpha$ for all $i$, so $\alpha$ is the
        treatment effect.
      \item Endogeneity of Treatment: $\Cov(D,u)\neq 0$
      \item Exogeneity of Instrument: $\Cov(Z,u)= 0$
      \item Relevance of Instrument: $\Cov(Z,D)\neq 0$
    \end{itemize}
    Can estimate $\alpha$ by 2SLS.

  \item \cite{angrist1991sources}:
    Assume that there exists a value of the instrument $w$ such that
    $P(w)=0$.
    Then $P[D_i(z)-D_i(w)=-1]$ and
    \begin{align*}
      \E[Y_i|Z_i=z]
      -
      \E[Y_i|Z_i=w]
      &=
      P(z)
      \E\big[
        (Y_i(1)-Y_i(0))
        \;|\;
        D_i(z)=1
      \big]
    \end{align*}
    and we can infer the treatment effect on the treated from
    $\E[Y_i|Z_i=z] - \E[Y_i|Z_i=w]$.

  \item
    LATE, \cite{imbensangrist1994LATE}:
    Assume monotonicity.
    Untestable condition, like the exclusion condition.

    Heterogeneous treatment effects:
    Don't assume linear CEF or linear model for the data.
    But can still do 2SLS.
    What does it estimate?
    LATE
\end{itemize}








\clearpage
\subsection{LATE}


Simple fact that if $Z\in \{0,1\}$,
\begin{align*}
  \frac{%
    \Cov(Y,D)
  }{%
    \Var(D)
  }
  = \E[Y|D=1]-\E[Y|D=0]
\end{align*}
Proof:
\begin{align*}
  \Cov(Y,D)
  &=
  \E[(Y-\E[Y])(D-\E[D])]
  \\
  &=
  \E[YD]
  - \E[D]\E[Y]
  - \E[Y]\E[D]
  + \E[Y]\E[D]
  \\
  &=
  \E[YD] - \E[D]\E[Y]
  \\
  &=
  \left(
  \E[YD|D=1]P[D=1]
  +
  \E[YD|D=0]P[D=0]
  \right)
  - P[D=1]\E[Y]
  \\
  &=
  \E[Y|D=1]P[D=1]
  - P[D=1]
  \big(
  \E[Y|D=1]P[D=1]
  +
  \E[Y|D=0]P[D=0]
  \big)
  \\
  &=
  \E[Y|D=1]P[D=1]
  -
  \E[Y|D=1]P[D=1]^2
  -
  \E[Y|D=0]P[D=0]P[D=1]
  \\
  &=
  \E[Y|D=1]
  \big(1 - P[D=1])\big)P[D=1]
  -
  \E[Y|D=0](1-P[D=1])P[D=1]
  \\
  \Var(D)
  &=
  P[D=1](1-P[D=1])
\end{align*}
So then we're done.

LATE Theorem:
Define
\begin{itemize}
  \item $(Y,D,Z)$: Outcome, binary treatment, binary instrument for
    treatment \emph{assignment}
  \item $(D_1,D_0)$: Potential treatment outcomes,
    i.e. $D_z\in \{0,1\}$ is the treatment status of the individual
    if their instrument is $Z=z$ for $z\in\{0,1\}$.
    Each individual can respond differently (in their take-up of
    treatment) to the instrument being turned on or off (being
    \emph{assigned} treatment or not), hence we need heterogeneous
    potential responses/outcomes for $D$ to accommodate, and this
    gives rise to the notions of compliers, always-takers,
    never-takers, and defiers. We define people by how they respond
    to treatment assignment (the instrument).

    Note: Actually observed treatment $D$ satisfies
    \begin{align*}
      D = ZD_1 + (1-Z)D_0
    \end{align*}
    and we only observe $D_1$ or $D_0$ depending upon their
    instrument.
    Since the person is assigned only one value of the instrument,
    we don't have the counterfactual and can't determine what group
    they fall into (compliers, always takers, etc.).

    Actually observed outcome satisfies
    \begin{align*}
      Y = DY_1 + (1-D)Y_0
    \end{align*}
\end{itemize}
\clearpage
Assumptions
\begin{itemize}
  \item Exclusion Restriction:
    Potential outcomes do not depend upon instrument (treatment
    assignment) $Z$, only upon treatment receipt $D$
  \item Random Assignment:
    $(Y_0,Y_1,D_0,D_1)\perp Z$
  \item Relevance I:
    $P[Z=1]\in (0,1)$, i.e. some people are \emph{assigned}
    treatment, some not
  \item Relevant II:
    $P[D_1=1]\neq P[D_0=1]$, i.e. the instrument has some effect so
    that being assigned to treatment $Z=1$ gives rise to probability
    of takeup/treatment-receipt $P[D_1=1]$ \emph{different}
    than if they hadn't been assigned to treatment.
  \item
    Monotonicity:
    $D_1\geq D_0$, no defiers.
\end{itemize}
Then, if there are no covariates, the population 2SLS coefficient
satisfies
\begin{align*}
  \frac{\Cov(Y,Z)}{\Cov(D,Z)}
  &=
  \frac{\E[Y|Z=1]-\E[Y|Z=0]}{\E[D|Z=1]-\E[D|Z=0]}
  =
  \E[Y_1-Y_0|D_1>D_0]
\end{align*}
In words, if we do 2SLS estimation, we know that we'll be consistent
for the ratio of covariances on the LHS, which is the population
2SLS coefficient.
We can ask ``What does that coefficient actually estimate?''
Under the above assumptions, it estimates LATE, the treatment effect
for the subpopulation of compliers.

Proof:
First, because
\begin{align*}
  Y &= DY_1 + (1-D)Y_0
  \\
  D &= ZD_1 + (1-Z)D_0
\end{align*}
This used the exclusion restriction, otherwise we'd need $Y_{dz}$
rather than just working with $Y_{d}$.

Next, because $P[Z=1]\in (0,1)$, i.e. we have both treatment and
not, the conditional expectations  $\E[Y|Z=z]$ and $\E[Y|D=z]$ are
well-defined.
The above implies
\begin{align*}
  \frac{\E[Y|Z=1]-\E[Y|Z=0]}{\E[D|Z=1]-\E[D|Z=0]}
  &=
  \frac{%
    \E[D_1Y_1 + (1-D_1)Y_0|Z=1]-\E[D_0Y_1 + (1-D_0)Y_0|Z=0]
  }{\E[D_1|Z=1]-\E[D_0|Z=0]}
  \\
  (Y_0,Y_1,D_0,D_1)\perp Z
  \quad
  &=
  \frac{%
    \E[D_1Y_1 + (1-D_1)Y_0]-\E[D_0Y_1 + (1-D_0)Y_0]
  }{\E[D_1]-\E[D_0]}
  \\
  \text{Collect Terms}
  \quad
  &=
  \frac{%
    \E[(Y_1-Y_0)(D_1-D_0)]
  }{\E[D_1-D_0]}
\end{align*}
Also note that
\begin{align*}
  \E[D_z]
  =
  P[D_z=1]
\end{align*}
For the above denominator $\E[D_1]-\E[D_0]$ to lead to a
well-defined estimator, we need $P[D_1=1]\neq P[D_0=1]$.


Notes
\begin{itemize}
  \item
    In general $\alpha_{LATE}\neq \alpha_{ATE}$.

  \item
    Under one-sided noncompliance $D_0=0$ (i.e. no way to get treatment
    if not assigned), $\alpha_{LATE}=\alpha_{ATET}$.

  \item
    We can estimate the fraction of fraction of compliers in the
    population because
    \begin{align*}
      P[D=1|Z=1]
      &=
      P[D_1=1|Z=1]
      =
      P[D_1=1]
      =
      P[D_1=1,D_0=0]
      +
      P[D_1=1,D_0=1]
    \end{align*}
    and also, under monotonicity $D_1\geq D_0$,
    \begin{align*}
      P[D=1|Z=0]
      &=
      P[D_0=1|Z=0]
      =
      P[D_0=1]
      =
      P[D_1=1,D_0=1]
    \end{align*}
    Then the fraction of compliers $P[D_1>D_0]$ can be identified
    \begin{align*}
      P[D_1>D_0]
      &=
      P[D_1=1,D_0=0]
      \\
      &=
      P[D_1=1,D_0=0]
      +
      P[D_1=1,D_0=1]
      -
      P[D_1=1,D_0=1]
      \\
      &=
      P[D=1|Z=1]
      -
      P[D=1|Z=0]
    \end{align*}
    Once we have this, we can back out the fraction of always takers,
    \begin{align*}
      P[D_1=1,D_0=1]
      &=
      P[D=1|Z=1]
      -
      P[D_1=1,D_0=0]
      \\
      &=
      P[D=1|Z=1]
      -
      P[D_1>D_0]
      \\
      &=
      P[D=1|Z=1]
      -
      \big(
      P[D=1|Z=1]
      -
      P[D=1|Z=0]
      \big)
      \\
      &=
      P[D=1|Z=0]
    \end{align*}
    We can also identify the fraction of never-takers as the fraction
    left over.

  \item
    Having now discussed identification, i.e. the population 2SLS
    coefficient is LATE, we can discuss estimation of LATE.
    We can do the usual Wald estimator or do 2SLS.
\end{itemize}



\clearpage
\subsection{Quantile IV}

%\begin{comment}
%\begin{frame}[shrink]{Quantile IV: Motivation}
%In the non-IV quantile regression case, we do quantile regression when
%we believe the conditional $Q_\tau(Y|X)$ satisfies
%\begin{align*}
  %Q_\tau(Y|X)=X'\beta_\tau
%\end{align*}
%for some $\beta_\tau$.
%This is a restriction on the conditional quantile function that we
%exploit by estimating a quantile regression.

%In Quantile IV, we also want a conditional quantile restriction, but one
%that conditions on $Z$, i.e.
%\begin{align}
  %Q_\tau(g(Y,X)|Z)=\text{something}
  %\label{qivrestriction}
%\end{align}
%for some function $g$ and some ``something'' that we will pin down in
%the next few slides.
%Then we can exploit this restriction and estimate some parameters.

%The next few slides will pursue a conditional quantile restriction like
%Expression~\ref{qivrestriction}.
%\end{frame}

%\begin{frame}[shrink]{Quantile IV: Setup}
%Model
%\begin{align*}
  %Y = h(X,\varepsilon)
%\end{align*}
%with $X$ and $\varepsilon$ possibly correlated.
%Running example
%\begin{itemize}
  %\item $Y$: Wages
  %\item $X$: Education
  %\item $\varepsilon$: Ability
%\end{itemize}
%Define for fixed $x$ the
%\alert{structural quantile function}:
%\begin{align*}
  %S_\tau(x) = Q_\tau(h(x,\varepsilon))
  %\qquad
  %\forall x
%\end{align*}
%This is the $\tau$th quantile if we could reassign \alert{everyone} to
%education level $x$, look at the resulting \alert{counterfactual}
%distribution of weages (with randomness/differences only arising from
%differences in ability $\varepsilon$), and pick out the $\tau$th
%quantile.
%\end{frame}


%\begin{frame}[shrink]{Aside: $Q_\tau(\,\cdot\,)$ Operator}
%$Q_\tau(\,\cdot\,)$ is the $\tau$th quantile operator which can be
%applied (like the expectation operator $\E[\,\cdot\,]$) to any RV,
%$Y$, $X$, $\varepsilon$.
%It must be inferred from context what the random object is
%whose $\tau$th quantile we want, e.g.
%\begin{itemize}
  %\item For fixed $x$, the only source of randomness in
    %$h(x,\varepsilon)$ is $\varepsilon$, hence
    %$Q_\tau(h(x,\varepsilon))$ gets the $\tau$th quantile of the RV
    %$h(x,\varepsilon)$, $x$ fixed and $\varepsilon$ random.
  %\item
    %$Q_\tau(Y)=Q_\tau(h(X,\varepsilon))$ gets the $\tau$th quantile of
    %the RV $Y$ or equivalently $h(X,\varepsilon)$, with $X$ and
    %$\varepsilon$ both random implying that $h(X,\varepsilon)$ is an RV
    %with some $\tau$th quantile.
%\end{itemize}
%\end{frame}



%\begin{frame}[shrink]{Quantile IV: Setup}
%Previous slide:
%For fixed $x$
%\begin{align*}
  %S_\tau(x) = Q_\tau(h(x,\varepsilon))
  %\qquad
  %\forall x
%\end{align*}
%Can also consider
%\begin{align*}
  %Q_\tau(Y|X)
  %=
  %Q_\tau(h(X,\varepsilon)|X)
%\end{align*}
%This is the $\tau$th quantile if we look at the \alert{actual} (not
%counterfactual) dist. of wages at covariate level $X$.
%Because of selection, generally
%\begin{align*}
  %Q_\tau(Y|X=x)
  %=
  %Q_\tau(h(X,\varepsilon)|X=x)
  %\neq
  %S_\tau(x) = Q_\tau(h(x,\varepsilon))
%\end{align*}
%The RHS of the $\neq$ sign involves counterfactual distributions, the
%LHS involves realized distributions.
%\end{frame}


%\begin{frame}[shrink]{Quantile IV: Picture}
%To emphasize that
%\begin{align*}
  %Q_\tau(Y|X=x)
  %=
  %Q_\tau(h(X,\varepsilon)|X=x)
  %\neq
  %S_\tau(x) = Q_\tau(h(x,\varepsilon))
%\end{align*}
%Picture to have in mind
%\begin{figure}
  %\includegraphics[angle=270, origin=c, scale=0.15, trim={40cm, 5cm, 30cm, 0cm}, clip]{./picture.jpg}
%\end{figure}
%\end{frame}


%\begin{frame}[shrink]{Quantile IV}
%Suppose that $h(x,e)$ is strictly increasing in $e$ for any fixed $x$.
%Then by monotonicity, for a fixed $x$, we have
%\begin{align*}
  %S_\tau(x)
  %= Q_\tau(h(x,\varepsilon))
  %= h(x,Q_\tau(\varepsilon))
%\end{align*}
%In words
%\begin{itemize}
  %\item $Q_\tau(h(x,\varepsilon))$:
    %Suppose we counterfactually reassign everyone to education level
    %$x$. The distribution of wages is then determined only by differences in
    %ability $\varepsilon$, and we can compute the $\tau$th quantile in
    %wages at that $x$, i.e. compute $Q_\tau(h(x,\varepsilon))$.
  %\item
    %$h(x,e)$ increasing in $e$ for each fixed $x$:
    %Suppose wages are increasing in ability for any level of
    %education. The high ability folks always earn more at each level of
    %education $x$, no matter the counterfactual level $x$ assigned to
    %everyone.
  %\item
    %$Q_\tau(h(x,\varepsilon)) = h(x,Q_\tau(\varepsilon))$:
    %To find out the $\tau$th quantile of wages if everyone has education
    %level $x$ (i.e. $Q_\tau(h(x,\varepsilon))$), we just need to find
    %the ability of the guy who's always at at the $\tau$th quantile of
    %ability (i.e. $Q_\tau(\varepsilon)$), plug in.
%\end{itemize}
%\end{frame}


%\begin{frame}[shrink]{Deducing a Restriction for Estimation}
%Next, because the function $h(X,e)$ is increasing in $e$ for any fixed
%$X$
%\begin{align*}
  %\{\varepsilon\leq Q_\tau(\varepsilon)\}
  %\quad&\iff\quad
  %\{h(X,\varepsilon)\leq h(X,Q_\tau(\varepsilon))\}
  %\\
  %\text{Last slide}
  %\quad&\iff\quad
  %\{h(X,\varepsilon)\leq Q_\tau(h(X,\varepsilon))\}
  %\\
  %\text{Defintions}
  %\quad&\iff\quad
  %\{Y\leq S_\tau(X)\}
  %\\
  %\text{Defintions}
  %\quad&\iff\quad
  %\{Y-S_\tau(X)\leq 0\}
%\end{align*}
%This result relied strictly on the property that the function $h(X,e)$
%is increasing in $e$ for fixed $X$ (regardless of whether $X$ and
%$\varepsilon$ are correlated).


%If $Z\perp \varepsilon$, then we can take a first step towards deducing
%a conditional quantile restriction by using the above results to note
%\begin{align*}
  %P[Y-S_\tau(X)\leq 0\,|\,Z]
  %=
  %P[\varepsilon \leq Q_\tau(\varepsilon)\,|\,Z]
  %=
  %P[\varepsilon \leq Q_\tau(\varepsilon)]
  %=
  %\tau
%\end{align*}
%We conditioned on $Z$ in the first line so we can (below) deduce a
%conditional quantile restriction.

%If we have a linear SQF
%\begin{align*}
  %S_\tau(x) = x'\alpha_\tau
  %\qquad
  %\forall x
%\end{align*}
%the above implies the conditional quantile restriction
%\begin{align*}
  %Q_\tau(Y-S_\tau(X)|Z)
  %=
  %0
%\end{align*}
%\end{frame}

%\begin{frame}[shrink]{Quantile IV: The Key Restriction}

%Under a linear SQF
%\begin{align*}
  %S_\tau(x)
  %= Q_\tau(h(x,\varepsilon))
  %=
  %x'\alpha_\tau
%\end{align*}
%and given an instrument $Z\perp \varepsilon$, we have deduced the
%following conditional quantile restriction on the
%\begin{align*}
  %Q_\tau(Y-X'\alpha_\tau|Z)
  %= 0
%\end{align*}
%This is a restriction that can be exploiting for estimation of
%$\alpha_\tau$.
%Simply choose $\alpha_\tau$ as the vector that gives teh \emph{smallest}
%coefficients when running a quantile regression of $Y-X'\alpha_\tau$ on
%$Z$.
%\end{frame}
%\end{comment}




\clearpage
\section{Differences-in-Differences}

Diff-in-Diff
\begin{itemize}
  \item Potential outcomes Setup
    \begin{itemize}
      \item Two time periods, $t=0,1$
      \item Treatment $D_i$ will happen after time 0
      \item Can divide individuals $i$ into treated and untreated
        groups and imagine their potential outcomes.
        \begin{itemize}
          \item $Y_{1i}(t)$: $i$'s potential outcome at time $t$
            if in treated group (i.e. if they are treated after time
            $0$)
          \item $Y_{0i}(t)$: $i$'s potential outcome at time $t$
            if in non-treated group (never treated)
        \end{itemize}
      \item In general, we connect observed outcomes $Y_i(t)$ to
        potential outcomes as follows
        \begin{align*}
          Y_{i}(t) = D_iY_{1i}(t) + (1-D_i)Y_{0i}(t)
        \end{align*}
        Implicitly, for time $0$, this lets treatment ``run backward''
        in time because, for a fixed individual $i$, being treated after
        time 0 leads to observation $Y_i(0)=Y_{1i}(0)$ while never being
        treated leads to observation $Y_i(0)=Y_{0i}(0)$.
        These are in general different, reflecting that there could be
        some anticipation.
        That will get ruled out below.

      \item
        Identification assumptions
        \begin{itemize}
          \item Non-Anticipation:
            For a fixed individual $i$, treatment after time zero does
            not causally affect potential outcomes at time $t=0$:
            \begin{align*}
              Y_i(0) = Y_{1i}(0) = Y_{0i}(0)
            \end{align*}
          \item Parallel Trends:
            The expected change (across time periods) in untreated
            potential outcomes is independent of treatment:
            \begin{align*}
              \E[Y_{0i}(1)-Y_{0i}(0)|D_i=1]
              =
              \E[Y_{0i}(1)-Y_{0i}(0)|D_i=0]
            \end{align*}
            Said another way $(Y_{0i}(1)-Y_{0i}(0))\perp D_i$.
        \end{itemize}
      \item Identification: Under these assumptions, can identify
        $\alpha_{ATET}$,
        \begin{align*}
          \alpha_{ATET}
          &:= \E[Y_{1i}(1)-Y_{0i}(1)|D_i=1]
          \\
          &=
          \big(
          \E[Y_i(1)|D=1]
          -
          \E[Y_i(1)|D=0]
          \big)
          -
          \big(
          \E[Y_i(0)|D=1]
          -
          \E[Y_i(0)|D=0]
          \big)
          \\
          &=
          \big(
          \E[Y_i(1)|D=1]
          -
          \E[Y_i(0)|D=1]
          \big)
          -
          \big(
          \E[Y_i(1)|D=0]
          -
          \E[Y_i(0)|D=0]
          \big)
        \end{align*}
        which is the change in the final-period outcome for the treated
        units, relative to the case where they had never been treated.
        We have an estimate of ATET, not ATE because we're explicitly
        constructing a counterfactual for the treated group. We have no
        baseline/control for untreated group that would let us
        identify ATE.

        Proof:
        Start with the definition
        \begin{align*}
          \alpha_{ATET}
          &= \E[Y_{1i}(1)-Y_{0i}(1)|D_i=1]
          \\
          &=
          \E[Y_{1i}(1)|D_i=1]
          -
          \E[Y_{0i}(1)|D_i=1]
          \\
          \text{Add Subtract}\;
          &=
          \E[Y_{1i}(1)|D_i=1]
          - \E[Y_{0i}(1)|D_i=1]
          + \E[Y_{0i}(0)|D_i=1]
          - \E[Y_{0i}(0)|D_i=1]
          \\
          &=
          \E[Y_{1i}(1)|D_i=1]
          - \E[Y_{0i}(1)-Y_{0i}(0)|D_i=1]
          - \E[Y_{0i}(0)|D_i=1]
          \\
          \text{Parallel trends}\;
          &=
          \E[Y_{1i}(1)|D_i=1]
          - \E[Y_{0i}(1)-Y_{0i}(0)|D_i=0]
          - \E[Y_{0i}(0)|D_i=1]
          \\
          \text{Non-Antic.}\;
          &=
          \E[Y_{1i}(1)|D_i=1]
          - \E[Y_{0i}(1)-Y_{0i}(0)|D_i=0]
          - \E[Y_{1i}(0)|D_i=1]
          \\
          \text{Defn of $Y_i(t)$}\;
          &=
          \E[Y_{i}(1)|D_i=1]
          - \E[Y_{i}(1)-Y_{i}(0)|D_i=0]
          - \E[Y_{i}(0)|D_i=1]
        \end{align*}
        Then just rearrange.
    \end{itemize}

  \item Now that we have identification for two periods,
    \begin{align*}
      \alpha_{ATET}
      &:= \E[Y_{1i}(1)-Y_{0i}(1)|D_i=1]
      \\
      &=
      \big(
      \E[Y_i(1)|D=1]
      -
      \E[Y_i(1)|D=0]
      \big)
      -
      \big(
      \E[Y_i(0)|D=1]
      -
      \E[Y_i(0)|D=0]
      \big)
      \\
      &=
      \big(
      \E[Y_i(1)|D=1]
      -
      \E[Y_i(0)|D=1]
      \big)
      -
      \big(
      \E[Y_i(1)|D=0]
      -
      \E[Y_i(0)|D=0]
      \big)
    \end{align*}
    Consider estimation.
    \begin{itemize}
      \item Repeated Cross-Section, Two Time Periods, No Covariates:
        Estimate population means by simple averages, take differences.
      \item Repeated Cross-Section, Two Time Periods, No Covariates:
        Suppose we assume a linear model
        for $D_i\in\{0,1\}$ and $T_i\in\{0,1\}$:
        \begin{align*}
          Y_i =
          \mu + \gamma D_i + \delta T_i + \alpha (D_i\cdot T_i)
          + \varepsilon_i
          \qquad
          \E[\varepsilon|D,T]=0
        \end{align*}
        Then $\alpha=\alpha_{ATET}$ defined above---the difference in
        difference of population averages.
        So we can estimate via regression.
        QUESTION: Can we get the same result without assuming linearity?

      \item Repeated Cross-Section, Two Time Periods, Covariates:
        Sometimes we might want to include covariates.
        It's usually only sensible to include time-invariant covariates
        because then we don't have to worry about endogeneity.

        Of course, if we include a time-invariant covariate straight in
        the above regression, useless because diff-in-diff differences
        out time-invariant things and uses the time trends to identify
        and estimate the causal effect. If time-invariant, doesn't
        affect time trend.
        Covariates need to be able to affect trend to matter.
        So interact time-invariant covariates with time indicator
        \begin{align*}
          Y_i =
          \mu + \gamma D_i + \delta T_i + \alpha (D_i\cdot T_i)
          + T_iX_i'\beta_1
          + (1-T_i)X_i'\beta_0
          + \varepsilon_i
        \end{align*}
        Here $X_i$ will explain difference in time trends, and we only
        require parallel trends to hold \emph{within} covariate strata.


      \item Panel Data, Two Time Periods, No Covariates:
        Several equivalent options
        \begin{itemize}
          \item
            Classify each entity as control or treated group.
            Compute sample averages to estimate the population
            quantities.
            This is the ``Compute group and time averages, then compute
            diff-in-diff''

          \item Can take time difference for each individual/entity
            since it's panel data to get
            \begin{align*}
              \Delta Y_i = \delta + \alpha D_i + u_i
            \end{align*}
            where $\Delta Y_i=Y_i(1)-Y_i(0)$ and $u_i=\Delta
            \varepsilon_i$. Run this regression.
            Can show equivalent to above since average of differences is
            equivalent to diff of averages.

          \item Estimate a regression with entity FE and a time dummy.
            \begin{align*}
              Y_i =
              \gamma_i + \delta T_i + \alpha (D_i\cdot T_i)
              + \varepsilon_i
            \end{align*}
        \end{itemize}
        Note: They might differ in the order of averaging in your
        intuition (Elisa example), but with panel data where everything
        is super-balanced they're all the same.

      \item Panel Data, Two Time Periods, Covariates:
        \begin{align*}
          \Delta Y_i = \delta + \alpha D_i + X_i'\beta + u_i
        \end{align*}
        where $\Delta Y_i=Y_i(1)-Y_i(0)$, $\beta=\beta_1-\beta_0$
        and $u_i=\Delta \varepsilon_i$.
        Here we can see that the change in $Y_i$ is explained by both
        treatment $D_i$ and, possibly, covariates $X_i$.

        Equivalent to estimating FE regression
        \begin{align*}
          Y_{it} = \gamma_i + \delta_t + \alpha (D_i\cdot T_i)
          + T_i X_i'\beta_1
          + (1-T_i) X_i'\beta_0
          + \varepsilon_i
        \end{align*}

      \item Panel Data, More than Two Time Periods, Covariates:
        Estimation with panel data and more than two time periods.
        Generalize above regression to
        \begin{align*}
          Y_{it}
          =
          \gamma_i
          + \delta_t
          + \alpha \underbrace{D_i\mathbf{1}\{t\geq \tau\}}_{D_{it}}
          + {X_{it}'}\beta
          + \varepsilon_i
        \end{align*}
        where $\tau$ is the date of the policy intervention.
        Although $X_{it}$ is, in general, time-varying, we might only want
        to control for time-invariant covariates if we're worried about
        introducing endogeneity.
        In that case, set $X_{it}=tX_i$, where $X_i$ is a set of
        time-invariant covariates interacted with time to help explain the
        time trend.
        If $t=2$ and we have $X_{it}=tX_i$, equivalent to the two-period
        regression with covariates.
    \end{itemize}
\end{itemize}
Event studies are appropriate when there's not a single simultaneous
policy change but \emph{recurring} or \emph{individual-specific} events.
Then set up regression
\begin{align*}
  Y_{it}
  =
  \alpha_i + \delta_t
  + X_{it}'\beta
  + \sum_{j=-m}^\ell D_{it}^j \alpha_j + \varepsilon_{it}
\end{align*}
where $D_{it}^j$ is a dummy indicator if they were treated or hit with
an event $j$ periods ago, i.e. at time $t-j$.
So $\alpha_j$ is the effect $j$ periods after the event hits.



\subsubsection{Changes-in-Changes Estimator,
\cite{athey2006identification}}

\paragraph{Setup}
\begin{itemize}
  \item
    Data $\{(Y_i,G_i,T_i,I_i)\}_{i=1}^N$ where $i$
    indexes observations, $T_i\in\{0,1\}$ is the time period of the
    observation, $G_i\in\{0,1\}$ is the group (treatment or
    control), $I_i=G_i\times T_i\in\{0,1\}$ the indicator for ``in
    treatment group, received treatment,'' $Y_i$ is the
    observed outcome.
  \item Potential outcomes $(Y_i^N,Y_i^I)$ for individual $i$ if
    they do not or do receive treatment.
\end{itemize}
\paragraph{CIC Model/Assumptions}
Generalization of DID.
The CIC model consists of assumptions (i)-(iii) below.
Assumption (iv) is necessary only for some identification results.
Assumption (iv) is necessary only if we wish to estimate ATEC or
ATE in addition to ATET.
\begin{enumerate}[label=(\roman*)]
  \item
    Model:
    $Y_i^N = h(U_i,T_i)$ for some function $h(u,t)$ that depends
    upon both time $T_i$ and $U_i$, which captures all unobservable
    characteristics in a single index.\footnote{%
      Assumption is restrictive. For nonlinear $h(u,t)$, rules out
      clasical measurement error.
    }

    Notice, although $Y_i^N$ can change with time $T_i$, this
    potential outcome does not depend upon group membership $G_i$
    directly/arbitrarily.
    This amounts to an exclusion restriction for $U_i$ that rules
    out selection into group $G_i$ based on $U_i$.

  \item Strict Monotonicity:
    Function $h(u,t)$ is strictly increasing in $u$ for
    $t\in\{0,1\}$.

    This is natural in cases where the unobservable $U$ corresponds
    to something like unobserved ability, which should translate
    into higher earnings.
    This is also automatically satisfied in additively separable
    models.
    But in general, this is a restrictive assumption that restricts
    the way the function can evolve over time.\footnote{%
      The restriction only bites with \emph{multiple} time periods.
      For a single time period, $t=0$, this is just a normalization
      because we can always set $U_i=Y_i$ and $h(u,t)=u$ so the
      outcome $Y_i$ increases in $U_i$ trivially.
    }

  \item Time Invariance of the $U$ Distribution within Groups,
    Across Time: $U\perp T\,|\,G$.

    This assumption rules out, for each given group, any
    \emph{compositional changes} in the distribution of the
    unobservable over time, within a group.
    In panel data, this is guaranteed because it's the same
    individuals across time.
    In the case of repeated cross sections, this is an important,
    nontrivial assumption that rules out selection.


  \item Support: $\U_1\subseteq \U_0$, i.e. the support of
    unobservables for the control group is at least as rich as the
    support of the unobservables for the treatment group.

    Also implies
    $\Y_{10}\subseteq \Y_{00}$ and
    $\Y^N_{11}\subseteq \Y_{01}$,
    i.e. pre-treatment control group has richer set of outcomes than
    pre-treatment treatment group.
    Also, post-treatment control group has richer set of potential
    outcomes than post-treatment treatment group.


  \item $Y_i^I=h^I(U_i,T_i)$ for some function $h^I(u,t)$ that is
    increasing in $u$.
    Thus the treatment effect is $h^I(u,1)-h(u,1)$ for
    individuals with unobserved component $u$.

    Assumptions (i)-(iv) are enough if we only care about ATET.
    But because the distribution of $U_i$ can vary across groups,
    the average treatment effect can vary across groups as well.
    So to estimate ATEC or ATE, some assumption like
    this (about how treatment affects outcomes) is necessary,
    just like for standard DID.
\end{enumerate}
A few things to note in this setup:
\begin{itemize}
  \item Scale Invariance:
    Because assumption (iii) involves independence of
    \emph{distributions}, not \emph{mean} independence, the same
    assumptions remain valid for any strictly monotone
    transformation of the outcome.  In this sense, the DID estimator
    is invariant to scaling of the outcome.
  \item Basic Identification Idea:
    The real meat lies in Assumptions (i) and (iii).
    There are three basic steps.
    \begin{enumerate}
      \item
        Estimate Differences in $U_i$ Distributions across $G_i$:
        By Assumption (i), all differences in the distribution of
        pretreatment outcomes across groups stem from differences in
        the distribution of $U_i$ across groups.
        So although the distribution of $U_i$ can differ arbitrarily
        across groups, we can use outcomes in the pretreatment
        period to pin down completely these differences.

      \item
        Estimate the Trend:
        Because all changes in outcomes within a group in the
        absence of treatment arise solely from the fact that
        $h(u,0)$ differs from $h(u,1)$, we can infer, from the
        control group, the change in the level of outcomes that's
        due to the passage of time.
        This will be relevant for the treatment group because of
        Assumption (i).

      \item
        Project foroward the Trend:
        Because any differences between groups (in their
        distributions of unobservables) are stable across time
        (Assumption (iii)), we can use the inferred distribution of
        $U_i$ and the estimated trend in the control group to
        eliminate the trend in the treatment group.
    \end{enumerate}
\end{itemize}

\clearpage
\paragraph{Standard DID}
\begin{itemize}
  \item
    The estimand is
    \begin{align*}
      \tau^{DID}
      &=
      \big(
      \E[Y_i\,|\,G_i=1,T_i=1]
      -
      \E[Y_i\,|\,G_i=1,T_i=0]
      \big)
      \\
      &\quad
      -
      \big(
      \E[Y_i\,|\,G_i=0,T_i=1]
      -
      \E[Y_i\,|\,G_i=0,T_i=0]
      \big)
    \end{align*}
    This estimand is motivated/justified by assumptions on the potential
    outcomes, which serve two purposes:
    \begin{enumerate}[label=(\roman*)]
      \item Ensure $\tau^{DID}$ above corresponds to \emph{some} kind of
        average treatment effect
      \item Define \emph{which} average treatment effect $\tau^{DID}$
        corresponds to.
    \end{enumerate}

  \item
    Assumptions:
    \begin{itemize}
      \item Linear Potential Outcome $Y_i^N$:
        An assumption that serves purpose (i) is essentially a
        functional form assumption, which gives rise to the linear form
        of the DID estimand since time and group membership affect
        potential outcome in a \emph{constant} and \emph{linear} way
        across individuals:
        \begin{align*}
          Y_i^N &= \alpha + \beta T_i + \gamma G_i + \varepsilon_i
        \end{align*}
        $\varepsilon_i$ represents unobserved individual
        characteristics.
        Note that with panel data, it is often appropriate to replace
        common $\gamma$ with an individual fixed effect $\gamma_i$.

      \item
        Independence (Good Control) Assumptions:
        Next, to satisfy purpose (i) of ensuring that the DID estimand
        estimates some kind of average treatment effect, we need some
        kind of unconfoundedness assumption that rules out
        selection/OVB, together with the above functional form
        assumption.
        Options:
        \begin{itemize}
          \item Full independence \citep{blundellmacurdy2000}:
            $\varepsilon_i \perp (G_i,T_i)$.
            This is also a limited kind of homoskedasticity assumption, i.e.
            the distribution of the $\varepsilon_i$ cannot change with group
            $G_i$ or time period $T_i$.\footnote{%
              It is not ful homoskedasticy among \emph{all}
              observations, but within time and group periods, which
              is weaker.
            }

          \item Mean independence \citep{abadie2005}:
            $\E[\varepsilon_i|G_i,T_i]=0$.\footnote{%
              As usual in regressions settings, the fact that the
              expectation has \emph{value zero in particular} is the wlog
              part.
              The real content of the assumption is constancy of this
              expectation.
            }
            This allows for heteroskedasticity in the distribution of
            $\varepsilon_i$ across values of $G_i$ and $T_i$.
            It implies that changes in time of moments of the outcomes
            other than the mean are not relevant for predicting the mean
            of $Y_i^N$.

            Note one complication here:
            Mean-independence is generally not invariant to
            scaling/units.
            If we assume mean independence in levels then take logs, we
            might not have mean independence for log-levels.

          \item Zero correlation:
            $\E[\varepsilon_iG_i]=\E[\varepsilon_iT_i]=0$.
            Also allows for heteroskedasticity.
        \end{itemize}

      \item Treatment Effect Assumptions:
        Having fulfilled purpose (i), we now consider assumptions that serve
        purpose (ii): \emph{which} average treatment effect we identify.
        \begin{itemize}
          \item Homogeneity $Y_i^I-Y_i^N=\tau$:
            The DID estimand then equals $ATET=ATE=ATEC$ and we have the
            following model for \emph{realized} outcomes:
            \begin{align*}
              Y_i &= \alpha + \beta T_i + \gamma G_i + \tau I_i + \varepsilon_i
            \end{align*}

          \item Heterogeneity $Y_i^I-Y_i^N=:\tau_i$ where $\tau_i$ has an
            abitrary distribution:
            Because $\tau_i:=Y_i^I-Y_i^N$ can have arbitrary distribution,
            this amounts to \emph{no} parametric or distributional
            assumptions on how treatment affects outcomes (e.g. no
            assumption of treatment effect equal to constant parameter
            $\tau$ or distributed normally).
            The DID estimand is then $ATET\neq ATE$ and $\neq ATEC$.
            Thus without any assumptions on the treatment effect, we can
            only infer ATET.
            To extrapolate from ATET to other kinds of average treatment
            effects, we'd need further assumptions on how treatment affects
            outcomes, e.g. homogeneity as above.
        \end{itemize}
    \end{itemize}

  \item Special Case of CIC Model:
    Standard DID as in \cite{blundellmacurdy2000} (but not the
    mean-independence model of \cite{abadie2005}) is nested by the
    changes-in-changes model with
    \begin{itemize}
      \item
        (Additivity):
        $U_i=\alpha + \gamma G_i + \varepsilon_i$ with
        $\varepsilon_i\perp (G_i,T_i)$.
        Hence, $G_i$ does not affect $Y_i^N$ except through $U_i$, and
        it's also clear that $U_i \perp T_i\,|\,G_i$.

      \item (Single Index Model):
        $h(u,t)=\phi(v(u,t))$ for some strictly increasing function
        $\phi(\,\cdot\,)$ and $v(u,t)$, in particular
        $v(u,t)=\phi(u+\delta t)$.

      \item (Identity Transformation):
        $\phi(\,\cdot\,)$ is the identity function.
    \end{itemize}
\end{itemize}

\clearpage
\paragraph{Identification of the Changes-in-Changes Model}
\begin{itemize}
  \item Notation:
    \begin{itemize}
      \item Dropping the $i$ subscript, we have
        random variables $(Y,Y^N,Y^I,G,T,U)$
      \item Use the following to denote those random variables
        and CDFs conditional on some $G$ and/or $T$:
        \begin{align*}
          (Y_{gt},Y_{gt}^N,Y_{gt}^I,U_g)
          \qquad
          (F_{Y,{gt}},F_{Y^N,{gt}},F_{Y^I,{gt}},F_{U,g})
        \end{align*}

    \end{itemize}
    Want to identify the counterfactual second-period outcome for the
    treatment group.
    In other words, want to express $F_{Y^N,11}$ (the CDF of
    non-treatment potential outcomes $Y^N$ for those units where
    $G_i=1$ and $T_i=1$) in terms of the joint distribution of the
    observables $(Y,G,T)$, more specifically, in terms of
    $F_{Y,00}$, $F_{Y,01}$, and $F_{Y,10}$.


  \item
    Quantile Function:
    For $q\in [0,1]$ and random variable $Y$ with compact support
    $\Y$,
    \begin{align*}
      F_Y^{-1}(q) = \inf \{y\in \Y\,:\, F_Y(y)\geq q\}
    \end{align*}
    Implies
    \begin{itemize}
      \item $F_Y^{-1}(q)$ left continuous
      \item $F_Y(F_Y^{-1}(q))\geq q$ with equality everywhere for
        continuous $Y$ and equality at dicontinuity points of
        $F_Y^{-1}(q)$ for discrete $Y$.
      \item $F_Y^{-1}(F_Y(y))\leq y$ with equality everywhere for
        continuous or discrete $Y$ (but not necessarily mixed $Y$).
    \end{itemize}

  \item
    Theorem:
    Suppose assumptions (i)-(iv) hold and the $U$ either continuous or
    discrete. Then the distribution of $Y_{11}^N$ is identified and
    \begin{align*}
      F_{Y^N,11}(y)
      =
      F_{Y,10}\big(
        F_{Y,00}^{-1}\big(
        F_{Y,01}(y)
        \big)
      \big)
    \end{align*}
    This gives the distribution of potential outcome $Y_N$ for the
    treatment group in the post-treatment period. From this,
    we will be able to construct average treatment effects.
    \begin{proof}
    First use invertibility of $h(u,t)$ in $u$ (i.e. direct
    correspondence between potential outcome $Y^N_{gt}$ and the
    unobservable $U$) to relate the distribution of $Y^N_{gt}$ to that
    of $U_g$.
    In particular, by Assumption (ii), Strict Monotonicity, $h(u,t)$ is
    invertible in $u$, hence
    \begin{align*}
      F_{Y^N,gt}(y)
      &:=
      P\big[
        Y^N \leq y \,|\, G=g,T=t
      \big]
      \\
      \text{Assumption (i)}\quad
      &=
      P\big[
        h(U,t) \leq y \,|\, G=g,T=t
      \big]
      \\
      \text{Assumption (ii)}\quad
      &=
      P\big[
        U \leq h^{-1}(y;t) \,|\, G=g,T=t
      \big]
      \\
      \text{Assumption (iii)}\quad
      &=
      P\big[
        U \leq h^{-1}(y;t) \,|\, G=g
      \big]
      \\
      \text{Definition of $U_g$}\quad
      &=
      P\big[
        U_g \leq h^{-1}(y;t)
      \big]
      \\
      \implies\quad
      F_{Y^N,gt}(y)
      &=
      F_{U,g}\big(h^{-1}(y;t)\big)
    \end{align*}
    In words,
    ``If we know the CDF of $U_g$ and mapping $h(u,t)$, we know the
    CDF of $Y^N_{gt}$.''

    The above result is important because it allow us to express the
    unobserved target distribution as
    \begin{align}
      F_{Y^N,11}(y)
      &=
      F_{U,1}\big(h^{-1}(y;1)\big)
      .
      \label{cicid}
    \end{align}
    Of course we observe neither the unobservable distribution
    $F_{U,1}$ nor the mapping $h^{-1}(y;1)$, so the task is to recover
    these objects from observable distributions.
    %We will deduce the distribution $F_{U,1}$ form the distribution
    %$F_{Y,10}$.
    %We will use stability of the distributions to deduce $h^{-1}(y;1)$
    %from quantiles of the control group in each time period.

    We can start first with the unobservable distribution $F_{U,1}$ for
    the treatment group.
    This can be related to the distribution of first-period outcomes for
    the treated group since there is a direct correspondence between
    outcomes in the absence of treatment and unobservables, as
    established above.
    In particular,
    \begin{align}
      F_{Y,10}(y)
      =
      F_{Y^N,10}(y)
      &=
      F_{U,1}\big(h^{-1}(y;0)\big)
      \label{cicid2}
    \end{align}
    Thus we have linked unobservable $F_{U,1}$ and
    observable $F_{Y,10}$.
    Use that to rewrite Expression~\ref{cicid} as
    \begin{align*}
      F_{Y^N,11}(y)
      &=
      F_{U,1}\big(h^{-1}(y;1)\big)
      =
      F_{U,1}\big(h^{-1}(h(h^{-1}(y;1);0);0)\big)
      =
      F_{Y,10}(h(h^{-1}(y;1);0))
    \end{align*}
    %What's left to exploit Expression~\ref{cicid} is to handle the
    %unknown mapping $h^{-1}(y;1)$.
    %In particular, notice that $y$ in Expression~\ref{cicid} is
    %implicitly a $t=1$ outcome, while $y$ in Expression~\ref{cicid2} is
    %implicitly a $t=0$ outcome.
    %Therefore, we need a route to convert $t=1$ outcomes to $t=0$
    %outcomes.
    %We do this by using the control group, where stability of the
    %unobservable distribution over time allows us to convert $t=1$
    %outcomes to $t=0$ outcomes.
    Next, notice the term $h(h^{-1}(y;1);0)$.
    This term takes a second period outcome $y$, uses $h^{-1}(y;1)$ to
    infer the unobservable, then plugs that into $h(u;0)$ to get the
    first period outcome corresponding to that $u$.
    We need to simplify this to complete the proof because the mapping
    $h(u;t)$ is unobserved.
    We do this using the control group.

    So first, to go from some $t=1$ outcome in the control group to the
    corresponding unobservable, as established above,
    \begin{align*}
      F_{Y,01}(y)
      =
      F_{Y^N,01}(y)
      &=
      F_{U,0}\big(h^{-1}(y;1)\big)
      \quad\implies\quad
      h^{-1}(y;1)
      =
      F_{U,0}^{-1}
      \big(
      F_{Y,01}(y)
      \big)
    \end{align*}
    Thus, given a $t=1$ period value $y$, we can recover the
    unobservable.

    Next, we want to go from the unobservable to some $t=0$ outcome.
    From the first established result,
    \begin{align*}
      F_{Y,00}(y)
      =
      F_{Y^N,00}(y)
      =
      F_{U,0}\big(h^{-1}(y;0)\big)
      \quad\implies\quad
      F_{Y,00}(h(u;0))
      &=
      F_{U,0}\big(h^{-1}(h(u;0);0)\big)
      =
      F_{U,0}(u)
      \\
      \quad\implies\quad
      h(u;0)
      &=
      F_{Y,00}^{-1}
      \big(
      F_{U,0}(u)
      \big)
    \end{align*}
    Putting together this route from $t=1$ outcome to $t=0$ outcome,
    \begin{align*}
      h(h^{-1}(y;1);0)
      &=
      F_{Y,00}^{-1}
      \big(
      F_{U,0}(h^{-1}(y;1))
      \big)
      \\
      &=
      F_{Y,00}^{-1}
      \big(
      F_{U,0}\big(
        F_{U,0}^{-1}
        \big(
        F_{Y,01}(y)
        \big)
      \big)
      \big)
      \\
      &=
      F_{Y,00}^{-1}
      \big(
        F_{Y,01}(y)
      \big)
      %\\
      %h^{-1}(y;1)
      %&=
      %h^{-1}
      %\bigg(
      %F_{Y,00}^{-1}
      %\big(
        %F_{Y,01}(y)
      %\big)
      %;
      %0
      %\bigg)
    \end{align*}
    Finally,
    \begin{align*}
      F_{Y^N,11}(y)
      &=
      F_{Y,10}(h(h^{-1}(y;1);0);0)
      =
      F_{Y,10}\big(
        F_{Y,00}^{-1}
        \big(
          F_{Y,01}(y)
        \big)
      \big)
    \end{align*}
    \end{proof}

  \item
    Corollary for Generating Counterfactuals:
    We now develop a useful corollary that results from the
    identification theorem.
    This is not a new identification result as its proof relies on the
    above-proved theorem.
    However, it offers another way to represent identification and a way
    to explicitly model counterfactuals.

    Define the following
    \begin{alignat*}{3}
      k^{CIC}(y)
      &:=
      F_{Y,01}^{-1}\big(
        F_{Y,00}(y)
      \big)
      &&=
      y + \big[ F_{Y,01}^{-1}\big( F_{Y,00}(y) \big) - y\big]
      =
      y + \Delta^{CIC}(y)
      =
      y + [k^{CIC}(y)-y]
    \end{alignat*}
    Results and Interpretation:
    \begin{itemize}
      \item $k^{CIC}(y)$ gives second period, no treatment counterfactual:
        Because the distribution of $U$ is stable over time, and because
        the production function $h(U,T)$ can change over time, this
        function roughly corresponds to computing the second period
        outcome for an observation with first period outcome equal to
        $y$, all done within the control group where there is no
        treatment.

        But because production technology is common across groups, we
        can use this ``counterfactual generating function'' to construct
        no-treatment counterfactual outcomes for the treated group.

        %First and most directly, $k^{CIC}(y)$ looks within the control
        %group, supposes that $Y_{00}=y$, computes the corresponding
        %quantile $q'$, and returns the value of quantile $q'$ in the
        %distribution $F_{Y,01}$.

        Contrast this with the usual DID counterfactual
        \begin{align*}
          k^{CIC}(y)
          &=
          y + \Delta^{CIC}(y)
          =
          y + \big[ F_{Y,01}^{-1}\big( F_{Y,00}(y) \big) - y\big]
          =
          F_{Y,01}^{-1}\big(
            F_{Y,00}(y)
          \big)
          \\
          k^{DID}(y)
          &=
          y + \Delta^{DID}(y)
          =
          y + \E[Y_{01}] - \E[Y_{00}]
        \end{align*}


      \item
        $k^{CIC}(Y_{10})\sim Y^N_{11}$
        \begin{align*}
          P\big[
            k^{CIC}(Y_{10})
            \leq y
          \big]
          &=
          P\big[
            F_{Y,01}^{-1}\big(
              F_{Y,00}(Y_{10})
            \big)
            \leq y
          \big]
          \\
          &=
          P\big[
              Y_{10}
            \leq
            F_{Y,00}^{-1}\big(
            F_{Y,01}(y)
            \big)
          \big]
          \\
          \text{By definition}\quad
          &=
          F_{Y,10}
          \big(
            F_{Y,00}^{-1}\big(
            F_{Y,01}(y)
            \big)
          \big)
          \\
          \text{Identification result}\quad
          &=
          F_{Y^N,11}(y)
        \end{align*}
        Hence, the distribution of $k^{CIC}(Y_{10})$ coincides with the
        distribution of $Y^N_{11}$.

      \item Because $k^{CIC}(y)$ gives the counterfactual second period
        outcome in the absence of treatment for an observation with
        first period outcome equal to $y$,
        the projected change in the absence of treatment is
        \begin{align*}
          \Delta^{CIC}(y)
          &=
          k^{CIC}(y)-y
          =
            F_{Y,01}^{-1}\big(
              F_{Y,00}(Y_{10})
            \big)
        \end{align*}

    \end{itemize}


  \item
    The results above all imply that we can write the average treatment
    effect as follows
    \begin{align*}
      \tau^{CIC}
      &:=
      \E[Y_{11}^I - Y_{11}^N]
      \\
      &=
      \E[Y_{11}^I] - \E[Y_{11}^N]
      \\
      \text{Since $k^{CIC}(Y_{10})\sim Y^N_{11}$}
      \qquad
      &=
      \E[Y_{11}^I] - \E[k^{CIC}(Y_{10})]
      \\
      \text{Definition}
      \qquad
      &=
      \E[Y_{11}]
      - \E[
          F_{Y,01}^{-1}\big(
            F_{Y,00}(Y_{10})
          \big)
        ]
    \end{align*}
    We can then construct an estimator using averages and empirical
    CDFs.


  \item
    CIC Model:
    \begin{itemize}
      \item Outcomes in the absence of treatment are ``produced'' by
        $h(U,T)$, e.g.  the production function depends directly on time
        but not group.
      \item Can use a control group $G=0$ to identify the production
        function with respect to $T$, which requires assuming stability
        in the distribution of unobservables across time $T$ (within
        group $G$) so as not to counfound identification.
      \item Can also use $T=0$ outcomes to identify time-invariant
        differences in the distribution of unobservables across $G$.
        In principle, the distributions of $U$ across $G$ can differ
        arbitrarily.
    \end{itemize}
    CIC-r Model
    \begin{itemize}
      \item Outcomes in the absence of treatment are ``produced'' by
        $h(U,G)$, e.g.  the production function depends directly on
        group but not time.
      \item Can use a control time period to identify the production
        function with respect to $G$, while necessarily assuming
        stability in the distribution of unobservables across groups $G$
        (within time $T$) so as not to counfound identification.
      \item Can also use $G=0$ outcomes to identify group-invariant
        differences in the distribution of unobservables across $T$.
        In principle, the distributions of $U$ across $T$ can differ
        arbitrarily.
    \end{itemize}

\end{itemize}



\clearpage
\subsection{Pretrends}

\begin{align*}
  y_{it} = \beta z_{it}
\end{align*}
where
\begin{itemize}
  \item $z_{it}$ policy, example is an indicator that is 1 in years
    after passage of min wage increase, zero in all other years
  \item $\eta_i$ confounder correlated with both $y_{it}$ and $z_{it}$,
    e.g. raising the probability of treatment and average outcomes
    simultaneously.
    It can be a multi-dimensional object, including a sequence
    $\{\eta_{it}\}$.
    We might place restrictions on how and when elements of $\eta_i$
    affect $y_{it}$ and $z_{it}$.
\end{itemize}
Notes
\begin{itemize}
  \item
    Standard diagnostic approach:
    Check for ``pre-trends,'' i.e. does the policy have an effect on
    outcomes before it actually occurs?
    In other words, do members of the treatment group have a different
    trend in outcomes relative to the control group?

  \item
    Ideal experiment:
    Random assignment of units into treatment and control.

    First, this would guarantee that there is no difference in
    \emph{average outcomes} \emph{at any point} prior to treatment.
    So treatment control contrasts of outcomes and covariates would be
    identical (on average) in all pre-periods.

    This first consequence of random assignment would, in turn,
    also guarantee that that there is no difference in the \emph{trend}
    in average outcomes prior to treatment.

    Note that this latter parallel trends condition is often taken
    as \emph{the} primitive assumption for validity DiD.
    It is implied by random assignment, but does \emph{not} imply random
    assignment; it's weaker.

  \item
    Violations of parallel trends:
    If we observe differences in the trends in average outcomes for the
    treatment and control groups, we can take that as evidence of some
    $\eta_i$.

  \item
    Goal:
    Given observed pre-trends in outcomes, we determine how much of the
    policy effect is do to confounds vs. the causal effect of policy.

\end{itemize}
Simple
\begin{align*}
  y_{it} &= \beta z_{it} + \gamma \eta_{it} + \varepsilon_{it}
\end{align*}






\clearpage
\subsection{%
  Causal Inference for Dynamic Models with Agg. Treatment
}

Setting
\begin{itemize}
  \item Treatment occurs at some aggregate level, e.g. states
  \item
    Multiple periods of observed outcomes and pre-treatment covariates
    (which might be pre-treatment outcomes) that are observed at one of
    two possible levels of aggregation:
    \begin{itemize}
      \item Group-Level: $\{Y_{it},X_{it}\}$, e.g.\ states,
        with treatment occurring at this level.
      \item Micro-Level: $\{Y_{ist},X_{ist}\}$, e.g.\ individual $i$ in
        state $s$ at time $t$, with treatment occurring at the level of
        $s$.
    \end{itemize}

  \item Membership in some group, $\{G_{it}\}$ or $\{G_{ist}\}$.
    \begin{itemize}
      \item Easiest case is $G_{it}\in\{0,1\}$ or $G_{ist}$ denoting that
        the $i$th unit of time $t$ (or $is$ unit of time $t$) belongs to
        the treatment or control group.
        Note that we need not have panel data and so unit $it$ need not
        be the same as $it'$.
      \item In event studies, units generally enter into treatment
        status at different times, so think of
        $G_{it}\in \{1,\ldots,T\}$ or $G_{ist}\in\{1,\ldots,T\}$
        partitioning units based on when unit $i$ or $is$ gets treated.
        This reflects the fact that, in general, the average treatment
        effect among those units treated in 2010 differs from the
        average treatment effect among those units treated in 2011.
        This could be because
        \begin{enumerate}[label=(\roman*)]
          \item Potential outcomes and the distribution of treatment
            effects for those units treated in 2010 are somehow
            different than for those units treated in 2011, e.g. each
            state has a type like ``early adopter vs. late adopter''
            which otherwise systematically affects outcomes, above and
            beyond treatment.
          \item
            There are other confounding factors going on 2010 or 2011 in
            the background.
        \end{enumerate}
        Note also, that in the case with many periods of data and
        dynamic treatment effects, there is a proliferation of ATEs that
        are generally distinct, e.g.
        the `` 1-year out ATE for those treated in 2010,''
        the ``1-year out ATE for those treated in 2011,''
        the ``2-year out ATE for those treated in 2010,''
        the ``2-year out ATE for those treated in 2011,''
        etc.

        Typically event studies pool these estimates, implicitly
        or explicitly invoking homogeneity of ATEs to estimate a
        single ``One year out ATE'', a single ``Two year out ATE,'' etc.
        along with placebo ``$n$ years prior-to-treatment-receipt'' ATEs
        to verify the comparability of treatment and control groups.


    \end{itemize}
\end{itemize}

\paragraph{Causal Effects}
Causal effects are defined pairwise across groups, with one group
referred to as the treatment group and the other as the control group.

Credibility of the causal effects comes from some set of
\emph{homogeneity} assumptions that ensure some manner of
comparability between groups, who are otherwise similar/comparable
\emph{but for group membership}.
Then differences in outcomes between groups (perhaps after some
adjustment) can then be credibly attributed to the effect of group
membership (i.e. treatment) alone, rather than other confounding
factors.

The homogeneity assumptions broadly come from two
strategies/approaches.
\begin{itemize}
  \item
    (\emph{Modeling Assumptions}):
    We posit a \emph{model} for counterfactual outcomes across
    groups, and overcome selection via \emph{modeling} and
    \emph{adjustment}, rather than randomizing assignment.
    In fact, the assignment is often unspecified, irrelevant, or
    even nonrandom.

    Said another way, to achieve identification, we impose sharp
    assumptions on \emph{individual} outcomes, their DGP, and/or
    treatment effects across groups/treatment, rather than on merely the
    \emph{distribution} of potential outcomes across groups/treatment.
    Examples include: Classical linear DiD model with constant effects,
    monotonic production function of changes-in-changes, or construction
    of a composite control in synthetic controls.

    In many cases, these assumptions limit the causal parameters
    that we can identify from the data because treatment is not
    randomized, and we might need to sacrifice and subordinate
    estimation of certain causal effects to the task of achieving a
    proper model/adjustment, e.g. diff-in-diff can't necessarily get at
    the ATE, just the ATET.

    In some cases, the assumptions are even sharp enough to let us
    impute the unobserved counterfactual outcome for a particular
    unit, though this restricts heterogeneity in individual treatment
    effects across groups in important and often undesirable ways.

  \item (\emph{As Good as Random Assignment Assumptions}):
    The \emph{distribution} of potential outcomes and treatment
    effects across groups is uncorrelated with group membership or
    treatment.
    This could come from random assignment of treatment or
    individuals to groups or random adoption of policies.
    Alternatively, this could come purely from conviction or prior
    beliefs that group membership or treatment is ``as good as
    randomly assigned'', generally after matching or controlling for
    observed covariates, so there is no further correlation with
    potential outcomes, a la selection on observables.\footnote{%
      In DiD settings the term ``adoption'' is sometimes employed
      because because states ``adopt'' a policy rather than have it
      assigned.
    }

    We assume neither a model nor homogeneity in individual treatment
    effects or PO.
    We overcome selection via random assignment or ``as good as random
    assignment.''
\end{itemize}
\paragraph{%
  Diff-in-Diff or ``Diff-in-Diff Type'' Approaches
}
Characterized by a few key features.
\begin{itemize}
  \item
    (\emph{Modeling Assumptions}):
    Any parametric or homogeneity asumptions that we might make on
    outcomes or treatment effects.

  \item
    (\emph{Assignment Mechanism Assumptions}):
    Whether we take a stand on any aspect of the assignment mechanism.


  \item
    (\emph{Identified Causal Param}):
    What causal parameters (i.e. parameters with a causal interpretation
    generally written in terms of \emph{potential} outcomes) we can
    identify from observed data, under assumptions on the model of
    outcomes and/or assignment mechanism.

  \item
    (\emph{Estimation of Causal Parameter}):
    How we actually estimate that causal parameter.

  \item
    (\emph{Uncertainty Considerations}):
    For testing, we need to ask what drives our uncertainty.
    How we characterize our uncertainty largely depends on the causal
    inference strategy that we adopt.
    \begin{itemize}
      \item (\emph{Modeling}):
        We have a sample of data drawn from some population, or we
        appeal to some large, finite superpopulation or superpopulation
        law.
        When we estimate parameters, we need to account for the fact
        that we only have a sample.

        With micro-level data, we also need to account for clustering
        because treatment occurs at the group level.

      \item (\emph{Assignment Mechanism}):
        Uncertainty comes from which units were randomly assigned to
        treatment (or as good as randomly assigned to treatment).
    \end{itemize}

  \item
    (\emph{Relation to ``Parallel Trends''}):
    This is the familiar assumption in classical DiD, and many causal
    inference settings with multiple data period need or employ this
    assumption for inference.
    But it's not always necessary or \emph{the} key identification
    assumption, as in classical DiD.
    So I will say a few words about it to connect to the classical DiD
    setting.

  \item
    (\emph{Implications for the DiD Estimand}):
    Again, the DiD estimand (a difference in differences) is an estimand
    that we can always estimate.
    Our assumptions determine whether it is identified with \emph{some}
    meaningful causal effect.
    Also, our assumptions determine whether it is the \emph{only}
    treatment effect identified, because in some cases, it is one
    identified causal effect \emph{of many}, and maybe not even the most
    interesting one.
\end{itemize}
\paragraph{Classical Diff-in-Diff}
The ``classical classical diff-in-diff'' assumes constant treatment
effect, but I will allow for treatment effect heterogeneity, and briefly
note the distinction where relevant.
\begin{itemize}
  \item
    (\emph{Modeling Assumptions}):
    Common time FE across groups (which implies parallel/common trends
    between groups).
    Unit fixed effects that are time invariant, which means means that
    they can have arbitrary distribution and can be arbitrarily
    correlated with treatment.
  \item
    (\emph{Assignment Mechanism Assumptions}):
    None assumed, which is the real benefit, since the modeling
    assumptions let us sidestep selection into treatment/policy adoption.
  \item
    (\emph{Identified Causal Param}):
    ATET only, unless we explicitly assume that the distribution of
    treatment effects is the same across groups (in which case
    ATET=ATE).

  \item
    (\emph{Estimation of Causal Parameter}):
    DiD regression with unit and time FE plus the interaction.
    The DiD estimand will be the ATET

  \item
    (\emph{Sources of Uncertainty}):
    Random sampling of units, clustering of treatment (i.e. all units in
    a state).
    Generally don't think of design-based uncertainty since we don't
    want to model treatment assignment/adoption.

  \item
    (\emph{Relation to ``Parallel Trends''}):
    This is the key assumption in this model that permits identification
    given that we don't specify the assignment mechanism.
    Without this assumption, selection into treatment can totally
    counfound things.
  \item
    (\emph{Implications for the DiD Estimand}):
    This is the only estimand to which we can assign a causal
    interpretation without further assumptions on our simple model for
    outcomes.
\end{itemize}
\paragraph{
  Covariate-Matched DiD with Micro-Level Data
}
In practice, we might form many matched subgroups from our sample for
which we'd like to estimate causal effects,
but for now, focus on a subset of units that represents a single
treatment group of interest, e.g. all individuals who were 16 years old
when a policy changed (an example of panel data) or all observations
of men's wages before

for which we construct a
single control/comparison group whose distribution of potential outcomes
is \emph{plausibly identical} to that of treatment group.
Hence we can write $G_{ist}\in\{0,1\}$,
with group membership is ``as good as randomly assigned''
so that we essentially have a dataset with treatment randomized across
units in the two groups.

The comparison group is constructed either by picking a comparison
group based on prior knowledge or matching based on some set of
\emph{pre-treatment} observables $X_{ist}$ such that matching on them
generates an identical distribution of distribution of potential
outcomes.

I use $G_{ist}$ rather than $G_{is}$ because we don't necessarily have
panel data in this setup (which would allow us to label units and drop
the $t$ index since an individual remains in the same group over time).

We don't don't necessarily assume that we have panel data;
our groups might be ``low income third year olds'' so that we

Fot he d
Note that these pre-treatment \emph{covariates} might even include
pre-treatment \emph{outcomes} (or the path of pre-treatment outcomes) if
we have multiple periods.
\begin{itemize}
  \item
    (\emph{Modeling Assumptions}):
    None needed because of assignment mechanism.

  \item
    (\emph{Assignment Mechanism Assumptions}):
    After the match, treatment is as good as randomly assigned,
    implying no correlation between potential outcomes and treatment.

    Example:
    After controlling for income, education, etc.,
    the distribution of potential outcomes for individuals in South
    Carolina are the same as those in California.

  \item
    (\emph{Identified Causal Params}):
    Because we're matching the treatment group, we'll estimate a set of
    ATETs.
    In particular, for all $t$, we can difference the averages in
    treatment and control groups to construct
    \begin{align*}
      \alpha_{t,ATET}
      :=&\;
      \E[Y_{ist}(1)-Y_{ist}(0)|G_{ist}=1]
      \\
      =&\;
      \E[Y_{ist}(1)|G_{ist}=1]
      -
      \E[Y_{ist}(0)|G_{ist}=1]
      \\
      G_{ist}\perp (Y_{ist}(0),Y_{ist}(1))
      \quad
      =&\;
      \E[Y_{ist}(1)|G_{ist}=1]
      -
      \E[Y_{ist}(0)|G_{ist}=0]
      \\
      =&\;
      \E[Y_{ist}|G_{ist}=1]
      -
      \E[Y_{ist}|G_{ist}=0]
    \end{align*}
    where the expectation is taken over $i$ and $s$, for fixed $t$.
    Note that for periods prior to treatment receipt, we expect no
    significant difference, which can be used to check the plausibility
    of the comparibility of the two groups.

    If we're uncomfortable assuming that the \emph{level} of outcomes is
    the same across units $s$, then we can allow for a time-invariant
    unit FE and still estimate ATETs at each time period, or use the
    Athey and Imbens changes-in-changes estimator.

  \item
    (\emph{Estimation of Causal Parameter}):
    Regress outcomes in each time period on a dummy for membership in
    the control group.
    If we want to allow for differences in average outcomes across
    aggregate units $s$, then we can do a standard DiD regression, with
    unit FE and a full set of dyanmic effects.

  \item
    (\emph{Sources of Uncertainty}):
    Random sampling of units, clustering of treatment (i.e. all units in
    a state), matching.

  \item
    (\emph{Relation to ``Parallel Trends''}):
    If we think the distribution of potential outcomes are identical
    across groups after our match, then we don't just expect
    \emph{parallel trends} in average outcomes prior to treatment
    but \emph{identical average outcomes} prior to treatment.
    And if we're uncomfortable assuming \emph{average} outcomes are
    identical across units $s$, then we might allow for unit-specific
    FE, in which case we are assuming parallel trends.

  \item
    (\emph{Implications for the DiD Estimand}):
    As in the previous bullet, under identical potential outcome
    distributions, DiD estimand is identified and has a causal
    interpretation, but the double differencing was unecessary since
    there were already identical average outcomes in the pre-treatment
    period.
    If we allow for different pre-treatment average outcomes, then the
    DiD estimand is the guy.

  \item
    Additional Comments:
    In some cases, matching may be done not just on covariates like
    race, age, income, but on pre-treatment outcomes.
    Examples and implications:
    \begin{itemize}
      \item Matching on pre-treatment outcomes
        This implies, for $t$ post-treatment,
        \begin{align*}
          (Y_{it}(0),Y_{it}(1))
          \perp
          G_{it}
          \;
          |
          \;
          \text{$Y_{is}$ for $s$ pre-treatment}
        \end{align*}


      \item Matching on pre-treatment trend in outcomes:
    \end{itemize}
\end{itemize}


\begin{comment}
- Changes in Changes
  - Model: Implicity common model btw grps,
- Random Assignment
  - Model: None neede
  - Assignment Mech: Random
  - Identified Causal Params
    - Ave outcomes under T or C for each period after treatment, hence ATEs
    - Average trends under T or C, hence ATEs for the trends
  - Est of Causal Param: Simple diffs in means between T & C
  - Sources of uncertainty: Assignment, sampling
  - Parallel trends: No assumption of this at all. For the treatment group, the counterfactual trend in outcomes *for those units* is completely missing/unidentified, and we make no parametric assumptions to extrapolate. The only thing identified is the average trends under T or C
  - DiD estimand one of many. Randomization lets us est straight diff in levels
- Assignment Correlated with Initial Level
- Assignment Correlated with Initial Trend
- Assignment Depends on Passing Threshold
\end{comment}


\clearpage
\subsection{Borusyak}

Setup
\begin{itemize}
  \item $Y_{it}$: Observed outcomes for $i=1,\ldots,N$
    and $t=1,\ldots,T$.
  \item $E_i$:
    Treatment time for unit $i$.
    This is in absolute/calendar time (not relative).
    If unit $i$ never treated and therefore a member of the control
    group, denote by $E_i=\infty$.
    We can use this to group units into cohorts with common treatment
    date (in absolute time).
  \item $K_{it}=t-E_i$:
    Relative time to treatment.
    Positive if $t$ is after the treatment receipt time for unit $i$,
    negative if before.
    If unit $i$ is never treated, denote this by $K_{it}=-\infty$.
  \item $D_{it}=\mathbf{1}\{t\geq E_i\}=\mathbf{1}\{K_{it}\geq 0\}$

  \item (\emph{Potential Outcomes}):
    For each unit and time combination $it$, there is a collection of
    potential outcomes $\{Y_{it}^{(k)}\}$ indexed by $k$, the time of
    treatment relative to $t$.

    So $Y_{it}^{(0)}$ is the outcome for unit $i$ at time $t$ if
    treatment for that unit occurs at $t$, $Y_{it}^{(1)}$ is the outcome
    for $i$ at time $t$ if realized treatment for that unit occurs at
    $t+1$, etc.
    In addition, if it's possible that a unit might never be treated,
    then we have $Y_{it}^{(-\infty)}$, i.e. the outcome for unit $i$ at
    time $t$ if the unit is \emph{never} treated.
    If all units are eventually treated, then this object is not
    well-defined.

    This choice of notation for potential outcomes is essentially
    assumption-free in that they allow past and even \emph{future}
    treatment ($k>0$) to influence potential outcomes in any given
    period $t$ arbitrarily, and the distribution of potential outcomes
    can be arbitrary.

  \item
    (\emph{Treatment Effects}):
    If it's possible for a unit $i$ \emph{never} to be treated,
    then the outcome $Y_{it}^{(-\infty)}$ is well-defined and can serve
    as baseline against which we define treatment effects,
    \begin{align*}
      \tau_{it}^{(k)}
      =
      Y_{it}^{(k)}
      -
      Y_{it}^{(-\infty)}
      \qquad
      \forall k
    \end{align*}
    If all units are eventually treated, as is typical in event studies,
    then there is no natural baseline against which to define treatment
    effects, and we can follow custom
    \begin{align*}
      \tau_{it}^{(k)}
      =
      Y_{it}^{(k)}
      -
      Y_{it}^{(-1)}
      \qquad
      \forall k
    \end{align*}
    where $\tau_{it}^{(k)}$ is, for unit $i$, the change in time $t$
    outcome if treatment occurs $k$ periods relative to $t$ rather than
    $-1$ periods relative to $t$ (i.e. in period $t-1$).

    Again, we typically restrict these treatment effects to be
    constant, but I wrote them without this assumption to be as general
    as possible for now.

  \item
    Realized Outcomes: $Y_{it}=Y_{it}^{(K_{it})}$.

  \item
    ``Event study'': All units receive treatment, but at random
    (often staggered) times $E_i$.

  \item
    Classical DiD:
    Control group, and all treated units receive treatment at the same
    time.
    %Only an additive constant in in $g_k$ not identified, $g_{-1}$
    %typically set to zero.
\end{itemize}
\paragraph{DGP Specification}
Standard specifications typically place further \emph{linearity}
(additive, constant effect) assumptions on the DGP for potential
outcomes $Y_{it}^{(k)}$ (and thus on treatment effects).
In particular, assume potential outcomes in any given period are
the sum of
\begin{itemize}
  \item Unit-specific and time-invariant effect, $a_i$
  \item Time-specific and unit-invariant effect, $b_t$
  \item Constant treatment effect $g_k$ based on the relative time $k$
    to treatment if unit is eventually treated.

    If $k<0$ (prior to treatment), these effects are typically called
    ``pre-trends.''
    If $k\geq 0$, these are typically called ``dynamic treatment
    effects.''
    But I will typically just use ``treatment effects.''

    At this stage, we are considering the most general model which
    allows for pre-trends.
    Later on, we will discuss cases where $g_k=0$ for all $k<0$ and the
    implications of this for identification.
\end{itemize}
Therefore, for any unit $i$, we define potential outcomes at $t$ based
on relative time of treatment receipt $k$ as follows:
\begin{align}
  Y_{it}^{(k)} = a_i + b_t + g_k + e_{it}
  \qquad
  %\text{$\forall$ treated $i$ and $\forall t=1,\ldots,T$}
  \forall i=1,\ldots,N
  \quad
  \forall t=1,\ldots,T
  \label{dgpt}
\end{align}
for some set of $a_i,b_t,g_k$ ``out there''
even if we can't always identify them.
If it's possible that unit $i$ is never treated, then
we naturally let $g_{-\infty}=0$, i.e.\ no treatment effect.

The quantities $a_i$, $b_t$, $g_k$ will all need to be normalized
somehow because the DGP only imposes constant treatment
\emph{effects} (unit FE, time FE, constant treatment effects),
which means that levels generally aren't identified.
This also gives rise to non-identification of certain objects.
We now discuss all of these identification and normalization issues.

%For any unit $i$ in the control group (i.e. any unit
%with $E_i=\infty$ and therefore is never treated),
%potential outcomes in period $t$ can be written
%\begin{align}
  %Y_{it}^{(-\infty)} = a_i + b_t + e_{it}
  %\qquad
  %\text{$\forall$ never-treated $i$ and $\forall t=1,\ldots,T$}
  %\label{dgpc}
%\end{align}
%for some set of $a_i,b_t,g_k$ we assume are ``out there''
%even if we can't always identify them.


\paragraph{Identification \& Normalization Issues}
\begin{itemize}
  \item
    (\emph{%
      Non-Identification of the Absolute Levels of $a_i$ and $b_t$
      Individually%
    })
    Notice that potential outcomes generated according to
    Expressions~\ref{dgpt} are numerically equivalent to potential
    outcomes generated according to the following model:
    \begin{align*}
      Y_{it}^{(k)}
      &=
      c
      +
      \underbrace{%
        ({a}_i+a)
      }_{%
        =:\hat{a}_i
      }
      +
      \underbrace{%
      ({b}_t+b)
      }_{%
        =:\hat{b}_t
      }
      +
      g_k
      +
      e_{it}
      \qquad\text{where}\quad
      0 = a+b+c
      %\\
      %Y_{it}^{(-\infty)}
      %&=
      %c
      %+
      %\underbrace{%
        %({a}_i+a)
      %}_{%
        %=:\hat{a}_i
      %}
      %+
      %\underbrace{%
      %({b}_t+b)
      %}_{%
        %=:\hat{b}_t
      %}
      %+
      %e_{it}
      %%\qquad\text{where}\quad
      %%0 = a+b+c
    \end{align*}
    Because we can always choose $(a,b,c)$ to sum to zero, there are
    then an infinite number of observationally equivalent models indexed
    by $(a,b,c)$ that can generate the exact same potential outcomes
    (numerically identical, not just distributionally).
    Because, by observing outcomes, we always observe the \emph{sum} of
    the individual effects $a_i$ and $b_i$ convolved together, we can
    reassign contributions from one source to the other (or to a
    constant) without changing potential outcomes.
    Said another way, there's no way to deconvolve their sum uniquely
    when observing outcomes alone.

    In principle this non-identification in the population DGP isn't a
    killer because, given a panel, we can still identify the \emph{sum}
    $a_i+b_t$.\footnote{%
      For now, assume that $g_k$ is identified or normalized and doesn't
      confound identification of this sum.
      We'll discuss these terms more later, as their presence certainly
      won't help.
      But for now, I just want to discuss inability to separately
      identify $a_i$ and $b_t$, whatever else might be going on with
      $g_k$.
    }
    To see this, notice that the set of observationally equivalent
    models is indexed by $(a,b,c)$ satisfying $0=a+b+c$, i.e. $(a,b,c)$
    that leave the sum $a_i+b_t$ unchanged.
    Moreover, we don't care about the individual levels of $a_i$ and
    $b_t$ per se, but rather the \emph{differential} effect of
    treatment, which differences out $a_i+b_t$ anyway.

    %All of this suggests that we really shouldn't characterize the
    %assumptions that we place upon the DGP in levels as in
    %Expression~\ref{dgpt}, since they're not identified.
    %Rather, we should summarize the assumptions in terms of
    %``constant differential effects for each time and unit.''
    %Rather, we should summarize the assumptions we put on the DGP in DiD
    %as
    %\begin{align*}
      %Y_{it}^{(-\infty)}
      %&=
      %Y_{is}^{(-\infty)}
      %+
      %b(s,t)
      %\qquad
      %\forall i
      %\\
      %Y_{it}^{(-\infty)}
      %&=
      %Y_{jt}^{(-\infty)}
      %+
      %a(j,i)
      %\qquad
      %\forall t
    %\end{align*}
    %In words, potential outcomes within a unit $i$ differ across times
    %$s$ and $t$ by a constant $b(s,t)$ that is independent of $i$ and
    %therefore common across units.
    %Also, potential outcomes within a time period $t$ differ across
    %units $i$ and $j$ by a constant $a(j,i)$ that is independent of $t$
    %and therefore common across times.
    %Expression~\ref{dgpt} implies this, i.e. $b(s,t)=b_t-b_s$ and
    %$a(j,i)=a_i-a_j$, but it uses unidentifiable $b_t$ and $a_i$ terms
    %to achieve this.
    %Since it's only the \emph{differences} $b(s,t)=b_t-b_s$ and
    %$a(j,i)=a_i-a_j$ that are identifiable, it would probably be
    %better to state the DGP assumptions in terms of these differences.

    %The easiest way to resolve this fundamental non-identification in
    %the population DGP is to \emph{normalize} (a strategy we will employ
    %throughout this discussion).
    %For example, we can simply choose the first unit $i=1$ as the
    %baseline unit and write
    %\begin{align*}
      %Y_{it}^{(-\infty)}
      %&=
      %\hat{a}_i
      %+ \hat{b}_t
      %+ e_{it}
      %\qquad\text{where}\quad
      %\hat{a}_1 = 0
    %\end{align*}
    This case of fundamental non-identification in the population DGP of
    the levels of $a_i$ and $b_t$ manifests in estimation in that we
    don't pin down the levels of $a_i$ or $b_t$, but rather choose some
    $it$ as the baseline (California in 2010), let the constant capture
    the level of this baseline, and then estimate \emph{differential}
    effects for different states and time periods relative to this
    baseline.
    We'll discuss estimation more below and show how to go from this
    population DGP to an estimable model whose estimands are identified
    functions of these population effects.

  \item
    (\emph{Non-Identification of the Absolute Levels of Treatment
    Effects $g_k$}):
    Notice that potential outcomes generated according to
    Expressions~\ref{dgpt} are numerically equivalent to potential
    outcomes generated according to the following model:
    \begin{align*}
      Y_{it}^{(k)}
      &=
      \underbrace{%
      ({a}_i+a)
      }_{%
        =:\hat{a}_i
      }
      +
      {b}_t
      +
      \underbrace{%
      (g_k+g)
      }_{%
        =:\hat{g}_k
      }
      +
      e_{it}
      \qquad\text{where}\quad
      0 = a+g
    \end{align*}
    Intuitively, because the DGP allows treatment to have an effect at
    \emph{all} leads and lags, if we observe a treated unit $i$, we
    cannot tell if a high level for its outcome is due to a larged fixed
    treatment effect contribution present at all leads and lags in the
    $g_k$, or simply to a high fixed effect present among all treated
    units.
    Stated in terms of the expression above, we can freely raise $a$ and
    lower $g$, or lower $g$ and raise $a$.
    This non-identification arises regardless of whether we have a
    control group.
    It is the allowance for unit fixed effects that causes this problem
    since they can perfectly absorb a constant component that appears in
    treatment effects $g_k$ at all leads and lags.

    If, in addition, we do not have a control group and all units are
    eventually treated, yet another numerically equivalent model for
    potential outcomes would be
    \begin{align*}
      Y_{it}^{(k)}
      &=
      c+
      \underbrace{%
      ({a}_i+a)
      }_{%
        =:\hat{a}_i
      }
      +
      \underbrace{%
      ({b}_t+b)
      }_{%
        =:\hat{b}_i
      }
      +
      \underbrace{%
      (g_k+g)
      }_{%
        =:\hat{g}_k
      }
      +
      e_{it}
      \qquad\text{where}\quad
      0 = a+b+c+g
    \end{align*}
    With no control group, there's no way to pin down the level of $b_t$
    separately from the $g_k$, and so we could freely take any
    constant contribution that's present in treatment effects at all
    leads and lags and instead reassign that to a constant component
    present at all leads and lags in the $b_t$.

    We already knew that non-identification of the levels of $a_i$ and
    $b_t$ gives rise to observationally equivalent models.
    But now we see that by allowing for treatment effects at all leads
    and lags, even the \emph{sum} $a_i+b_t$ is not uniquely identified
    anymore, regardless of whether or not we have a control group.

    In principle, however, none of this is a problem if we're interested
    in the \emph{dynamics} of treatment effects, i.e. the relative
    magnitude of treatment effects at different distances to the
    treatment receipt date, as we might legitimately be in event study
    designs.
    It also wouldn't be a problem if we wanted to posit such a model and
    inspect $g_k$ for $k<0$ to see if pretrends exist,\footnote{%
      However, there's an important caveat, as we discuss in the next
      bullet.
    }
    which is a statement about the dynamics of $g_k$ for $k<0$, not
    their level.

    Therefore, we normalize the level of treatment effects $g_k$
    since, once we allow treatment effects at all leads and lags,
    their level is not identified in the full DGP
    (regardless of whether or not we have a control group).
    This is typically done by setting $g_{-1}=0$.
    Under this normalization,
    \begin{align*}
      Y_{it}^{(-1)}
      &= a_i + b_t + e_{it}
      \\
      Y_{it}^{(k)}
      &= a_i + b_t + g_k + e_{it}
      \\
      \implies\quad
      Y_{it}^{(k)}
      -
      Y_{it}^{(-1)}
      &=
      g_k
    \end{align*}
    i.e.\ the $g_k$ represent treatment effects relative to potential
    outcomes $Y_{it}^{(-1)}$
    Moreover, this allows unique identification of the level of the sum
    $a_i+b_t$ (but not the level of $a_i$ and $b_t$ individually for
    reasons already discussed that are still applicable even after
    normalizing treatment effects).

  \item
    (\emph{Non-Identification of Linear Trends in $g_k$ if All Units
    Treated}):
    Fix $k=K_{it}$, which is the realized relative time to treatment for
    unit $i$ at time $t$. Because all units are treated, this is a
    finite number and we will observe the following outcomes:
    \begin{align*}
      Y_{it}
      =
      Y_{it}^{(K_{it})}
      &=
      a_i
      +
      b_{t}
      +
      g_{K_{it}}
      +
      e_{it}
    \end{align*}
    for some $\{a_i,b_t,g_k\}$ that are ``out there.''
    But potential outcomes generated in the manner above are
    numerically equivalent to potential outcomes generated according
    to the following model
    %Add a constant and another unit-specific effect to the unit effects,
    %add a linear trend in $t$ to the time effects,
    %and add a linear trend in $K_{it}$ to the treatment effects:
    \begin{align*}
      Y_{it}
      =
      Y_{it}^{(K_{it})}
      &=
      (a_i + \ddot{a}_i)
      +
      (b_t + m_b \cdot t)
      +
      (g_{K_{it}} + m_g \cdot K_{it})
      +
      e_{it}
      \\
      &=
      (a_i + \ddot{a}_i)
      +
      (b_t + m_b \cdot t)
      +
      (g_{K_{it}} + m_g \cdot [t-E_i])
      +
      e_{it}
      \\
      &=
      \underbrace{%
        (a_i + \ddot{a}_i - m_g E_i)
      }_{\hat{a}_i}
      +
      \underbrace{%
        (b_t + m_b \cdot t)
      }_{\hat{b}_t}
      +
      \underbrace{%
        (g_{K_{it}} + m_g \cdot t)
      }_{\hat{g}_{K_{it}}}
      +
      e_{it}
    \end{align*}
    if we ensure that
    \begin{align*}
      0 &= \ddot{a}_i - m_g E_i
      \\
      0 &= m_b + m_g \\
    \end{align*}
    Hence, on top of the usual non-identification of additive constants
    that we've already discussed (and did not include here, for simpler
    exposition), we now also see that there are an infinite number of
    observationally equivalent models that have distinct linear trends
    in the path of treatment effects.
    %Intuitively, in the case where all units are treated and there can
    %exist anticipatory treatment effects, we cannot distinguish between
    %a linear trend in treatment effects and a combination of a linear
    %time trend in the time-specific FE and a cohort effect.
\end{itemize}

\clearpage
Estimation
\begin{itemize}
  \item Observed outcomes:
    Consider a fully-dynamic DGP in which treatment effects for treated
    units are present at all leads and lags
    \begin{align*}
      Y_{it}
      =
      Y_{it}^{(K_{it})}
      &=
      a_i
      +
      b_t
      +
      g_{K_{it}}
      +
      e_{it}
      \\
      &=
      \sum_{j=1}^N
      a_j\mathbf{1}\{j=i\}
      +
      \sum_{s=1}^T
      b_s\mathbf{1}\{s=t\}
      +
      \sum_{k=\underline{K}}^{\overline{K}}
      g_{k}
      \mathbf{1}\{k=K_{it}\}
      +
      e_{it}
      \\
      &=
      \sum_{j=1}^N
      a_j\mathbf{1}\{j=i\}
      +
      \sum_{s=1}^T
      b_s\mathbf{1}\{s=t\}
      +
      \sum_{k=\underline{K}}^{\overline{K}}
      g_{k}
      \mathbf{1}\{k=t-E_i\}
      +
      e_{it}
    \end{align*}
    where $\overline{K}$ is the largest lag at which we observe a
    treatment effect, and $\underline{K}$ is the largest lead at which
    we observe a treatment effect.
    %We now discuss how to turn this model into something estimable, and
    %how to identify components of this DGP with regression estimands.

    Notice that the full set dummies on the $a_j$ terms can construct
    the $1_{n\times 1}$ vector, and so can full the set of dummies on
    the $b_s$ terms. In other words, we have colinearity.
    This can be solved by dropping $\mathbf{1}\{k=i\}$ for some $k$, or
    dropping $\mathbf{1}\{u=t\}$ for some $u$.
    Even more common is to introduce a constant and drop
    $\mathbf{1}\{k=i\}$ for some $k$ \emph{and}
    $\mathbf{1}\{u=t\}$ for some $u$.
    This solves the colinearity problem in the FE dummies and
    establishes $ku$ as the baseline.
    Then coefficients on the time period and unit dummies represent
    differential effects relative to this baseline.
    To see all of this,
    \begin{align*}
      Y_{it}
      =
      Y_{it}^{(K_{it})}
      &=
      \sum_{j=1}^N
      (a_j-a_k+a_k)\mathbf{1}\{j=i\}
      +
      \sum_{s=1}^T
      (b_s-b_u+b_u)\mathbf{1}\{s=t\}
      +
      \sum_{k=\underline{K}}^{\overline{K}}
      g_{k}
      \mathbf{1}\{k=K_{it}\}
      \\
      &=
      (a_k + b_u)
      +
      \sum_{j=1}^N
      (a_j-a_k)\mathbf{1}\{j=i\}
      +
      \sum_{s=1}^T
      (b_s-b_u)\mathbf{1}\{s=t\}
      +
      \sum_{k=\underline{K}}^{\overline{K}}
      g_{k}
      \mathbf{1}\{k=K_{it}\}
      \\
      &=
      (a_k + b_u)
      +
      \sum_{j\neq k}
      (a_j-a_k)\mathbf{1}\{j=i\}
      +
      \sum_{s\neq u}
      (b_s-b_u)\mathbf{1}\{s=t\}
      +
      \sum_{k=\underline{K}}^{\overline{K}}
      g_{k}
      \mathbf{1}\{k=K_{it}\}
      \\
      &=
      (a_k + b_u)
      +
      \sum_{j\neq k}
      (a_j-a_k)\mathbf{1}\{j=i\}
      +
      \sum_{s\neq u}
      (b_s-b_u)\mathbf{1}\{s=t\}
      +
      \sum_{k=\underline{K}}^{\overline{K}}
      g_{k}
      \mathbf{1}\{k=t-E_{i}\}
    \end{align*}


  \item (\emph{With Untreated Units and Common Adoption}):
    With common adoption,
    \begin{align*}
      Y_{it}
      =
      Y_{it}^{(K_{it})}
      &=
      (a_k + b_u)
      +
      \sum_{j\neq k}
      (a_j-a_k)\mathbf{1}\{j=i\}
      +
      \sum_{s\neq u}
      (b_s-b_u)\mathbf{1}\{s=t\}
      +
      \sum_{k=\underline{K}}^{\overline{K}}
      g_{k}
      \mathbf{1}\{k=t-E\}
    \end{align*}
    Probably need to drop a $g_k$ because, from the dummies of units and
    the constant, I can construct a column vector where I pick up all
    the treated units and times.
    From the dummies of the treatment, I can construct that same thing.
    This points to identification problem even if non-treatment possible.
    Specifically, I can't tell if outcomes due to common treatment
    effect at all leads and lags or FE for treated units.


  \item (\emph{With Untreated Units and Staggered Adoption}):
    Now consider the dummies $\mathbf{1}\{k=K_{it}\}$.
    Consider the dummy for $k=0$.
    This is zero except for the units $i$ and times $t$ where treatment
    occurs.
\end{itemize}




\begin{itemize}
  \item
    The above assumptions imply
    \begin{align*}
      Y_{it}
      =
      Y_{it}^{(K_{it})}
      &=
      \tilde{\alpha}_i
      +
      \tilde{\beta}_t
      +
      \tilde{\gamma}_{K_{it}}
      +
      \tilde{\varepsilon}_{it}
      \\
      &=
      \tilde{\alpha}_i
      +
      \tilde{\beta}_t
      +
      \sum_{k=-\infty}^\infty
      \tilde{\gamma}_k
      \mathbf{1}\{K_{it}=k\}
      +
      \tilde{\varepsilon}_{it}
    \end{align*}



  \item Semi-Dynamic DGP:
    Constant treatment effects that are generally nonzero at all lags,
    but no leads:
    \begin{align*}
      Y_{it}
      &=
      \tilde{\alpha}_i
      +
      \tilde{\beta}_t
      +
      \sum_{k=0}^\infty
      \tilde{\gamma}_k
      \mathbf{1}\{K_{it}=k\}
      +
      \tilde{\varepsilon}_{it}
    \end{align*}



\end{itemize}




\clearpage
\subsection{Reading List}

Books and reviews
\begin{itemize}
  \item Matched Sampling for Causal Effects, Rubin (2006)
  \item Observation and Experiment: An Introduction to Causal Inference, Rosenbaum 2017
  \item DAGs and PO: Imbens (2019)
  \item Econometric methods for program evaluation, Abadie and Cattaneo
    (2018)
\end{itemize}
Papers
\begin{itemize}
  \item History
    \begin{itemize}
      \item James Heckman (1990), Varieties of selection bias.
      \item Charles F Manski (1990), Nonparametric bounds on treatment effects.
    \end{itemize}
  \item Estimating Causal Effects of Treatments in Randomized and
    Nonrandomized Studies, Rubin 1974
  \item \cite{imbensangrist1994LATE}:
    LATE, uses monotonicity to obtain identification in the presence of treatment effect heterogeneity
  \item Sekhon and Shem-Tov: Inference on a new class of sample average
    treatment effects
  \item Estimation and design of optimal policy functions given
    treatment effect heterogeneity
    \begin{itemize}
      \item  Efficient Policy Learning, Athey and Wager (2017):
      \item Generalized random forests by Athey, Tibshirani, Wager, et
        al (2019):
      \item Who Should be treated?, Kitagawa and Tetenov (2015):
    \end{itemize}
  \item
    Assessing sensitivity to an unobserved binary covariate
    in an observational study with binary outcome,
    Rosenbaum and Rubin (1983)
  \item Why ask why? forward causal inference and reverse causal
    questions, Gelman and Imbens (2013)
  \item Unconfoundedness and problems with overlap
    \begin{itemize}
      \item The central role of the propensity score in observational
        studies for causal effects,
        Rosenbaum and Rubin (1983)
      \item
        Crump, Hotz, Imbens, Mitnik (2009)
      \item D'Amour, Ding, Feller, Lei, Sekhon (2017)
      \item Li, Morgan, Zaslavsky (2018)
    \end{itemize}
  \item Double Robustness
    \begin{itemize}
      \item Robins and Rotnitzky (1995)
      \item Imbens (2004)
      \item Belloni, Chernozhukov, Fernandez-Val, Hansen (2013)
      \item Athey, Imbens, Wager (2018)
    \end{itemize}
  \item RD
    \begin{itemize}
      \item Hahn, Todd, and Van der Klaauw 2001
      \item Imbens and Kalyanaraman 2012
    \end{itemize}
  \item Estimating Heterogeneous Treatment Effects
    \begin{itemize}
      \item Athey and Imbens (2016)
      \item Wager and Athey (2017)
    \end{itemize}
  \item Synthetic Control
    \begin{itemize}
      \item Abadie, Diamond, and Hainmueller (2010)
    \end{itemize}
  \item Network Settings
    \begin{itemize}
      \item Graham (2015)
      \item Ogburn, VanderWeele, et al (2014)
    \end{itemize}
  \item
    Multi-valued Treatment:
    The role of the propensity score in estimating dose–response
    functions,
    Imbens (2000)

  \item Interference
    \begin{itemize}
      \item Exact p-values for network interference by Athey, Eckles,
        and Imbens (2018)
      \item Randomization tests of causal effects under interference
        by Basse, Feller, and Toulis (2019)
      \item A general method for detecting interference between units in
        randomized experiments, Anarow (2012)
      \item Estimating average causal effects under interference between
        units, Anarow and Samii (2013)
    \end{itemize}

  \item Business
    \begin{itemize}
      \item A modern bayesian look at the multi-armed bandit
      \item
        Top challenges from the first practical
        online controlled experiments summit
      \item Estimation considerations in contextual
        bandits.
      \item Balanced linear contextual bandits.
      \item Is the fda too conservative or too
        aggressive?: A bayesian decision analysis of clinical trial
        design
    \end{itemize}


  \item High dimensions
    \begin{itemize}
      \item Double/debiased/neyman machine learning of treatment effects
      \item Approximate residual balancing: debiased
        inference of average treatment effects in high dimensions.
    \end{itemize}

  \item
    Sensitivity analysis
    \begin{itemize}
      \item  Measuring the sensitivity of parameter estimates to
        estimation moments.
      \item A simple approximation for evaluating external validity
        bias.
    \end{itemize}
\end{itemize}

\clearpage
DAGs
\begin{itemize}
  \item Terminology
    \begin{itemize}
      \item Nodes: Variables
      \item Edges: Arrows connecting nodes, direction matters
      \item Parents of Some Target Node
        %All nodes in the graph with an arrow from them that's directed
        %\emph{into} the target node
      \item Ancestors of Some Target Node
        %Parents of target node, parents of its parents, and so on.
      \item Children of Some Target Node
        %: All nodes in the graph with an arrow into them that's directed
        %\emph{from} the target node
      \item Descendents of Some Target Node
        %: Children of the target node, children of its children, and so
        %on.
      \item Path: Set of connected edges, irrespective of the direction
        of arrows.
      \item Collider of a path:
        Node with arrows in, no arrows out, e.g.  $Z_2$ in
        $X \ra Z_2 \leftarrow Z_1$
      \item Directed Path: All arrows in same direction
      \item Back-Door Path from node $A$ to $B$:
        Starts with incoming arrow into $A$ and ends with incoming arrow
        into $B$, e.g.  $A \leftarrow X \ra Y \ra B$.

        Generally contains both colliders and non-colliders.
        Must contain at least one non-collider.
      \item Path between $A$ and $B$ is \emph{blocked} or
        \emph{$d$-Separated} by conditioning on subset $\mathbb{Z}_1$ (of
        the set of all nodes $\mathbb{Z}$) if and only if \emph{one} of
        the following conditions is satisfied:
        \begin{enumerate}[label=(\roman*)]
          \item $\mathbb{Z}_1$ contains a non-collider
          \item The path contains a collider
            \begin{enumerate}[label=(\alph*)]
              \item Not in $\mathbb{Z}_1$ and
              \item With no descendents in $\mathbb{Z}_1$
            \end{enumerate}
        \end{enumerate}
        i.e. ``To block, condition on a non-collider, or don't condition
        on a collider or any of its descendents.''
    \end{itemize}
  \item Do Operator:
    We observe associations and the conditional distribution
    $P(Y|X=x)$ but this is potentially distinct from the distribution
    we'd observe if we \emph{manipulate} $X$, which implies a
    potentially distinct distribution denoted $P(Y|{do}(X=x))$.
    We are interested in conditions under which
    $P(Y|X=x)=P(Y|{do}(X=x))$ (i.e. the observed associations are
    causal) or we can estimate $P(Y|{do}(X=x))$ after perhaps
    adjusting for other observables.
  \item Do-Calculus:
    Surgery performed on the graph to infer causual associations.
    Three fundamental rules:
    \begin{enumerate}
      \item
        $P(Y|do(X),Z,W)=P(Y|do(X),Z)$
        if we delete all paths into $X$, and $Z$ blocks all paths from
        $W$ to $Y$.
      \item Back-Door Criterion:
        $P(Y|do(X),Z)=P(Y|X,Z)$ if $Z$ blocks all back-door paths from
        $X$ to $Y$.

        In practice, collect all back-door paths from $X$ to $Y$, and
        find a $Z$ that blocks all of them.
        This method helps you determine what to condition on to get
        proper causal statements.

      \item $P(Y|\text{do}(X))=P(Y)$ if no path from $X$ to $Y$ with
        only forward directed arrows.
    \end{enumerate}

\end{itemize}




\clearpage
\section{Design-Based Inference}

\begin{itemize}
  \item Samples, Populations, and Superpopulations
    \begin{itemize}
      \item Population:
        The finite set of units for which we observe realized outcomes,
        covariates, treatment.
        Can do inference conditioning on this population.

      \item Superpopulation Perspective:
        The finite set of units for which we observe outcomes (called
        the finite sample) was \emph{sampled} from a superpopulation,
        which we generally take to be infinite, although it might just
        be very large.
    \end{itemize}
  \item Assignment mechanism:
    The function that determines probabilities for the full vector of
    assignment.
    This in general can depend upon potential outcomes and covariates,
    and can be written
    \begin{align*}
      P[W\,|\,X, Y(0), Y(1)]
    \end{align*}
    From this, we can determine unit assignment probabilities
    \begin{align*}
      p_i(X,Y(0),Y(1))
    \end{align*}
    which sum over all full assignment vectors with $W_i=1$.

    We can alo determine finite-population propensity scores at a given
    level of covariates by adding up the unit level assignment
    probabilities for all individuals with that level of covariates
    \begin{align*}
      e(x)
      =
      \frac{1}{N(x)}
      \sum_{i:X_i=x}
      p_i(X,Y(0),Y(1))
    \end{align*}
    In general, the is just the average assignment probability.
    Under unconfoundedness and individualistic assignment, it is also
    unit-level assignment probability.

  \item Restrictions on the assignment mechanism.

    Individualistic assignment:
    There exists a function $q(\,\cdot\,)$ such that
    \begin{align*}
      p_i(X,Y(0),Y(1))
      =
      q(X_i,Y_i(0),Y_i(1))
    \end{align*}
    Unconfounded assignment
    \begin{align*}
      P[W|X,Y(0),Y(1)]
      =
      P[W|X]
    \end{align*}

  \item
    Assignment Mechanism and Superpopulation:
    Sample of size $N$ is from an infinite superpopulation.
\end{itemize}


\clearpage
\begin{itemize}
  \item Sampling approach:
    \begin{itemize}
      \item
        Units at hand are a size-$N$ sample realization randomly drawn
        from a larger superpopulation, generally infinite.

      \item
        In this conception, treatment assigment $D$ was set before
        drawing the sample.
        Hence random assignment here means that the joint
        superpopulation law over both potential outcomes $(Y(1),Y(0))$
        and $D$ (i.e. the assignment mechanism) exhibits independence.

      \item Since our units are a random sample draw from the
        population, outcomes (and potential outcomes) are realizations
        of $N$ random objects.

      \item Estimand is defined in terms of the superpopulation law.

      \item Interpretation of asymptotics:
        Because the estimand is defined in terms of the superpopulation
        law, it is \emph{fixed} in asymptotics where the sample size
        grows because we draw more and more observations iid from the
        superpopulation law.
        Thus we use a CLT for iid random variables to get asymptotic
        approximations to the distribution of estimator $\hat{\theta}$
        about fixed superpopulation estimand $\theta$.
    \end{itemize}

  \item Design Approach:
    \begin{itemize}
      \item Units at hand are the population of interest.
      \item
        We randomly assign units in this finite population to treatment
        or control.
        We can imagine running the experiment again, getting a different
        assignment vector, and correspondingly different estimates of
        the average treatment effect.

      \item Potential outcomes for the units under study are fixed and
        are just what they are; they are not realizations of random
        variables.

      \item Estimand is defined in terms of this finite sample
        population.

      \item
        Interpretation of Asymptotics:

        To get asymptotic approximations, we can conceive of some
        infinite sequence of outcomes and potential outcomes
        $\{Y_i,Y_i(1),Y_i(0)\}$ and a sequence of

      \item If we have many observations, we can invoke a CLT for random
        but not necessarily identically distributed
    \end{itemize}
    Potential outcomes fixed, assignment of subjects to treatment is
    random.

  \item Internal validity (Shadish, Cook, and Campbell 2002):
    The \emph{observed} covariance between treatment and an outcome
    reflects a causal relationship, i.e. the covariance we
    \emph{would} observe if we could manipulate the variables.
    The question  of internal validity is
    ``Can we estimate causual effects within the study population?''

    External validity:
    Does the causal relationship hold in other settings with different
    poulations/persons, treatment types or admistration of treatment,
    different institutional contexts?

  \item
    Assignment mechanism in randomized studies:
    Draw a certain number of individuals to receive the treatment, and
    then give them the treatment.

  \item
    Stratified experiment:
    Partition the population on the basis of covariate values into $G$
    strata, fix number of untis we will draw from each stratum, full
    randomization within stratum.

    Paired randomized experiments:
    Pair up individuals and randomize within pairs.

    Clustered randomized experiments:
    Partition the covariate space (like a stratified experiment), but
    assign treatment randomly to entire randomly selected clusters, with
    all units in the cluster receiving the same level of treatment.
    More generally, can vary the selection probabilities by cluster, and
    the assignment to treatment probabilities for individuals within a
    cluster.

  \item
    Randomization inference for average treatment effects:
    Suppose interested in
    \begin{align*}
      \tau
      :=
      \frac{1}{N}
      \sumiN
      \big(
      Y_i(1)-Y_i(0)
      \big)
      =
      \overline{Y}(1)
      -
      \overline{Y}(0)
    \end{align*}
    Estimator
    \begin{align*}
      \hat{\tau}
      =
      \overline{Y}_t^{obs}
      -
      \overline{Y}_c^{obs}
    \end{align*}
    If we average over the randomization distribution,
    then estimator $\hat{\tau}$ is unbiased for $\tau$ and has variance
    \begin{align*}
      \Var(\hat{\tau})
      =
      \frac{S^2_c}{N_c}
      +
      \frac{S^2_t}{N_t}
      -
      \frac{S^2_{tc}}{N}
    \end{align*}
    where $S^2_c$, $S^2_t$, and $S^2_{tc}$ are population quantities.
    Can construct unbiaed estimators for the first two terms.
    The third term---which correspods to the variance of the treatment
    effect in the population---is not estimable, but if constant
    treatment effects, it equals zero.

    Suppose the sample at hand is a random sample from the population
    (rather than the population of interest) and we are interested in
    population ATE
    \begin{align*}
      \tau = \E[Y_i(1)-Y_i(0)]
    \end{align*}
    Estimator is the same
    \begin{align*}
      \hat{\tau}
      =
      \overline{Y}_t^{obs}
      -
      \overline{Y}_c^{obs}
    \end{align*}
    If we average over also the \emph{sampling} (in addition to
    randomization of treatment), then the variance of this estimator is
    given by
    \begin{align*}
      \Var(\hat{\tau})
      =
      \frac{S^2_c}{N_c}
      +
      \frac{S^2_t}{N_t}
    \end{align*}
    Given only unbiasedness and variance, we do not have enough for
    inference about $\tau$ using $\hat{\tau}$, and we need to appeal to
    large sample approximations.
    Two options
    \begin{itemize}
      \item Assume the sample is drawn iid from an infinite
        superpopulation and invoke standard CLT
      \item Assume sequence $(Y_i(0),Y_i(1))$ nice enough that we can
        apply a CLT for independent, but not necessarily identically
        distributed RVs.
    \end{itemize}
    But we can suppose the sample is big enough to appeal to
    large sample approximations. This does not mean we care about a
    superpopulation, just that we think normality of our estimators
    holds approximately.




\end{itemize}




\paragraph{Check out}
\begin{itemize}
  \item Young 2016: Randommization methods in development economics.
  \item Meager 2015: Microfinance programs
  \item Imbens 2010: Differences in treatment effects between locations
    arise from differences in distributions of \emph{characteristics} of
    the units in those locations, so can reweight
  \item Allcott 2015: Assets ability of similar unconfoundedness
    conditions to eliminiate the difference in treatment effects between
    111 energy conservation programs.
  \item Romano, Shaikh, and Wolf (2010) for multiple testing
  \item Imbens and Kolesar 2015
  \item Freedman (2008): On regression adjustments, talk about bias
    when trying to do regression adjustments in experimental data. If
    heavy skew, not worth it.
  \item
    Hudgens and Holleran,
    where the they figure out how to break a network into approximately
    independent clusters.
    Decomposition into direct and indirect effects.
\end{itemize}
\paragraph{My Project}
\begin{itemize}
  \item Consider the ratio of outcomes as a definition of causal effects
    as a way to get at the derivative with respect to distance.
  \item How to deal with spillovers.
    Computational or log odds ratio way of getting at degree of
    spillovers
  \item Using PCA for stratification.
    I have pretreatment covariates,
    I use PCA to break them up into clusters,
    but there is uncertainty in how I form the strata.
    Does that outweigh?
    Maybe I have an auxiliary dataset where I can run regressions and
    figure out how to stratify?
    Or maybe I learn about treatment effect heterogeneity in pre-step.

  \item
    Extreme example of spatial thing is that everyone in the cluster
    gets the same treatment.
    This is the spirit of the ring method.
    Hence the comments about causal inference in a clustered randomized
    experiment setting hold.

    In my project, I might allow for spillovers to depend on the
    structure of individuals within the ring, and I can estimate the
    strength of those spillovers perhaps since each ring has a different
    configure of individuals.
    Like if I know the position of units, that might help?

    Also, I can reweight observations within a big cluster allowing for
    spillovers to get at a better causal effect.

  \item
    Testing null of homogeneity of treatment effects against alternative
    of heterogeneity, constant size of the effect is a nuisance
    parameter.
    Take the difference, test whether variance is statistically
    significantly different from zero, which we could do if we observed
    both.
    We don't, so what can you do?
    Impute, pair up?
    Is that most powerful?

  \item
    What are some other Ulrich papers I can write using tricks with
    nuisance parameters and least favorable distributions and such in
    the case of an almost sharp null hypotheses, but with nuisance
    parameters.


  \item
    Overid tests in cases where I'm concerned about internal validity.
    Imbens (where he adjusts for differences in covariates) and
    an overid test assuming that's all good to see if external validity
    holds.

  \item
    Distance based interactions and spillovers.
    Use the fact that there are multiple individuals at the same
    distance, but with different people nearby.

  \item
    Imbens and Athey say to focus on cluster level analysis, since
    unit-level analysis is so tough

  \item
    Two-way clustering, causal inference perspective to see if it can
    make sense.

  \item
    Think of the area around a treatment center as a cluster, and there
    are many potential clusters.

  \item Estimating treatment effect heterogeneity, Athey and Imbens, PCA
    to get at which observables explain the most variation
\end{itemize}
Key stuff
\begin{itemize}
  \item What are the causal estimands, what can I estimate?
  \item Stratification and how to use covariates for better estimation
  \item How should I cluster?
    Suppose interested in design
  \item Hudgens and Holloran network shit
\end{itemize}


\clearpage
There are a bunch of individuals at a bunch of locations with different
potential outcomes.
A configuration $\calC$ will induce a set of treatments.
\begin{align*}
  \{Y(\ell)\}
  =
  \{Y^p(\ell,d(\ell,\calC))\}
\end{align*}
We can consider an alternative proposed treatment, $\calC'$, which wold
induce
\begin{align*}
  \{Y'(\ell)\}
  =
  \{Y^p(\ell,d(\ell,\calC'))\}
\end{align*}
We can compute multiple statistics
\begin{itemize}
  \item Average outcome
    \begin{align*}
      \frac{1}{|L|}
      \sum_{\ell\in L}
      Y'(\ell)
      =
      \frac{1}{|L|}
      \sum_{\ell\in L}
      Y^p(\ell,d(\ell,\calC'))
    \end{align*}
    We need an estimator of that.
    Want unbiased over randomization distribution.

    Can hit that by adjusting for up the number of times that the
    location falls into that distance bin.
\end{itemize}
Superpopulation
\begin{itemize}
  \item There is a law which generates units and where they live
  \item What assumptions do I need on where they live?
  \item Consider sequence of finite sample populations
\end{itemize}










\clearpage
\section{Panel Data}

DGPs:
The models for $Y_{it}$, i.e. outcomes for unit $i$ at time $t$, include
the following:
\begin{enumerate}
  \item Pooled DGP:
    No unit or time FE
  \item FE model:
    Time-invariant FE for each unit, can be
    \emph{arbitrarily} correlated with the $X_i$
  \item Random Effect model:
    There exist time-invariant FE for each unit, but uncorrelated with
    the attributes $X_i$ because all drawn independently from a common
    model
\end{enumerate}
Estimation Approaches and when they work (i.e. under which DGPs they are
unbiased, consistent, and/or efficient):
\begin{itemize}
  \item Pool OLS: Just regress outcomes on covariates, no unit or
    time-spec effects

    Works for pooled OLS DGP.
    Also works for RE DGP, but RE \& FE estimators more efficient.

  \item FE estimator:
    Works for FE \emph{and} RE DGP.
    If the the DGP is truly the FE DGP, then the FE estimator is less
    efficient, but still consistent.

  \item RE estimator:
    Works if RE DGP and is efficient under that DGP.
    But if FE DGP, then inconsistent.
\end{itemize}
Hausman Test:
FE estimator consistent under FE or RE DGP, RE efficient and
consistent only under RE DGP



\clearpage
\section{Statistical ML}

Minimax risk and its rate
\begin{align*}
  \inf_{\hat{\theta}}
  \sup_{P\in \calP}
  \E_P[L(\hat{\theta},\theta)]=R_n
\end{align*}
This is a rate that changes with sample size $n$.
$\calP$ is a statistical model (collection of general distributions).
$\theta$ is very general, not necessarily a finite-dim Euclidean param.





\clearpage
\section{Macro Methods}

\subsection{Solving Linear RE Models}

Any model implies \emph{equilibrium conditions}, which can generally be
written
\begin{align*}
  F(X_{t-1}, X_t, X_{t+1}, \varepsilon_t) = 0
\end{align*}
To solve on the computer, we will often write a function for this, which
returns the residuals (which should equal zero) corresponding to each
equilibrium condition.

Can obtain linearized equilibrium conds numerically, written in
canonical form
\begin{align*}
  A \E_t[X_{t+1}] + BX_t + C X_{t-1} + V \varepsilon_t = 0
\end{align*}
How? Expectations?

Solving the linear system means finding $P$ and $Q$ such that we have
\emph{linearized dynamics}
\begin{align*}
  X_t = PX_{t-1} + Q\varepsilon_t
\end{align*}
There exist methods/standard approaches to find $P$ and $Q$, which then
allow simulation, estimation, IRF computation, etc.

\emph{Certainty equivalence}:
Solution satisfies ``certainty equivalence.''
Given linearized dynamics, we can find a solution (linearized dynamics)
of the form above in which the distribution (including variance) of
shocks does not matter, only their mean (of zero).


\clearpage
\subsection{Endogenous Grid Point Method}

Fluctuating income problem
\begin{align*}
  \max
  &
  \;
  \E_0\left[
    \sumtinfz
    \beta^t
    \frac{c_t^{1-\gamma}}{1-\gamma}
  \right]
  \\
  &a'+c = Ra + e
\end{align*}
Equilibrium characterized by Euler Equation
\begin{align*}
  c^{-\gamma}
  =
  \beta R
  \E[c'{}^{-\gamma}]
  =
  \beta R
  \E\bigg[
    \big(
    Ra' + e' - a''
    \big)^{-\gamma}
  \bigg]
\end{align*}
States are $(a,e)$ and choice variables are $(a',c)$.

Value function iteration:
Set up a grid for $(a,e)$ and do value function iteration to find
unknown optimal policy $g(a,e)$.

Endogeneous grid point method:
Set up a grid for $a'$, compute $a$ grid, infer policy function.
\begin{enumerate}
  \item Fix a grid for $a'$ (the set of savings/asset amounts the agent
    will choose).
    For each $a'$ in the grid, the optimal policy function implies an
    associated/$a'$-consistent level of initial consumption $c$ and
    initial $a$.
    We will iterate on policy functions until convergence.

  \item Guess policy function $g(\cdot,\cdot)$.

  \item
    Determine $(a,c)$ grid:
    Rewrite the Euler equation given this policy function guess
    \begin{align*}
      c^{-\gamma}
      &=
      \beta R
      \E[c'{}^{-\gamma}]
      =
      \beta R
      \E\bigg[
        \big(
        Ra' + e' - g(a',e')
        \big)^{-\gamma}
      \bigg]
    \end{align*}
    Because $a'$ is chosen today, the only uncertainty from the
    expectation comes from $e'$.

    %Note:
    %The two choice values $(c,a')$ are jointly determined by the above
    %EE (an equilibrium optimality condition) and the budget constraint.
    %One implies the other always.

    For each $a'$ in the grid, compute RHS of EE.
    This will give the $c$ values consistent with that $a'$.
    Then by budget constraint, can also compute the $a$ consistent with
    that $a'$,
    \begin{align*}
      a =
      \frac{1}{R}
      \big[
      a' + c - e
      \big]
    \end{align*}

  \item
    By computing $(a,c)$ consistent with a given $a'$, we have an
    equilibrium map from $(a,e)\ra a'$, i.e. an updated guess for the
    function $g(\cdot,\cdot)$.
    Iterate until convergence.
\end{enumerate}
Projection method interp
\begin{itemize}
  \item $g(a,e;G)$: Savings policy function parameterized by $G$
  \item $c(a,e;G)=Ra+e-g(a,e;G)$: Consumption
    policy implied by $g(a,e;G)$ and BC
  \item $C(a',e;G)=(\beta R\E[c(a',e';G)^{-\gamma}])^{-\frac{1}{\gamma}}$:
    Consumption policy implied by $g(a,e;G)$ and EE
  \item $C(a',e;G)=c(g^{-1}(a',e;G),e;G)$: Should hold, can rearrange to
    get
    \begin{align*}
      R(a',e;G)
      = \frac{C(a',e;G)}{c(g^{-1}(a',e;G),e;G)} - 1
      = 0
    \end{align*}
\end{itemize}
Reiter method
\begin{itemize}
  \item Idiosyncratic shocks but no aggregate shocks
  \item Discretize economy, replacing equilibrium policy functions and
    wealth distribution with vectors
  \item Specify equations that these variables must satisfy, e.g.
    Euler equation and transition equation over states
  \item Specify aggregate equations governing the evolution of aggregate
    quantities, which might interact with the discretized policy rules
    and wealth distribution
  \item Stack equilibrium conditions into large system, linearize, solve
  \item There will be a decision rule for each date and a distribution
    of wealth for each date, so index vectors for policy functions and
    wealth distribution by $t$.
\end{itemize}






\clearpage
\subsection{Sequence Space}

\paragraph{Equilibrium Conditions}
A model contains/describes a sequence of exogenous vectors of aggregate
quantities $\{Z_s\}$ in $\R^{n_z}$ and endogenous vectors of aggregate
quantities $\{U_s\}$ in $\R^{n_u}$.
The latter are $n_u$ unknowns that are determined by $n_u$ equilibrium
(market clearing) conditions for each $t$:
\begin{align*}
  \underset{(n_u\times 1)}{0}
  &=
  H_t\big(
    \{
    \underset{(n_u\times 1)}{U_s}
    \}_{s=0}^\infty
  ,
    \{
    \underset{(n_z\times 1)}{Z_s}
    \}_{s=0}^\infty
  \big)
  \qquad
  \forall t=0,2,\ldots
\end{align*}
Truncating after $T$ periods (i.e. until period $T-1$), this can all be
stacked into
\begin{align}
  \underset{(n_u\times T)}{0}
  =
  H\big(
  \underset{(n_u\times T)}{U}
  ,
  \underset{(n_z \times T)}{Z}
  \big)
  \label{eqconds}
\end{align}
\paragraph{%
  Linearizing Aggregate Dynamics via Market Clearing Jacobians (w.r.t.
  Aggregates)
}
We can linearize (about steady state) the dynamic response of the
endogeneous aggregates to changes in the exogenous aggregates via the
implicit function theorem:
\begin{align*}
  \underset{(n_u\times T)}{0}
  &=
  H_U \, dU + H_Z \, dZ
  \\
  \implies\quad
  dU
  &=
  -H_U^{-1} H_Z dZ
\end{align*}
where $H_U$ and $H_Z$ are the Jacobians of $H$ (with respect to
aggregates) evaluated at steady state.
Notice that we need only compute $H_U^{-1}H_Z$ once, and we can recycle
it to compute the respose $dU$ to \emph{any} sequence of exogenous
shocks $dZ$.

A little more detail is necessary.
Because of the dynamic nature of the model (it is potentially both
forward and backward looking in all endogeneous and exogenous
variables), each entry $H_{it}(U,Z)$ in the $(n_u\times T)$
function/matrix in Expression~\ref{eqconds} can, in principle, respond
to \emph{any} endogenous or exogenous variable at any lead or lag.
Therefore, to be a bit more explicit about things, the linearization can
be rewritten elementwise (i.e. for each entry $H_{it}(U,Z)$ in the
matrix/function given in Expression~\ref{eqconds}) by
\begin{align*}
  \underset{(1 \times 1)}{0}
  =
  dH_{it}(U,Z)
  &=
  \sum_{j=1}^{n_u}
  \sum_{s=0}^{T-1}
  \frac{\partial H_{it}(U,Z)}{\partial U_{j,s}}
  dU_{j,s}
  +
  \sum_{j=1}^{n_z}
  \sum_{s=0}^{T-1}
  \frac{\partial H_{it}(U,Z)}{\partial Z_{j,s}}
  dZ_{j,s}
\end{align*}
The computation of market clearing Jacobians (with respect to
aggregates) $H_U$ and $H_Z$ is done in pieces via the chain rule, which
is both convenient and necessary because of the heterogeneity hidden
under the aggregate quantities and because of the intermediation of
prices.

\clearpage
\paragraph{Decomposing Market Clearing Jacobians via the Chain Rule}
``Market clearing Jacobians with respect to Aggregates'' describe how
the market clearing conditions respond to changes in aggregates.
We can usefully break up the computation of these as follows.
\begin{itemize}
  \item Market Clearing Jacobians with Respect to Prices:
    First consider Jacobians with respect to prices $p_{k,v}$ for
    $k=1,\ldots,n_p$ and times $v=0,\ldots,T-1$ which, in general, imply
    a decomposition as follows:
    \begin{align*}
      \frac{\partial H_{it}(U,Z)}{\partial U_{j,s}}
      =
      \frac{\partial H_{it}(U,Z)}{\partial p_{k,v}}
      \frac{\partial p_{k,v}}{\partial U_{j,s}}
    \end{align*}
    To compute the market clearing Jacobians with respect to prices
    $\frac{\partial H_{it}(U,Z)}{\partial p_{k,v}}$,
    it is then useful to define corresponding aggregate variable Jacobians
    with respect to prices $\frac{\partial U_{i,t}}{\partial p_{k,s}}$
    since those enter into the expression via the chain rule.

  \item Aggregate Jacobians with Respect to Prices:
    Define
    \begin{align*}
      \underbrace{%
        \calJ^{U_i,\,p_k}
      }_{%
        (T\times T)
      }
      \qquad\text{where}\quad
      \calJ^{U_i,\,p_k}_{t,s}
      =
      \frac{\partial U_{i,t}}{\partial p_{k,s}}
    \end{align*}
    These Jacobians are sufficient statistics for the heterogeneous
    household side of the equilibrium response to prices.
    The specifics of the underlying heterogeneous household optimization
    problem(s) that gives rise to a particular value of
    $\calJ^{U_i,\,p_k}$
    are irrelevant to aggregate dynamics once we know
    that value of $\calJ^{U_i,\,p_k}$.
    Column $s$ of $\calJ^{U_i,\,p_k}$ gives the impulse response to news
    shock $dp_{k,s}$ for $s=0,\ldots,T-1$.
\end{itemize}
\paragraph{%
  Algorithm for Computing Aggregate Jacobians w.r.t. Prices
}
Definitions:
\begin{itemize}
  \item Let $\{X_s\}$ be any sequence of inputs into the household
    problem.
  \item Let $\{Y_s\}$ be any sequence of aggregates that result from
    household decisions.
  \item Let $\{D_s\}$ be the distribution of agents over idiosyncratic
    states.
\end{itemize}
We are interested in the Jacobian $\calJ^{Y,X}$.
To make progress, define the following.
\begin{enumerate}[label=(\roman*)]
  \item Bellman Equation for household problem:
    The household maximizes based on the next period value function
    $v_{t+1}$ and inputs $X_t$.
    Hence we can write the current period value as a function
    of next period value and inputs.
    \begin{align*}
      v_t = v(v_{t+1},X_t)
      \qquad
      t = 0,\ldots,T-1
    \end{align*}
  \item Law of Motion for Distribution of Agents over idiosyncratic
    states:
    The combination of household decisions/policies and the law of
    motion for idiosyncratic states imply a law of motion for the
    distribution of households:
    \begin{align*}
      D_{t+1} = \Lambda(v_{t+1},X_t)'D_t
      \qquad
      t = 0,\ldots,T-1
    \end{align*}
    where $(v_{t+1},X_t)$ imply policies.

  \item Aggregate Outcome:
    Given household choices (which result from $v_{t+1}$ and $X_t$) and
    the distribution, we can compute the aggregate quantity.
    \begin{align*}
      Y_t = y(v_{t+1},X_t)'D_t
      \qquad
      t = 0,\ldots,T-1
    \end{align*}
\end{enumerate}
Naive way to compute $\calJ^{Y,X}_{t,s}$ terms for each
$t$ and $s$ in $\{0,\ldots,T-1\}$:
\begin{enumerate}
  \item For each $s=0,\ldots,T-1$, perturb
\end{enumerate}


\clearpage
Suppose the exogenous aggregate $Z_t$ is driven by iid structural
innovations $\{\varepsilon_{t-s}^Z\}$
\begin{align*}
  dZ_t
  =
  \sum_{s=0}^\infty
  m_s^Z \varepsilon_{t-s}^Z
\end{align*}
where $m_s^Z$ is the response of $dZ_t$ to shock $s$ periods ago or,
equivalently, the response of $dZ_{t+s}$ to a shock at time $t$.

Naturally, these shocks will induce a response in $X_t$, so we can write
\begin{align*}
  dX_t
  =
  \sum_{s=0}^\infty
  m_s^{X,Z} \varepsilon_{t-s}^Z
\end{align*}
We would like to know the $m_s^{X,Z}$ terms.
To solve we will equate this to something we do know, and then identify
the $m_s^{X,Z}$ terms.

First, we can ask about the contribution of $\varepsilon_t^Z$ to $dX_t$.
When $\varepsilon_t$ hits, we know that it will contribute to
the sequence
\begin{align*}
  (dZ_t,dZ_{t+1},\ldots)
\end{align*}
the amount
\begin{align*}
  (m_0^Z\varepsilon_t,m_1^Z\varepsilon_t,\ldots)
\end{align*}
By the Jacobian result and certainty equivalence, this contributes to
$dX_t$ the following amount
\begin{align*}
  G_{0,0}^{X,Z}m_0^Z\varepsilon_t
  +
  G_{0,1}^{X,Z}m_1^Z\varepsilon_t
  +
  \cdots
\end{align*}
Next, consider $\varepsilon_{t-1}^Z$.
When it hits, we know that it will contribute to the sequence
\begin{align*}
  (dZ_{t-1},dZ_{t},\ldots)
\end{align*}
the amount
\begin{align*}
  (m_0^Z\varepsilon_{t-1},m_1^Z\varepsilon_{t-1},\ldots)
\end{align*}
By the Jacobian result and certainty equivalence, this contributes to
$dX_t$ the following amount
\begin{align*}
  G_{1,0}^{X,Z}m_0^Z\varepsilon_{t-1}
  +
  G_{1,1}^{X,Z}m_1^Z\varepsilon_{t-1}
  +
  \cdots
\end{align*}
Continuing and adding up
\begin{align*}
  m_s^{X,Z}
  =
  \begin{pmatrix}
    G_{s,1}^{X,Z}
    & \cdots &
    G_{s,T}^{X,Z}
  \end{pmatrix}
  \begin{pmatrix}
    m_0^Z \\ \vdots \\ m_T^Z
  \end{pmatrix}
\end{align*}











\clearpage
\section{Deaton -- Analysis of Household Surveys}


Suppose we want to estimate the finite sample population mean where $N$
is the total number of observations in the population.

Given a random draw of $n<N$ individuals from the population, we might
consider estimator
\begin{align*}
  \bar{x}
  =
  \frac{1}{n}
  \sumin
  x_i
  =
  \frac{1}{n}
  \sumiN
  a_i
  x_i
\end{align*}
In the middle expression, the $x_i$ are random draws from the population
distribution. In the final expression, the $x_i$ are fixed and the $a_i$
are random indicator variables for whether a given observation was
selected for the sample.

Perspectives
\begin{itemize}
  \item $n$ Individuals from Finite, Size-$N$ Population:
    There's some finite population of $N$ individuals that I can compute
    population statistics and quantities for, if I happened to have
    information on all individuals.

    The randomness then comes from sampling, i.e. I randomly selected
    $n<N$ individuals for my subsample.
    I can compute statistics for them, but they wouldn't equal the
    population values. I can compute standard errors by considering the
    finite-sample distribution of these statistics over repeated samples
    from the (finite) population.

    There is \emph{no} assumption that the observations were generated
    by a common probability law.

  \item Superpopulation perspective, Common Law:
    There's a law of nature that I hope to learn about.
    For example, imagine all individuals are scanned and processed,
    then they have their outcome generated according to some common
    probability law $F_0$.
    I can learn about that from independent draws from this probability
    law.

  \item Sub-Population from Full Population:
    There is some full population with all individuals in all cities.
    I randomly select cities to observe, and once I pick them, I observe
    all individuals with the chosen cities.

    The randomness comes from which cities I randomly picked to observe.
    In principle, I have no observations with which I can do inference
    about values in the cities not chosen, unless I appeal to a
    superpopulation.
    Alternatively, I can treat the cities as the draws or units of
    observation and I drew the cities randomly just as I drew $n$ from
    $N$ in the finite population case above.
\end{itemize}












%% APPPENDIX %%

% \appendix



\clearpage
\bibliographystyle{econ_abstracts}
\nocite{*}
\bibliography{~/Dropbox/ResearchPapers/PaperRepo/Papers.bib}




\end{document}











https://www.youtube.com/watch?v=UrefKMSEuAI&list=PLE125425EC837021F
https://www.youtube.com/user/mathematicalmonk/featured

https://www.youtube.com/watch?v=4RZiWZXdbTw&list=PL1M5TsfDV6Vufqfs_h5fDR3pBhIj4QOW7&index=2
https://www.youtube.com/watch?v=S5TVIPknDI4&list=PL1M5TsfDV6Vui-q_q1Bq5kF2Y77udGwWx
https://www.youtube.com/watch?v=ROLeLaR-17U&list=PL1M5TsfDV6Vu-GcB4Eb1P1KQ3wVxMI9Mn
https://www.youtube.com/watch?v=4xF_DMbL14w&list=PL1M5TsfDV6VsE11CCeMuBL0owBpwp4xru
https://www.youtube.com/watch?v=TfKwgGT2fSM&list=PL1M5TsfDV6Vs9biqgcsAG-ZQAqqkXaOqA
https://www.youtube.com/watch?v=nlsR4lxYBRo&list=PL1M5TsfDV6Vs53iHrxybY3rUa0MU1qAOy
https://www.youtube.com/watch?v=Kv2qe2nBATI&list=PL1M5TsfDV6VsiMw3IAsfyaZBmZfpSj7Bf
https://www.youtube.com/watch?v=Zxyj8HU2Kmg
https://www.youtube.com/watch?v=Pz4ephK-f94
https://www.youtube.com/results?search_query=spline
https://www.youtube.com/watch?v=3jQs02dbfrI&list=PL06ytJZ4Ak1rXmlvxTyAdOEfiVEzH00IK

https://www.youtube.com/watch?v=UOMvUaYfpH4
https://www.youtube.com/watch?v=_PwhiWxHK8o
https://www.youtube.com/watch?v=HTVDo0Bd36Y
https://www.youtube.com/watch?v=y1JuX5IsIuE
https://www.youtube.com/watch?v=1Eg6TvOx2OY
https://www.youtube.com/watch?v=P_og8H-VkIY&list=PLwJRxp3blEvZ8AKMXOy0fc0cqT61GsKCG
https://www.youtube.com/watch?v=WV_jcaDBZ2I&list=PLwJRxp3blEvaOTZfSKXysxRmi6gXJf5gP
https://www.youtube.com/watch?v=GMVh02WGhoc&list=PLwJRxp3blEvaxmHgI2iOzNP6KGLSyd4dz
https://www.youtube.com/watch?v=Za1YxRJL-SA&list=PLwJRxp3blEvZBAn3bwAAtdJqotRPBWBlP
https://www.youtube.com/watch?v=WK03XgoVsPM&list=PLD15D38DC7AA3B737
https://www.youtube.com/watch?v=zvrcyqcN9Wo
https://www.youtube.com/watch?v=JHvmBb6YKDw




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%% SAMPLE CODE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    %% VIEW LAYOUT %%

        \layout

    %% LANDSCAPE PAGE %%

        \begin{landscape}
        \end{landscape}

    %% BIBLIOGRAPHIES %%

        \cite{LabelInSourcesFile}  %Use in text; cites
        \citep{LabelInSourcesFile} %Use in text; cites in parens

        \nocite{LabelInSourceFile} % Includes in refs w/o specific citation
        \bibliographystyle{apalike}  % Or some other style

        % To ditch the ``References'' header
        \begingroup
        \renewcommand{\section}[2]{}
        \endgroup

        \bibliography{sources} % where sources.bib has all the citation info

    %% SPACING %%

        \vspace{1in}
        \hspace{1in}

    %% URLS, EMAIL, AND LOCAL FILES %%

      \url{url}
      \href{url}{name}
      \href{mailto:mcocci@raidenlovessusie.com}{name}
      \href{run:/path/to/file.pdf}{name}


    %% INCLUDING PDF PAGE %%

        \includepdf{file.pdf}


    %% INCLUDING CODE %%

        %\verbatiminput{file.ext}
            %   Includes verbatim text from the file

        \texttt{text}
            %   Renders text in courier, or code-like, font

        \matlabcode{file.m}
            %   Includes Matlab code with colors and line numbers

        \lstset{style=bash}
        \begin{lstlisting}
        \end{lstlisting}
            % Inline code rendering


    %% INCLUDING FIGURES %%

        % Basic Figure with size scaling
            \begin{figure}[h!]
               \centering
               \includegraphics[scale=1]{file.pdf}
            \end{figure}

        % Basic Figure with specific height
            \begin{figure}[h!]
               \centering
               \includegraphics[height=5in, width=5in]{file.pdf}
            \end{figure}

        % Figure with cropping, where the order for trimming is  L, B, R, T
            \begin{figure}
               \centering
               \includegraphics[trim={1cm, 1cm, 1cm, 1cm}, clip]{file.pdf}
            \end{figure}

        % Side by Side figures: Use the tabular environment


