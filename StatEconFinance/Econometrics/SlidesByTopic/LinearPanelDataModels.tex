\documentclass[12pt]{article}

\author{}
\title{PS5}
\date{\today}

%% Formatting & Spacing %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry} % most detailed page formatting control
\usepackage{fullpage} % Simpler than using the geometry package; std effect
\usepackage{setspace}
%\onehalfspacing
\usepackage{microtype}

%% Formatting %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{version}
%\excludeversion{solutions}
\includeversion{solutions}
%\usepackage[margin=1in]{geometry}
    %   Adjust the margins with geometry package
%\usepackage{pdflscape}
    %   Allows landscape pages
%\usepackage{layout}
    %   Allows plotting of picture of formatting



%% Header %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{ECO-518 - Spring 2020}
\rhead{Problem Set 5}
\chead{%
  \begin{solutions}
  Solutions
  \end{solutions}
}
\setlength{\headheight}{15.2pt}
       %Make the header bigger to avoid overlap

%\fancyhf{}
       %Erase header settings

\renewcommand{\headrulewidth}{0.3pt}
       %Width of the line

\setlength{\headsep}{0.2in}
       %Distance from line to text


%% Mathematics Related %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{amsthm} %allows for labeling of theorems
%\numberwithin{equation}{section} % Number equations by section
\usepackage{bbm} % For bold numbers

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{ex}[thm]{Example}

\theoremstyle{remark}
\newtheorem*{rmk}{Remark}
\newtheorem*{note}{Note}

% Below supports left-right alignment in matrices so the negative
% signs don't look bad
\makeatletter
\renewcommand*\env@matrix[1][c]{\hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{*\c@MaxMatrixCols #1}}
\makeatother


%% Font Choices %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
%\usepackage{blindtext}
\usepackage{courier}


%% Figures %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{arrows.meta}
\usepackage{graphicx}
\usepackage{subfigure}
    %   For plotting multiple figures at once
\graphicspath{ {Figures/} }
    %   Set a directory for where to look for figures


%% Hyperlinks %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{hyperref}
\hypersetup{%
    colorlinks,
        %   This colors the links themselves, not boxes
    citecolor=black,
        %   Everything here and below changes link colors
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

%% Colors %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{color}
\definecolor{codegreen}{RGB}{28,172,0}
\definecolor{codelilas}{RGB}{170,55,241}

% David4 color scheme
\definecolor{d4blue}{RGB}{100,191,255}
\definecolor{d4gray}{RGB}{175,175,175}
\definecolor{d4black}{RGB}{85,85,85}
\definecolor{d4orange}{RGB}{255,150,100}

%% Including Code %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{verbatim}
    %   For including verbatim code from files, no colors
\usepackage{listings}
    %   For including code snippets written directly in this doc

\lstdefinestyle{bash}{%
  language=bash,%
  basicstyle=\footnotesize\ttfamily,%
  showstringspaces=false,%
  commentstyle=\color{gray},%
  keywordstyle=\color{blue},%
  xleftmargin=0.25in,%
  xrightmargin=0.25in
}
\lstdefinestyle{log}{%
  basicstyle=\scriptsize\ttfamily,%
  showstringspaces=false,%
  xleftmargin=0.25in,%
  xrightmargin=0.25in
}


\lstdefinestyle{matlab}{%
  language=Matlab,%
  basicstyle=\footnotesize\ttfamily,%
  breaklines=true,%
  morekeywords={matlab2tikz},%
  keywordstyle=\color{blue},%
  morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},%
  identifierstyle=\color{black},%
  stringstyle=\color{codelilas},%
  commentstyle=\color{codegreen},%
  showstringspaces=false,%
    %   Without this there will be a symbol in
    %   the places where there is a space
  %numbers=left,%
  %numberstyle={\tiny \color{black}},%
    %   Size of the numbers
  numbersep=9pt,%
    %   Defines how far the numbers are from the text
  emph=[1]{for,end,break,switch,case},emphstyle=[1]\color{blue},%
    %   Some words to emphasise
}

\newcommand{\matlabcode}[1]{%
    \lstset{style=matlab}%
    \lstinputlisting{#1}
}
    %   For including Matlab code from .m file with colors,
    %   line numbering, etc.

\lstdefinelanguage{Julia}%
  {morekeywords={abstract,break,case,catch,const,continue,do,else,elseif,%
      end,export,false,for,function,immutable,import,importall,if,in,%
      macro,module,otherwise,quote,return,switch,true,try,type,typealias,%
      using,while},%
   sensitive=true,%
   %alsoother={$},%
   morecomment=[l]\#,%
   morecomment=[n]{\#=}{=\#},%
   morestring=[s]{"}{"},%
   morestring=[m]{'}{'},%
}[keywords,comments,strings]

\lstdefinestyle{julia}{%
    language         = Julia,
    basicstyle       = \scriptsize\ttfamily,
    keywordstyle     = \bfseries\color{blue},
    stringstyle      = \color{codegreen},
    commentstyle     = \color{codegreen},
    showstringspaces = false,
    literate         = %
      {ρ}{{$\rho$}}1
      {ℓ}{{$\ell$}}1
      {∑}{{$\Sigma$}}1
      {Σ}{{$\Sigma$}}1
      {√}{{$\sqrt{}$}}1
      {θ}{{$\theta$}}1
      {ω}{{$\omega$}}1
      {ɛ}{{$\varepsilon$}}1
      {φ}{{$\varphi$}}1
      {σ²}{{$\sigma^2$}}1
      {Φ}{{$\Phi$}}1
      {ϕ}{{$\phi$}}1
      {Dₑ}{{$D_e$}}1
      {Σ}{{$\Sigma$}}1
      {γ}{{$\gamma$}}1
      {δ}{{$\delta$}}1
      {τ}{{$\tau$}}1
      {μ}{{$\mu$}}1
      {β}{{$\beta$}}1
      {Λ}{{$\Lambda$}}1
      {λ}{{$\lambda$}}1
      {r̃}{{$\tilde{\text{r}}$}}1
      {α}{{$\alpha$}}1
      {σ}{{$\sigma$}}1
      {π}{{$\pi$}}1
      {∈}{{$\in$}}1
      {∞}{{$\infty$}}1
}


%% Bibliographies %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage{natbib}
    %---For bibliographies
%\setlength{\bibsep}{3pt} % Set how far apart bibentries are

%% Misc %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{enumitem}
    %   Has to do with enumeration
\usepackage{appendix}
%\usepackage{natbib}
    %   For bibliographies
\usepackage{pdfpages}
    %   For including whole pdf pages as a page in doc
\usepackage{pgffor}
    %   For easier looping


%% User Defined %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newcommand{\nameofcmd}{Text to display}
\newcommand*{\Chi}{\mbox{\large$\chi$}} %big chi
    %   Bigger Chi

% In math mode, Use this instead of \munderbar, since that changes the
% font from math to regular
\makeatletter
\def\munderbar#1{\underline{\sbox\tw@{$#1$}\dp\tw@\z@\box\tw@}}
\makeatother

% Misc Math
\newcommand{\ra}{\rightarrow}
\newcommand{\diag}{\text{diag}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\ch}{\text{ch}}
\newcommand{\dom}{\text{dom}}
\newcommand{\one}[1]{\mathbf{1}_{#1}}


% Command to generate new math commands:
% - Suppose you want to refer to \boldsymbol{x} as just \bsx, where 'x'
%   is any letter. This commands lets you generate \bsa, \bsb, etc.
%   without copy pasting \newcommand{\bsa}{\boldsymbol{a}} for each
%   letter individually. Instead, just include
%
%     \generate{bs}{\boldsymbol}{a,...,z}
%
% - Uses pgffor package to loop
% - Example with optional argument. Will generate \bshatx to represent
%   \boldsymbol{\hat{x}} for all letters x
%
%     \generate[\hat]{bshat}{\boldsymbol}{a,...,z}

\newcommand{\generate}[4][]{%
  % Takes 3 arguments (maybe four):
  % - 1   wrapcmd (optional, defaults to nothing)
  % - 2   newname
  % - 3   mathmacro
  % - 4   Names to loop over
  %
  % Will produce
  %
  %   \newcommand{\newnameX}{mathmacro{wrapcmd{X}}}
  %
  % for each X in argument 4

  \foreach \x in {#4}{%
    \expandafter\xdef\csname%
      #2\x%
    \endcsname%
    {\noexpand\ensuremath{\noexpand#3{\noexpand#1{\x}}}}
  }
}


% MATHSCR: Gen \sX to stand for \mathscr{X} for all upper case letters
\generate{s}{\mathscr}{A,...,Z}


% BOLDSYMBOL: Generate \bsX to stand for \boldsymbol{X}, all upper and
% lower case.
%
% Letters and greek letters
\generate{bs}{\boldsymbol}{a,...,z}
\generate{bs}{\boldsymbol}{A,...,Z}
\newcommand{\bstheta}{\boldsymbol{\theta}}
\newcommand{\bsmu}{\boldsymbol{\mu}}
\newcommand{\bsSigma}{\boldsymbol{\Sigma}}
\newcommand{\bsvarepsilon}{\boldsymbol{\varepsilon}}
\newcommand{\bsalpha}{\boldsymbol{\alpha}}
\newcommand{\bsbeta}{\boldsymbol{\beta}}
\newcommand{\bsOmega}{\boldsymbol{\Omega}}
\newcommand{\bshatOmega}{\boldsymbol{\hat{\Omega}}}
\newcommand{\bshatG}{\boldsymbol{\hat{G}}}
\newcommand{\bsgamma}{\boldsymbol{\gamma}}
\newcommand{\bslambda}{\boldsymbol{\lambda}}

% Special cases like \bshatb for \boldsymbol{\hat{b}}
\generate[\hat]{bshat}{\boldsymbol}{b,y,x,X,V,S,W}
\newcommand{\bshatbeta}{\boldsymbol{\hat{\beta}}}
\newcommand{\bshatmu}{\boldsymbol{\hat{\mu}}}
\newcommand{\bshattheta}{\boldsymbol{\hat{\theta}}}
\newcommand{\bshatSigma}{\boldsymbol{\hat{\Sigma}}}
\newcommand{\bstildebeta}{\boldsymbol{\tilde{\beta}}}
\newcommand{\bstildetheta}{\boldsymbol{\tilde{\theta}}}
\newcommand{\bsbarbeta}{\boldsymbol{\overline{\beta}}}
\newcommand{\bsbarg}{\boldsymbol{\overline{g}}}

% Redefine \bso to be the zero vector
\renewcommand{\bso}{\boldsymbol{0}}

% Transposes of all the boldsymbol shit
\newcommand{\bsbp}{\boldsymbol{b'}}
\newcommand{\bshatbp}{\boldsymbol{\hat{b'}}}
\newcommand{\bsdp}{\boldsymbol{d'}}
\newcommand{\bsgp}{\boldsymbol{g'}}
\newcommand{\bsGp}{\boldsymbol{G'}}
\newcommand{\bshp}{\boldsymbol{h'}}
\newcommand{\bsSp}{\boldsymbol{S'}}
\newcommand{\bsup}{\boldsymbol{u'}}
\newcommand{\bsxp}{\boldsymbol{x'}}
\newcommand{\bsyp}{\boldsymbol{y'}}
\newcommand{\bsthetap}{\boldsymbol{\theta'}}
\newcommand{\bsmup}{\boldsymbol{\mu'}}
\newcommand{\bsSigmap}{\boldsymbol{\Sigma'}}
\newcommand{\bshatmup}{\boldsymbol{\hat{\mu'}}}
\newcommand{\bshatSigmap}{\boldsymbol{\hat{\Sigma'}}}

% MATHCAL: Gen \calX to stand for \mathcal{X}, all upper case
\generate{cal}{\mathcal}{A,...,Z}

% MATHBB: Gen \X to stand for \mathbb{X} for some upper case
\generate{}{\mathbb}{R,Q,C,Z,N,Z,E}
\newcommand{\Rn}{\mathbb{R}^n}
\newcommand{\RN}{\mathbb{R}^N}
\newcommand{\Rk}{\mathbb{R}^k}
\newcommand{\RK}{\mathbb{R}^K}
\newcommand{\RL}{\mathbb{R}^L}
\newcommand{\Rl}{\mathbb{R}^\ell}
\newcommand{\Rm}{\mathbb{R}^m}
\newcommand{\Rnn}{\mathbb{R}^{n\times n}}
\newcommand{\Rmn}{\mathbb{R}^{m\times n}}
\newcommand{\Rnm}{\mathbb{R}^{n\times m}}
\newcommand{\Rkn}{\mathbb{R}^{k\times n}}
\newcommand{\Cn}{\mathbb{C}^n}
\newcommand{\Cnn}{\mathbb{C}^{n\times n}}

% Dot over
\newcommand{\dx}{\dot{x}}
\newcommand{\ddx}{\ddot{x}}
\newcommand{\dy}{\dot{y}}
\newcommand{\ddy}{\ddot{y}}

% First derivatives
\newcommand{\dydx}{\frac{dy}{dx}}
\newcommand{\dfdx}{\frac{df}{dx}}
\newcommand{\dfdy}{\frac{df}{dy}}
\newcommand{\dfdz}{\frac{df}{dz}}

% Second derivatives
\newcommand{\ddyddx}{\frac{d^2y}{dx^2}}
\newcommand{\ddydxdy}{\frac{d^2y}{dx dy}}
\newcommand{\ddydydx}{\frac{d^2y}{dy dx}}
\newcommand{\ddfddx}{\frac{d^2f}{dx^2}}
\newcommand{\ddfddy}{\frac{d^2f}{dy^2}}
\newcommand{\ddfddz}{\frac{d^2f}{dz^2}}
\newcommand{\ddfdxdy}{\frac{d^2f}{dx dy}}
\newcommand{\ddfdydx}{\frac{d^2f}{dy dx}}


% First Partial Derivatives
\newcommand{\pypx}{\frac{\partial y}{\partial x}}
\newcommand{\pfpx}{\frac{\partial f}{\partial x}}
\newcommand{\pfpy}{\frac{\partial f}{\partial y}}
\newcommand{\pfpz}{\frac{\partial f}{\partial z}}


% argmin and argmax
\DeclareMathOperator*{\argmin}{arg\;min}
\DeclareMathOperator*{\argmax}{arg\;max}


% Various probability and statistics commands
\newcommand{\iid}{\overset{iid}{\sim}}
\newcommand{\vc}{\operatorname{vec}}
\newcommand{\Cov}{\operatorname{Cov}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\trace}{\operatorname{trace}}
\newcommand{\Corr}{\operatorname{Corr}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\asto}{\xrightarrow{a.s.}}
\newcommand{\pto}{\xrightarrow{p}}
\newcommand{\msto}{\xrightarrow{m.s.}}
\newcommand{\dto}{\xrightarrow{d}}
\newcommand{\Lpto}{\xrightarrow{L_p}}
\newcommand{\Lqto}[1]{\xrightarrow{L_{#1}}}
\newcommand{\plim}{\text{plim}_{n\rightarrow\infty}}


% Redefine real and imaginary from fraktur to plain text
\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}

% Shorter sums: ``Sum from X to Y''
% - sumXY  is equivalent to \sum^Y_{X=1}
% - sumXYz is equivalent to \sum^Y_{X=0}
\newcommand{\sumnN}{\sum^N_{n=1}}
\newcommand{\sumin}{\sum^n_{i=1}}
\newcommand{\sumjn}{\sum^n_{j=1}}
\newcommand{\sumim}{\sum^m_{i=1}}
\newcommand{\sumik}{\sum^k_{i=1}}
\newcommand{\sumiN}{\sum^N_{i=1}}
\newcommand{\sumkn}{\sum^n_{k=1}}
\newcommand{\sumtT}{\sum^T_{t=1}}
\newcommand{\sumninf}{\sum^\infty_{n=1}}
\newcommand{\sumtinf}{\sum^\infty_{t=1}}
\newcommand{\sumnNz}{\sum^N_{n=0}}
\newcommand{\suminz}{\sum^n_{i=0}}
\newcommand{\sumknz}{\sum^n_{k=0}}
\newcommand{\sumtTz}{\sum^T_{t=0}}
\newcommand{\sumninfz}{\sum^\infty_{n=0}}
\newcommand{\sumtinfz}{\sum^\infty_{t=0}}

\newcommand{\prodnN}{\prod^N_{n=1}}
\newcommand{\prodin}{\prod^n_{i=1}}
\newcommand{\prodiN}{\prod^N_{i=1}}
\newcommand{\prodkn}{\prod^n_{k=1}}
\newcommand{\prodtT}{\prod^T_{t=1}}
\newcommand{\prodnNz}{\prod^N_{n=0}}
\newcommand{\prodinz}{\prod^n_{i=0}}
\newcommand{\prodknz}{\prod^n_{k=0}}
\newcommand{\prodtTz}{\prod^T_{t=0}}

% Bounds
\newcommand{\atob}{_a^b}
\newcommand{\ztoinf}{_0^\infty}
\newcommand{\kinf}{_{k=1}^\infty}
\newcommand{\ninf}{_{n=1}^\infty}
\newcommand{\minf}{_{m=1}^\infty}
\newcommand{\tinf}{_{t=1}^\infty}
\newcommand{\nN}{_{n=1}^N}
\newcommand{\tT}{_{t=1}^T}
\newcommand{\kinfz}{_{k=0}^\infty}
\newcommand{\ninfz}{_{n=0}^\infty}
\newcommand{\minfz}{_{m=0}^\infty}
\newcommand{\tinfz}{_{t=0}^\infty}
\newcommand{\nNz}{_{n=0}^N}

% Limits
\newcommand{\limN}{\lim_{N\rightarrow\infty}}
\newcommand{\limn}{\lim_{n\rightarrow\infty}}
\newcommand{\limk}{\lim_{k\rightarrow\infty}}
\newcommand{\limt}{\lim_{t\rightarrow\infty}}
\newcommand{\limT}{\lim_{T\rightarrow\infty}}
\newcommand{\limhz}{\lim_{h\rightarrow 0}}

% Shorter integrals: ``Integral from X to Y''
% - intXY is equivalent to \int^Y_X
\newcommand{\intab}{\int_a^b}
\newcommand{\intzN}{\int_0^N}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BODY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}
%\maketitle


\paragraph{Linear Panel Data Model}
We observe $\{y_{it},x_{it}\}_{i=1,t=1}^{N,T}$.
We might then write down the following model:
\begin{align}
  y_{it}
  =
  x_{it}'\beta
  + \alpha_i
  + \varepsilon_{it}
  \qquad
  i = 1,\ldots,N
  \quad
  t = 1,\ldots,T
  \label{panelmodel}
\end{align}
What does this mean?
\begin{itemize}
  \item At first blush, this is a ``zero economic or causal content''
    representation because we always write outomes $y_{it}$ as
    determined according to the RHS for \emph{some} $\alpha_i$, $\beta$,
    $\varepsilon_{it}$.
    Recall that we can always define a regression coefficient as
    the linear projection, implying that we can always write
    $y=x\beta +u$ for some $\beta$ and a residual $u$ uncorrelated with
    $x$ (but not necessarily conditionally mean zero).
    This is exactly that.

    As before, only \emph{further}/\emph{stronger} assumptions on the
    DGP give these definitions causal or economic meaning.

  \item If we're willing to make the assumption that
    \begin{align}
      \E[\varepsilon_{it}|x_{it},\alpha_i]=0
      \quad\implies\quad
        \E[y_{it}|x_{it},\alpha_i] = x_{it}'\beta + \alpha_i
        \label{panelcausal}
    \end{align}
    this is a \emph{much} stronger statement in two senses.
    \begin{enumerate}[label=(\roman*)]
      \item First, it is a statement/restriction about the CEF (hence
        the DGP).
        As such, this implies a \emph{causal} interpretation of the
        objects $\beta$ and $\alpha_i$, because they characterize that
        CEF, allowing us to make statements about what happens to the
        mean of the outcome if we change $\alpha_i$ or elements of
        $x_{it}$, holding everything else fixed.

      \item Second, it is a restriction on the
        \emph{nature of the heterogeneity}.
        In particular, heterogeneity shows up only as
        differences in the \emph{level of outcomes} between units.
        The \emph{marginal effect} of any element of $x_{it}$ is
        \emph{identical} for all units.

        As a result, $\beta$ is typically the parameter of interest
        (although we could, in principle, be interested in other
        features of the model like the individual $\alpha_i$'s, the
        distribution of $\alpha_i$'s, the variance of
        $\varepsilon_{it}$, etc.).
    \end{enumerate}
\end{itemize}
Note that Expression~\ref{panelcausal} is a \emph{minimal}
condition for any of this panel data stuff to be a worthwhile and
interesting endeavor from an economic or causal inference point of view.
But we will need \emph{supplemental} assumptions in order to
consistently \emph{estimate} $\beta$.
Said another way, Expression~\ref{panelcausal} might actually be
true, in which case (i) and (ii) still apply.
But we will need to place \emph{even more} assumptions on the
DGP to estimate and use this model in practice.
We will see this in action many times.

For example, note that if we observed $\alpha_i$,
Assumption~\ref{panelcausal} implies that we could immediately and
consistently estimate $\beta$ by regressing $y_{it}-\alpha_i$ on
$x_{it}$.
But we don't.
So how are we going to get around that?

Finally, note that Expression~\ref{panelcausal} is a minimimal condition
for economic and causal inference \emph{interpretation}.
But for identification and estimation, we will gnerally work with moment
conditions that like look like ``correlation equals zero'' rather than
the stronger ``conditional mean equals zero'' as in
Expression~\ref{panelcausal}.
This is directly analogous to how, in standard linear regression,
we need only ``residuals uncorrelated with regressors'' for
identification of the regression vector and consistent estimation.
But that is implied by the stronger statement that ``residuals
conditionally mean zero,'' which says that the CEF is linear in the
regressors and therefore lends a specifically causal/economic
interpretation (that we often have in mind anyway).


There will be two broad approaches to estimation of
Model~\ref{panelmodel}.
\begin{enumerate}
  \item Random Effects:
    On top of Expression~\ref{panelcausal}, assume
    \begin{enumerate}[label=(\alph*)]
      \item $\alpha_i\perp x_{it}$: Statement about the joint
        distribution of $\alpha_i$ and $x_{it}$ in the population.

      \item $\E[\alpha_i|x_{it}]=0$, a harmless normalization (after
        assuming (a)) if we include a constant in the model
    \end{enumerate}
    Implication:
    Can consistently estimate $\beta$ by simply regressing $y_{it}$ on
    $x_{it}$, treating $\alpha_i$ as part of the error term because,
    under Expression~\ref{panelcausal} and RE assumptions (a) and (b)
    \begin{align*}
      \E[\alpha_i + \varepsilon_{it}|x_{it}]
      =
      \E\big[\E[\alpha_i + \varepsilon_{it}|x_{it},\alpha_i]\, \big|\,x_{it}]\big]
      =
      \E\big[\alpha_i + 0\,\big|\,x_{it}\big]
      =
      0
    \end{align*}
    The only complication induced by the above model/assumptions is
    that there is now a time-invariant, unit-specific component in
    the error term of the regression.
    This induces correlation in regression errors (hence outcomes)
    across $t$ within $i$ that we must account for, since that we
    don't have as many independent observations as we think.


    Applicability:
    This is more common in the statistics literature, moreso than in the
    econometric literature because endogeneity/selection in a model with
    time-invariant, unit-specific effects (and no marginal heterogeneity
    in marginal effects) would manifest precisely as correlation between
    $\alpha_i$ and $x_{it}$, which induces OVB if we simply regress
    $y_{it}$ on $x_{it}$.

    Example: In the schooling example, ``High ability individuals are
    not more likely to have higher school.''


  \item Fixed Effects:
    \emph{Do not} rule out correlation between $\alpha_i$ and $x_{it}$;
    let $\alpha_i$ and $x_{it}$ to be \emph{arbitrarily correlated}.
    Then it would be inappropriate to regress $y_{it}$ on $x_{it}$,
    treating $\alpha_i$ as part of the error term as in the random
    effect approach, as this would induce OVB in the coefficient on
    $x_{it}$.
    And because we cannot observe $\alpha_i$, there's no sense in which
    we can ``include'' that as a RHS variable in some regression.

    Example: Schooling (a RHS variable) will generally be correlated
    with unobserved ability ($\alpha_i$) that almost certainly has an
    impact on wages ($y_{it}$).

    Therefore, the approach most taken here is to
    \emph{transform the data} so as to eliminate $\alpha_i$.
    In other words, if Model~\ref{panelmodel} is true, what are some
    transformations of the data that can be used to identify and
    estimate $\beta$?
    This means coming up with a useful transformation of the data and
    appropriate assumptions on the errors (e.g. strengthening
    Expression~\ref{panelcausal}), which can be used to generate
    enough moment conditions to identify the parameters.
\end{enumerate}
To finish up the introduction and notation, note that sometimes we want
$x_{it}$ to include lags of the dependent variable $y_{it}$.
If so, this is called a \emph{dynamic} linear panel data model, which I
will write in more explicit form as
\begin{align*}
  y_{it}
  =
  \rho y_{i,t-1}
  + \beta x_{it}
  + \gamma x_{i,t-1}
  + \alpha_i
  + \varepsilon_{it}
  \qquad
  i = 1,\ldots,N
  \quad
  t = 2,\ldots,T
\end{align*}
where $t$ starts at $t=2$ because we lose one observation
for including one lag on the RHS.


\paragraph{FE Approach, Non-Dynamic Panel Data}
Start with the \emph{non-dynamic} linear panel data model,
Expression~\ref{panelmodel}.
Since we want to allow for arbitrary correlation between $x_{it}$ and
$\alpha_i$, we seek an approach which transforms the data to eliminate
$\alpha_i$ altogether and estimates $\beta$ using the transformed data.

Two common transformations, and the associated implications for the
transformed data under the assumption of Expression~\ref{panelmodel}:
\begin{enumerate}
  \item
    Under Expression~\ref{panelmodel}, if we demean, we obtain the
    following model/relationship for the demeaned data
    \begin{align*}
      y_{it} - \overline{y}_i
      =
      (x_{it}-\overline{x}_i)'\beta
      + (\varepsilon_{it}-\overline{\varepsilon}_i)
      \qquad
      i = 1,\ldots,N
      \quad
      t = 1,\ldots,T
    \end{align*}
    Thus from a restriction on the DGP for $y_{it}$ (namely that all
    endogeneity is captured by a time-invariant, unit-specific effect
    $\alpha_i$) which is characterized by some $\beta$, we have deduced
    a restriction on $y_{it}-\overline{y}_i$ that also includes that
    very same $\beta$.

    The transformed (demeaned) data can be used to consistently estimate
    $\beta$ via linear regression of
    $y_{it}-\overline{y}_i$ on
    $x_{it}-\overline{x}_i$
    if
    \begin{align}
      \E[(x_{it}-\overline{x}_i)(\varepsilon_{it}-\overline{\varepsilon}_i)]=0
      \label{consistencycond_demean}
    \end{align}
    This last expression specifies moment conditions associated with a
    valid method of moments estimator that consistently estimates
    $\beta$.

  \item
    Under Expression~\ref{panelmodel}, if we difference, we obtain the
    following model/relationship for the differenced data
    \begin{align*}
      y_{it}-y_{i,t-1}
      =
      (x_{it}-x_{i,t-1})'\beta
      + (\varepsilon_{it}-\varepsilon_{i,t-1})
      \qquad
      i = 1,\ldots,N
      \quad
      t = 2,\ldots,T
    \end{align*}
    where we lose an observation to first-differencing, hence $t$
    starting at $t=2$.

    Again, the transformed (differenced) data can be used to consistly
    estimate $\beta$ via linear regression of
    $y_{it}-{y}_{i,t-1}$ on
    $x_{it}-{x}_{i,t-1}$
    if
    \begin{align}
      \E[(x_{it}-{x}_{i,t-1})(\varepsilon_{it}-{\varepsilon}_{i,t-1})]=0
      \label{consistencycond_diff}
    \end{align}
    This last expression specifies moment conditions associated with a
    valid method of moments estimator that consistently estimates
    $\beta$.
\end{enumerate}
For each, we might assume straight away that either
Expression~\ref{consistencycond_demean} or \ref{consistencycond_diff}
holds, either of which we saw was enough to consistently estimate
$\beta$.
But that's a bit artificial and tough to motivate.
Therefore, we often instead assume the more natural
\emph{strict exogeneity} condition
\begin{align}
  \forall t,s
  \quad
  \E[\varepsilon_{is}|x_{i1},\ldots,x_{iT}]
  &= 0
  \quad\implies\quad
  \begin{cases}
    \E[\varepsilon_{is}|x_{is}]=0
    \\
    \E[(x_{it}-\overline{x}_i)(\varepsilon_{it}-\overline{\varepsilon}_i)]=0
    \\
    \E[(x_{it}-{x}_{i,t-1})(\varepsilon_{it}-{\varepsilon}_{i,t-1})]=0
  \end{cases}
  \label{strictexogeneity}
\end{align}
which implies both Expression~\ref{consistencycond_demean} and
\ref{consistencycond_diff}.
It's tough conceptually to think of settings where strict exogeneity
fails but Either~\ref{consistencycond_demean} or
\ref{consistencycond_diff} holds.

It's easy to see that this strict exogeneity condition cannot hold
if $x_{it}$ includes lags of $y_{it}$, because $\varepsilon_{is}$ helped
\emph{determine} $y_{is}$ which will be in some $x_{it}$.
Said another way, ``strict exogeneity'' as stated in
Expression~\ref{strictexogeneity} does not provide valid moment
conditions for consistent estimation for $\beta$ when working with
dynamic linear panel data models.
We should look for alternative moment conditions that can be used to
consistently estimate $\beta$.


\paragraph{Dynamic Linear Panel Data Models}
When the RHS includes lags of the dependent variable, we have a dynamic
linear panel data model, written
\begin{align}
  y_{it}
  =
  \rho y_{i,t-1}
  + \beta x_{it}
  + \gamma x_{i,t-1}
  + \alpha_i
  + \varepsilon_{it}
  \qquad
  i = 1,\ldots,N
  \quad
  t = 2,\ldots,T
  \label{dynamic}
\end{align}
Our parameter of interest is $\beta$.
There is still an unobserved, time-invariant effect $\alpha_i$ that we
think of as arbitrarily correlated with the other RHS variables,
including $x_{it}$.
Therefore, as before, we look for a transformation of the data that
eliminates $\alpha_i$ altogether and estimates $\beta$ using the
transformed data.

Most natural is to eliminate $\alpha_i$ by differencing.
Under Model~\ref{dynamic} for outcomes, we can deduce the following
relationship:
\begin{align}
  \Delta y_{it}
  =
  \rho \Delta y_{i,t-1}
  + \beta \Delta x_{it}
  + \gamma \Delta x_{i,t-1}
  + \Delta \varepsilon_{it}
  \qquad
  i = 1,\ldots,N
  \quad
  t = 3,\ldots,T
  \label{dynamic_diffed}
\end{align}
where $t$ starts at $t=3$ because we lost another observation due to the
differencing.
This gives us a transformation independent of $\alpha_i$.

Because $\varepsilon_{it}$ helps determine $y_{it}$ according to
Equation~\ref{dynamic}, we see that $\Delta
\varepsilon_{it}=\varepsilon_{it}-\varepsilon_{i,t-1}$ is
correlated with RHS variable $\Delta y_{i,t-1}=y_{i,t-1}-y_{i,t-2}$.
Thus, the strict exogeneity assumption (previously employed in the
\emph{non-dynamic} linear panel data model case)
\emph{cannot} hold, by construction.
It's surely violated, implying that we cannot consistently estimate
$\rho$. The estimate would certaintly be contaminated by OVB.
And even though we're interested in $\beta$, inconsistent estimation of
$\rho$ will spill over and induce inconsistent estimation of
$\beta$.\footnote{%
  Because this is a linear model, we might have hoped that that
  inconsistent estimation of $\rho$ would ``average out'' or fail to
  effect estimation of $\beta$.
  But that would only be true if $\Delta y_{i,t-1}$ and
  $\Delta x_{i,t-1}$ were proper
  control variables for the coefficient on $\Delta x_{it}$, i.e.
  if $\E[\Delta \varepsilon_{it}|\Delta x_{it}, \Delta x_{i,t-1}, \Delta y_{i,t-1}]
  =\E[\Delta \varepsilon_{it}| \Delta x_{i,t-1},\Delta y_{i,t-1}]$
  But this seems tough to reason about directly.
  So better to take the standard approach and think of the relationship
  between the level of the errors $\varepsilon_{it}$ and the level of
  the RHS variables, then deduce implications for the changes.
}
Therefore, we need to figure out how to use the transformed data and the
original to construct moment conditions that permit consistent
estimation of $\beta$.

We therefore instead take an GMM/IV approach to estimation.
First, rearrange
\begin{align}
  \Delta \varepsilon_{it}
  =
  \Delta y_{it}
  - \rho \Delta y_{i,t-1}
  - \beta \Delta x_{it}
  - \gamma \Delta x_{i,t-1}
  \qquad
  i = 1,\ldots,N
  \quad
  t = 3,\ldots,T
  \label{dynamic_diffed_re}
\end{align}
There are two different sets of assumptions on the errors that we might
(neither of which is ex ante preferred to the other).
\begin{enumerate}
  \item First, we might assume that
    \begin{align*}
      \E[\varepsilon_{it}x_{is}] = 0
      \qquad t=2,\ldots,T
      \quad   s=1,\ldots,T
    \end{align*}
    So rather than \emph{all} RHS variables (including the lagged
    dependent variable) being strictly exogenous, only the $x$'s are.

    This delivers moment conditions
    \begin{align*}
      \E[\Delta \varepsilon_{it} \cdot x_{is}]
      = 0
      \qquad  t=3,\ldots,T
      \quad   s=1,\ldots,T
    \end{align*}
    for different $s$ and $t$ combinations where it's possible to
    construct the above moment condition.

  \item
    Alternatively, we might assume only that $x$ is predetermined
    \begin{align*}
      0 &= \E[\varepsilon_{it} x_{is}]
      \qquad t=2,\ldots,T
      \quad  s=1,\ldots,t
      \\
      0 &= \E[\varepsilon_{it} y_{is}]
      \qquad t=2,\ldots,T
      \quad  s=1,\ldots,t-1
    \end{align*}
    which allows $\varepsilon_{it}$ to be correlated with $x_{i,t+1}$
    onwards, and $\varepsilon_{it}$ to be correlated with $y_{it}$ (as
    we'd expect) and $y_{i,t+1}$ onwards (also as we'd expect given the
    dynamic nature of the dependent variables).

    This delivers moment conditions
    \begin{align*}
      \E[\Delta \varepsilon_{it} \cdot x_{is}]
      &= 0
      \qquad  t=3,\ldots,T
      \quad   s=1,\ldots,t-1
      \\
      \E[\Delta \varepsilon_{it} \cdot y_{is}]
      &= 0
      \qquad  t=3,\ldots,T
      \quad   s=1,\ldots,t-2
    \end{align*}
\end{enumerate}






\end{document}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%% SAMPLE CODE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    %% VIEW LAYOUT %%

        \layout

    %% LANDSCAPE PAGE %%

        \begin{landscape}
        \end{landscape}

    %% BIBLIOGRAPHIES %%

        \cite{LabelInSourcesFile}  %Use in text; cites
        \citep{LabelInSourcesFile} %Use in text; cites in parens

        \nocite{LabelInSourceFile} % Includes in refs w/o specific citation
        \bibliographystyle{apalike}  % Or some other style

        % To ditch the ``References'' header
        \begingroup
        \renewcommand{\section}[2]{}
        \endgroup

        \bibliography{sources} % where sources.bib has all the citation info

    %% SPACING %%

        \vspace{1in}
        \hspace{1in}

    %% URLS, EMAIL, AND LOCAL FILES %%

      \url{url}
      \href{url}{name}
      \href{mailto:mcocci@raidenlovessusie.com}{name}
      \href{run:/path/to/file.pdf}{name}


    %% INCLUDING PDF PAGE %%

        \includepdf{file.pdf}


    %% INCLUDING CODE %%

        %\verbatiminput{file.ext}
            %   Includes verbatim text from the file

        \texttt{text}
            %   Renders text in courier, or code-like, font

        \matlabcode{file.m}
            %   Includes Matlab code with colors and line numbers

        \lstset{style=bash}
        \begin{lstlisting}
        \end{lstlisting}
            % Inline code rendering


    %% INCLUDING FIGURES %%

        % Basic Figure with size scaling
            \begin{figure}[h!]
               \centering
               \includegraphics[scale=1]{file.pdf}
            \end{figure}

        % Basic Figure with specific height
            \begin{figure}[h!]
               \centering
               \includegraphics[height=5in, width=5in]{file.pdf}
            \end{figure}

        % Figure with cropping, where the order for trimming is  L, B, R, T
            \begin{figure}
               \centering
               \includegraphics[trim={1cm, 1cm, 1cm, 1cm}, clip]{file.pdf}
            \end{figure}

        % Side by Side figures: Use the tabular environment


