%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Metropolis %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\documentclass{beamer}
%\usepackage{cmbright}
%\usetheme{metropolis}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Metropolis with Sidebar %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[aspectratio=169, handout]{beamer}
%\documentclass{beamer}
\usepackage{cmbright}
\usepackage{comment}

\useoutertheme[right, width=0.20\paperwidth]{sidebar}
\usecolortheme{metropolis}
\useinnertheme[sectionpage=none]{metropolis}
\usefonttheme{metropolis}

\makeatletter
\beamer@headheight=1.75\baselineskip     %controls the height of the headline, default is 2.5
\makeatother

\usepackage{etoolbox}
\patchcmd\insertverticalnavigation{\dohead}{\vskip-35pt\dohead}{}{}

%\setbeamertemplate{sidebar canvas right}{}
%\setbeamertemplate{sidebar right}{BOB}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Simple Template %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\documentclass{beamer}
%\usetheme{Boadilla}
%\usepackage{lmodern}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Sidebar Template %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\documentclass[serif]{beamer}  % For serif latex font
%\usepackage{pxfonts}
%\usepackage{eulervm}
%\usepackage{mathpazo}

%\usetheme{Goettingen}
%\usecolortheme{lily}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Common Settings %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title[]{ECO-518: Precept 5 \\ Matt Cocci}
\author[]{}
\date{\today}

\setbeamertemplate{section in toc}[sections numbered]
\setbeamertemplate{subsection in toc}[subsections numbered]
%\setbeamertemplate{section in toc}[square unnumbered]
%\setbeamertemplate{subsection in toc}[square unnumbered]

%% Mathematics Related %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{amsthm} %allows for labeling of theorems
%\numberwithin{equation}{section} % Number equations by section
\usepackage{bbm} % For bold numbers

%% Figures %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{arrows.meta}
\usepackage{pgfplots}
\usepgfplotslibrary{dateplot}
\usepackage{graphicx}
\usepackage{subfigure}
    %   For plotting multiple figures at once
%\graphicspath{ {Directory/} }
    %   Set a directory for where to look for figures

%% Misc %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% For easier looping
\usepackage{pgffor}

\usepackage{pdfpages}

%% User Defined %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newcommand{\nameofcmd}{Text to display}
\newcommand*{\Chi}{\mbox{\large$\chi$}} %big chi
    %   Bigger Chi

% In math mode, Use this instead of \munderbar, since that changes the
% font from math to regular
\makeatletter
\def\munderbar#1{\underline{\sbox\tw@{$#1$}\dp\tw@\z@\box\tw@}}
\makeatother

% Misc Math
\newcommand{\ra}{\rightarrow}
\newcommand{\diag}{\text{diag}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\ch}{\text{ch}}
\newcommand{\dom}{\text{dom}}
\newcommand{\one}[1]{\mathbf{1}_{#1}}


% Command to generate new math commands:
% - Suppose you want to refer to \boldsymbol{x} as just \bsx, where 'x'
%   is any letter. This commands lets you generate \bsa, \bsb, etc.
%   without copy pasting \newcommand{\bsa}{\boldsymbol{a}} for each
%   letter individually. Instead, just include
%
%     \generate{bs}{\boldsymbol}{a,...,z}
%
% - Uses pgffor package to loop
% - Example with optional argument. Will generate \bshatx to represent
%   \boldsymbol{\hat{x}} for all letters x
%
%     \generate[\hat]{bshat}{\boldsymbol}{a,...,z}

\newcommand{\generate}[4][]{%
  % Takes 3 arguments (maybe four):
  % - 1   wrapcmd (optional, defaults to nothing)
  % - 2   newname
  % - 3   mathmacro
  % - 4   Names to loop over
  %
  % Will produce
  %
  %   \newcommand{\newnameX}{mathmacro{wrapcmd{X}}}
  %
  % for each X in argument 4

  \foreach \x in {#4}{%
    \expandafter\xdef\csname%
      #2\x%
    \endcsname%
    {\noexpand\ensuremath{\noexpand#3{\noexpand#1{\x}}}}
  }
}


% MATHSCR: Gen \sX to stand for \mathscr{X} for all upper case letters
\generate{s}{\mathscr}{A,...,Z}


% BOLDSYMBOL: Generate \bsX to stand for \boldsymbol{X}, all upper and
% lower case.
%
% Letters and greek letters
\generate{bs}{\boldsymbol}{a,...,z}
\generate{bs}{\boldsymbol}{A,...,Z}
\newcommand{\bstheta}{\boldsymbol{\theta}}
\newcommand{\bsmu}{\boldsymbol{\mu}}
\newcommand{\bsSigma}{\boldsymbol{\Sigma}}
\newcommand{\bsvarepsilon}{\boldsymbol{\varepsilon}}
\newcommand{\bsalpha}{\boldsymbol{\alpha}}
\newcommand{\bsbeta}{\boldsymbol{\beta}}
\newcommand{\bsOmega}{\boldsymbol{\Omega}}
\newcommand{\bshatOmega}{\boldsymbol{\hat{\Omega}}}
\newcommand{\bshatG}{\boldsymbol{\hat{G}}}
\newcommand{\bsgamma}{\boldsymbol{\gamma}}
\newcommand{\bslambda}{\boldsymbol{\lambda}}

% Special cases like \bshatb for \boldsymbol{\hat{b}}
\generate[\hat]{bshat}{\boldsymbol}{b,y,x,X,V,S,W}
\newcommand{\bshatbeta}{\boldsymbol{\hat{\beta}}}
\newcommand{\bshatmu}{\boldsymbol{\hat{\mu}}}
\newcommand{\bshattheta}{\boldsymbol{\hat{\theta}}}
\newcommand{\bshatSigma}{\boldsymbol{\hat{\Sigma}}}
\newcommand{\bstildebeta}{\boldsymbol{\tilde{\beta}}}
\newcommand{\bstildetheta}{\boldsymbol{\tilde{\theta}}}
\newcommand{\bsbarbeta}{\boldsymbol{\overline{\beta}}}
\newcommand{\bsbarg}{\boldsymbol{\overline{g}}}

% Redefine \bso to be the zero vector
\renewcommand{\bso}{\boldsymbol{0}}

% Transposes of all the boldsymbol shit
\newcommand{\bsbp}{\boldsymbol{b'}}
\newcommand{\bshatbp}{\boldsymbol{\hat{b'}}}
\newcommand{\bsdp}{\boldsymbol{d'}}
\newcommand{\bsgp}{\boldsymbol{g'}}
\newcommand{\bsGp}{\boldsymbol{G'}}
\newcommand{\bshp}{\boldsymbol{h'}}
\newcommand{\bsSp}{\boldsymbol{S'}}
\newcommand{\bsup}{\boldsymbol{u'}}
\newcommand{\bsxp}{\boldsymbol{x'}}
\newcommand{\bsyp}{\boldsymbol{y'}}
\newcommand{\bsthetap}{\boldsymbol{\theta'}}
\newcommand{\bsmup}{\boldsymbol{\mu'}}
\newcommand{\bsSigmap}{\boldsymbol{\Sigma'}}
\newcommand{\bshatmup}{\boldsymbol{\hat{\mu'}}}
\newcommand{\bshatSigmap}{\boldsymbol{\hat{\Sigma'}}}

% MATHCAL: Gen \calX to stand for \mathcal{X}, all upper case
\generate{cal}{\mathcal}{A,...,Z}

% MATHBB: Gen \X to stand for \mathbb{X} for some upper case
\generate{}{\mathbb}{R,Q,C,Z,N,Z,E}
\newcommand{\Rn}{\mathbb{R}^n}
\newcommand{\RN}{\mathbb{R}^N}
\newcommand{\Rk}{\mathbb{R}^k}
\newcommand{\RK}{\mathbb{R}^K}
\newcommand{\RL}{\mathbb{R}^L}
\newcommand{\Rl}{\mathbb{R}^\ell}
\newcommand{\Rm}{\mathbb{R}^m}
\newcommand{\Rnn}{\mathbb{R}^{n\times n}}
\newcommand{\Rmn}{\mathbb{R}^{m\times n}}
\newcommand{\Rnm}{\mathbb{R}^{n\times m}}
\newcommand{\Rkn}{\mathbb{R}^{k\times n}}
\newcommand{\Rnk}{\mathbb{R}^{n\times k}}
\newcommand{\Rkk}{\mathbb{R}^{k\times k}}
\newcommand{\Cn}{\mathbb{C}^n}
\newcommand{\Cnn}{\mathbb{C}^{n\times n}}

% Dot over
\newcommand{\dx}{\dot{x}}
\newcommand{\ddx}{\ddot{x}}
\newcommand{\dy}{\dot{y}}
\newcommand{\ddy}{\ddot{y}}

% First derivatives
\newcommand{\dydx}{\frac{dy}{dx}}
\newcommand{\dfdx}{\frac{df}{dx}}
\newcommand{\dfdy}{\frac{df}{dy}}
\newcommand{\dfdz}{\frac{df}{dz}}

% Second derivatives
\newcommand{\ddyddx}{\frac{d^2y}{dx^2}}
\newcommand{\ddydxdy}{\frac{d^2y}{dx dy}}
\newcommand{\ddydydx}{\frac{d^2y}{dy dx}}
\newcommand{\ddfddx}{\frac{d^2f}{dx^2}}
\newcommand{\ddfddy}{\frac{d^2f}{dy^2}}
\newcommand{\ddfddz}{\frac{d^2f}{dz^2}}
\newcommand{\ddfdxdy}{\frac{d^2f}{dx dy}}
\newcommand{\ddfdydx}{\frac{d^2f}{dy dx}}


% First Partial Derivatives
\newcommand{\pypx}{\frac{\partial y}{\partial x}}
\newcommand{\pfpx}{\frac{\partial f}{\partial x}}
\newcommand{\pfpy}{\frac{\partial f}{\partial y}}
\newcommand{\pfpz}{\frac{\partial f}{\partial z}}


% argmin and argmax
\DeclareMathOperator*{\argmin}{arg\;min}
\DeclareMathOperator*{\argmax}{arg\;max}


% Various probability and statistics commands
\newcommand{\iid}{\overset{iid}{\sim}}
\newcommand{\vc}{\operatorname{vec}}
\newcommand{\Cov}{\operatorname{Cov}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\trace}{\operatorname{trace}}
\newcommand{\Corr}{\operatorname{Corr}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\asto}{\xrightarrow{a.s.}}
\newcommand{\pto}{\xrightarrow{p}}
\newcommand{\msto}{\xrightarrow{m.s.}}
\newcommand{\dto}{\xrightarrow{d}}
\newcommand{\Lpto}{\xrightarrow{L_p}}
\newcommand{\Lqto}[1]{\xrightarrow{L_{#1}}}
\newcommand{\plim}{\text{plim}_{n\rightarrow\infty}}


% Redefine real and imaginary from fraktur to plain text
\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}

% Shorter sums: ``Sum from X to Y''
% - sumXY  is equivalent to \sum^Y_{X=1}
% - sumXYz is equivalent to \sum^Y_{X=0}
\newcommand{\sumnN}{\sum^N_{n=1}}
\newcommand{\sumin}{\sum^n_{i=1}}
\newcommand{\sumjn}{\sum^n_{j=1}}
\newcommand{\sumim}{\sum^m_{i=1}}
\newcommand{\sumik}{\sum^k_{i=1}}
\newcommand{\sumiN}{\sum^N_{i=1}}
\newcommand{\sumkn}{\sum^n_{k=1}}
\newcommand{\sumtT}{\sum^T_{t=1}}
\newcommand{\sumninf}{\sum^\infty_{n=1}}
\newcommand{\sumtinf}{\sum^\infty_{t=1}}
\newcommand{\sumnNz}{\sum^N_{n=0}}
\newcommand{\suminz}{\sum^n_{i=0}}
\newcommand{\sumknz}{\sum^n_{k=0}}
\newcommand{\sumtTz}{\sum^T_{t=0}}
\newcommand{\sumninfz}{\sum^\infty_{n=0}}
\newcommand{\sumtinfz}{\sum^\infty_{t=0}}

\newcommand{\prodnN}{\prod^N_{n=1}}
\newcommand{\prodin}{\prod^n_{i=1}}
\newcommand{\prodiN}{\prod^N_{i=1}}
\newcommand{\prodkn}{\prod^n_{k=1}}
\newcommand{\prodtT}{\prod^T_{t=1}}
\newcommand{\prodnNz}{\prod^N_{n=0}}
\newcommand{\prodinz}{\prod^n_{i=0}}
\newcommand{\prodknz}{\prod^n_{k=0}}
\newcommand{\prodtTz}{\prod^T_{t=0}}

% Bounds
\newcommand{\atob}{_a^b}
\newcommand{\ztoinf}{_0^\infty}
\newcommand{\kinf}{_{k=1}^\infty}
\newcommand{\ninf}{_{n=1}^\infty}
\newcommand{\minf}{_{m=1}^\infty}
\newcommand{\tinf}{_{t=1}^\infty}
\newcommand{\nN}{_{n=1}^N}
\newcommand{\tT}{_{t=1}^T}
\newcommand{\kinfz}{_{k=0}^\infty}
\newcommand{\ninfz}{_{n=0}^\infty}
\newcommand{\minfz}{_{m=0}^\infty}
\newcommand{\tinfz}{_{t=0}^\infty}
\newcommand{\nNz}{_{n=0}^N}

% Limits
\newcommand{\limN}{\lim_{N\rightarrow\infty}}
\newcommand{\limn}{\lim_{n\rightarrow\infty}}
\newcommand{\limk}{\lim_{k\rightarrow\infty}}
\newcommand{\limt}{\lim_{t\rightarrow\infty}}
\newcommand{\limT}{\lim_{T\rightarrow\infty}}
\newcommand{\limhz}{\lim_{h\rightarrow 0}}

% Shorter integrals: ``Integral from X to Y''
% - intXY is equivalent to \int^Y_X
\newcommand{\intab}{\int_a^b}
\newcommand{\intzN}{\int_0^N}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Presentation %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\begin{frame}[plain]
\titlepage
\end{frame}


\begin{frame}{Outline}
\tableofcontents[hideallsubsections]
%\tableofcontents
\end{frame}


{\footnotesize
\begin{frame}{Types of Uncertainty}
Two Main Types and Considerations
\begin{itemize}
  \item Population versus sample and associated
    \alert{sampling uncertainty}.

    We would like to extrapolate from the sample to the population,
    and we need \alert{sampling assumptions} to deliver external
    validity in order to do so.

  \item \alert{Random assignment}, which gives rise to non-trivial
    inference problem \emph{even if} we have the full population.

    Fisher randomization inference considers exclusively this.
\end{itemize}
Note
\begin{itemize}
  \item We often do OLS, but the type of uncertainty we allow for
    affects \alert{standard errors} and hence our inference
  \item Often both types of uncertainty play a role
\end{itemize}
We will study these in the context of causal inference.
\end{frame}
}



{\footnotesize
\begin{frame}{Causal Inference: Outcomes}
\alert{Potential Outcomes}
\begin{itemize}
  \item Under binary treatment, this is a pair $(Y(0),Y(1))$
    giving the outcome under control status versus treatment,
    respectively
  \item Under multivalued treatment, this is a set
    $\{Y_i(d)\}_{d\in \calD}$
  \item \alert{Stable Unit Treatment Value Assumption (SUTVA)}:
    Implicit in the above notation for potential outcomes, we assume
    potential outcomes for a given unit only depends upon treatment status
    \alert{for that unit}, not other units.
    No spillovers.
\end{itemize}
\alert{Observed Outcomes}
\begin{itemize}
  \item Letting $D$ denote treatment status, we then observe
    \begin{align*}
      Y
      = Y(D)
      =
      Y(0)(1-D)
      +
      Y(1)D
    \end{align*}
  \item Inherently a \alert{missing data problem} in that we only
    observe one potential outcome, $Y(0)$ or $Y(1)$.
\end{itemize}
\end{frame}
}


{\footnotesize
\begin{frame}{Causal Inference: Dealing with Missing Data Problem}
Two approaches to dealing with missing data problem:
\begin{itemize}
  \item \alert{Modeling/Parametric Assumptions}
    \begin{itemize}
      \item Impose assumptions on the DGP that let us deduce missing
        observation, e.g.
        \begin{align*}
          Y(1)=Y(0)+c
        \end{align*}
        and we can estimate $c$

      \item Macro: Whole DSGE Model
    \end{itemize}

  \item \alert{Assumptions on Assignment Mechanism}
    \begin{itemize}
      \item Given assumptions on the assignment mechanism, we can
        estimate average effects
    \end{itemize}
\end{itemize}
\end{frame}
}



{\footnotesize
\begin{frame}{Causal Inference: Assignment Mechanism}
\alert{Assignment Mechanism}
\begin{itemize}
  \item Assumption on how treatment is assigned, given potential
    outcomes and/or covariates.

  \item Formally, it's a probability distribution over the joint
    treatment vector $(D_1,\ldots,D_n)$ for all units which, in general,
    depends upon potential outcomes and covariates
    \begin{align*}
      P[D_1,\ldots,D_n|Y(0),Y(1),X]
    \end{align*}
  \item Random Treatment:
    $D$ independent of potential outcomes and covariates
  \item Stratified Treatment:
    Partition sample into subgroups (e.g. based on gender), random
    assignment within subgroups.
    Ensures all treated units aren't of same gender.
  \item Selection on Observables
\end{itemize}
\end{frame}
}

{\footnotesize
\begin{frame}{Sources of Randomness}
Two sources of randomness when doing causal inference:
\begin{itemize}
  \item \alert{Design}-Based Uncertainty:
    Assignment was random and we don't observe the full set of potential
    outcomes, though we're generally interested in the difference of
    average outcomes if \alert{everyone} assigned to treatment or not.
  \item \alert{Sampling} Uncertainty:
    Sometimes we only observe a subset of the population of interest and
    we would like to extrapolate.
\end{itemize}
\end{frame}
}


{\footnotesize
\begin{frame}{Example: Finite Sample Inference}
Suppose the sample at hand is my population of interest.
\begin{itemize}
  \item Example: States in a panel study. There aren't more than 50
    states. Uncertainty is when timing hits.
  \item Potential outcomes fixed
  \item Only uncertainty is over the treatment assignment
\end{itemize}
\end{frame}
}


{\footnotesize
\begin{frame}{Randomization Inference}
Implicitly takes this finite sample perspective.
Only uncertainty is over treatment assignment.
Only uncertainty is that I didn't observe the other missing outcome.
What makes it work is the sharp null, which fully specifies missing
outcomes.
Mechanics.
\end{frame}
}


{\footnotesize
\begin{frame}{Inference on the Superpopulation}
Sample is a draw from superpopulation
\begin{itemize}
  \item Example: Individuals within states, states adopt policies, want
    to estimate average effect of earnings.
  \item Induces distribution on potential outcomes
  \item We make assumptions on the assignment mechanism
\end{itemize}
\end{frame}
}


%Working it Out
%- Regression estimand under sampling + design, vs. design uncertainty
%- We showed last time that we estimate the average treatment effect
%- Suppose we take simple difference in means
%- Two perspectives


\section{Unit-Root Econometrics}

{\scriptsize
\begin{frame}{Types of Processes I}
Strictly stationary process
\begin{itemize}
  \item Distribution the same
\end{itemize}
$I(0)$
\begin{itemize}
  \item \alert{Definition}:
    Strictly stationary plus long run variance in $(0,\infty)$
  \item \alert{General Representation}:
    For some mean $\delta$ that is generally nonzero, can write
    \begin{align*}
      \delta + u_t
    \end{align*}
    where $u_t$ is a zero mean strictly stationary process
\end{itemize}
$I(-1)$
\begin{itemize}
  \item \alert{Definition}: First difference of $I(0)$ process
  \item \alert{Result}: Has zero LR variance
\end{itemize}
$I(d)$ process, for $d=1,2,\ldots$
\begin{itemize}
  \item \alert{Definition}:
    The $d$th difference of the process yields an $I(0)$ process
  \item $I(1)$ most important case, see next slide
\end{itemize}
\end{frame}
}

{\scriptsize
\begin{frame}{Types of Processes II}
$I(1)$, aka Difference Stationary Process, aka Unit Root Process
\begin{itemize}
  \item \alert{Definition}: $I(d)$ process with $d=1$, i.e. first
    difference yields stationary process
  \item
    For some strictly stationary zero-mean process $\{u_t\}$,
    starting point $\xi_0$ (see discussion below), and deterministic
    time trend $\delta\cdot t$,
    level $\{\xi_t\}$ of this process has form
    \begin{align*}
      \xi_t = \xi_0 + \delta \cdot t + u_t + \cdots + u_1
    \end{align*}

  \item Called ``driftless'' if $\delta=0$, ``with drift'' if
    $\delta\neq0$.
    Above rep also makes clear that any ``$I(1)$ with drift'' is sum of
    a driftless $I(1)$ process and deterministic linear time trend.

  \item Must have starting point $\xi_0$ else $\xi_t$ would have
    infinite variance; wlog choose start date of $t=0$.
    Value $\xi_0$ can be viewed as random.

  \item Beveridge-Nelson:
    Any $I(1)$ proces can be written as the sum of
    \begin{itemize}
      {\scriptsize
      \item Linear time trend
      \item Strictly stationary zero mean process, often called the
        \alert{transitory component} this component does not affect very
        long-run forecasts.
      \item \alert{Stochastic trend}, which comes from the accumulation/adding
        up of the strictly stationary $u_t$ terms to get to the levels.

        Of called the \alert{permanent component} because the $u_t$
        terms have a permanent effect on foreasts at all horizons.
      }
    \end{itemize}

\end{itemize}
\end{frame}
}


{\footnotesize
\begin{frame}{Types of Processes III}
Trend Stationary Process
\begin{itemize}
  \item Linear time trend plus a stationary process (which is often
    called the \alert{transitory component})
  \item Distinct from $I(1)$ in that it does not have a stochastic
    trend.
\end{itemize}
\end{frame}
}


{\footnotesize
\begin{frame}{Goal: Distinguishing $I(1)$ from Trend Stationary}
We have extensively studied $I(0)$ processes up to second order variance
properties.

In studying processes with trends, ghe key task will be to distinguish
between
\begin{itemize}
  \item Trend stationary processes, which equal deterministic linear
    time trend plus stationary process
    \begin{align*}
      \xi_t = \xi_0 + \delta\cdot t + u_t
      \qquad
      \text{$u_t$ strictly stationary}
    \end{align*}

  \item $I(1)$ aka difference stationary processes, which equal a trend
    stationary process plus a stochastic trend.
\end{itemize}
There are many tests that take the $I(1)$ as the null, with trend
stationarity as the alternative.

There are fewer tests that take trend stationary as the null, with
$I(1)$ as the alternative.
\end{frame}
}


{\footnotesize
\begin{frame}{Goal for Inference}
Suppose we estimate regression model
\begin{align*}
  y_t = x_t\beta + \varepsilon_t
\end{align*}
where $u_t$ is a stationary error term.

The asymptotic behavior of the OLS estimator $\hat{\beta}$ depends
crucially upon $x_t$. Specifically:
\begin{itemize}
  \item $x_t$ Trend Stationary: $t$-stat for OLS estimator
    asymptotically standard normal
  \item $x_t$ Difference Stationary:
    $t$-stat has nonstandard limiting distribution, and we call
    regression in this instance \alert{cointegrating regression}.
\end{itemize}
\end{frame}
}





\end{document}



Placebo Tests
- Usually done to assess plausibility of procedure
- You know the potential outcomes are the same
- You want to estimate zero effect
- You take estimation of zero effect as encouraging
- Prob[zero effect | known zero effect] the means that P[some effect | zero effect] is zero


Normal model, conjugacy all over the place





% Sample code
\pause to add breaks
\textcolor{red}{text to show}.
\vspace{20pt}

\usebeamercolor{dull text}
\alert<+>{Words that you want to alert}

