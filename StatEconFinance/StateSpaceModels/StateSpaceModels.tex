\documentclass[a4paper,12pt]{article}

\author{Matthew Cocci}
\title{State Space Models} \date{\today}
\usepackage{enumitem} %Has to do with enumeration
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{amsthm} %allows for labeling of theorems
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
%\usepackage{blindtext}
\usepackage{graphicx}
%\usepackage[hidelinks]{hyperref} % For internal/external linking.
				 % [hidelinks] removes boxes
% \usepackage{url} % allows for url display, non-clickable
%\numberwithin{equation}{section}
   % This labels the equations in relation to the sections
      % rather than other equations
%\numberwithin{equation}{subsection} %This labels relative to subsections
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
%\setkomafont{disposition}{\normalfont\bfseries}
\usepackage{appendix}
\usepackage{fullpage}
\usepackage{subfigure} % For plotting multiple figures at once
\usepackage{verbatim} % for including verbatim code from a file
%\usepackage{natbib} % for bibliographies

%% Hyperlinks %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{hyperref}
\hypersetup{%
    colorlinks,
        %---This colors the links themselves, not boxes
    citecolor=black,
        %---Everything here and below changes link colors
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}


\begin{document}
\maketitle

\tableofcontents %adds it here

\clearpage
\section{Introduction}

State Space Models, the Kalman Filter, and simulation smoothers together
rank among those ``Hugely Important Things I Never Knew Existed''
following my undergrad education.

They're hugely important because they embed as special cases many
concepts in time series and dynamics.  In fact, when working with time
series, you can almost always fall back on the toolkit developed here.
It doesn't take much work to cast ARMA models, dynamic factor models,
structural VARs, and other important classes of models into state space
form, simply treating those applications as special cases.  Then, once
you know the state space representation and methods for efficient
estimation and posterior sampling, you've done half the work for many
applications in time series econometrics.

So the first portion will consist of describing state space models and
the very important concept of the ``state space.'' The second portion
will then give an overview of the subsequent sections which discuss
computing likelihood via the Kalman Filter and posterior sampling to
draw paths for the underlying state dynamics.

\section{State Space Models}

\subsection{Basic Building Blocks}

State space models are a nothing more than a particular approach to
describe and model time series data. State space models assume
that measurable, observed time series data---called \emph{observables} in
state space model terminology---are simply a function of underlying
(possibly unobserved) \emph{states}, whose dynamics can be restricted
according to simple assumptions or a full-fledged structural model.

What makes state space models so useful is the flexibility provided by
this approach that distinguishes between \emph{observables} (which
correspond to the data) and \emph{states} (which are flexible enough to
correspond to unobserved/latent variables, economic model concepts,
exogenous shocks, or even the data itself).

To consider an economic example, the \emph{states} in our model (which
we'll collect into a state vector) might correspond to a small number of
unobserved ``dynamic factors,'' whose evolution captures many different
features of the observed cross-sectional data.  With our states, we then
define the \emph{state space} as the set of all values our state vector
can assume. In other words, it's the multi-dimensional space spanned by
our state vector.

To quantify and model these (possibly unobserved) states, we use
\emph{observables}---series we can directly measure and observe like
like GDP, inflation, unemployment, or really any number of objects that
we want to quantify, model, and forecast. These data series inform our
estimates of the states, which we cannot always directly measure.

So just to reiterate, the biggest distinction between states and
observables: observables \emph{always} correspond one-to-one with data,
while states need not have a directly measurable series associated with
them.

\subsection{Linear State Space Models in Two Equations}

State space models essentially reduce to two fundamental equations:
\begin{align}
  \text{Transition:} \quad
    s_{t} &= C(\theta) + T(\theta) s_{t-1}
    + R(\theta)\varepsilon_{t} \label{ste}\
    \quad E[\varepsilon_t] = 0
    \quad E[\varepsilon_t \varepsilon'_t] =  Q(\theta) \\
  \text{Measurement:} \quad
    y_{t} &= D(\theta) + M(\theta) s_{t} + \eta_{t} \label{moe}
    \qquad\qquad E[\eta_t] =  0
    \quad E[\eta_t \eta'_t] =  H(\theta)
\end{align}
where $\theta$ is a vector of parameters to be estimated.\footnote{These
parameters will typically include a mix of simple concepts (means,
variances, autocorrelation coefficients) and complex concepts (like
perhaps elasticities in an economic model).} It is also assumed that
$\varepsilon_t$ and $\eta_t$ are uncorrelated, iid, and independent of
past values.\footnote{Though this easily be generalized by shutting down
  $\eta_t$ and incorporating measurement error into the states. See the
example below on expanding the state space.} Also, by construction,
$E[\varepsilon_t s_t']=E[\eta_t y_t']=0$.

Moreover, while $\varepsilon_t$ and $\eta_t$ are typically assumed to be
normal, we wrote them here in the more general (yet equally valid)
representation above. Later on, we will discuss the extra subtlety that
non-normal errors introduce into the interpretation.

\paragraph{State Transition Equation} Equation~\ref{ste} describes how
the state vector, $s_t$, evolves over time; it's a law of motion. In
words, the state vector next period is a function of the previous
period's state vector, plus some innovation/disturbance/shock (whatever
you want to call it).  Typically, the size of the shock vector
$\varepsilon_t$ will be much less than the number of states: There are a
small number of fundamental shocks with covariance matrix $Q(\theta)$
that get apportioned out to many more states via $R(\theta)$

But since the states and shocks might be unobserved (so that they do not
have a directly measurable series associated with them), we have to
relate them to the data somehow, which is where the next equation comes
in.

\paragraph{Measurement Equation} Equation~\ref{moe}, sometimes called
the ``Observation Equation'', relates the states to the directly
measurable observables, allowing for potential ``measurement error''
captured by $\eta_t$. More succinctly, $M$ is a matrix that \emph{maps}
states to observables. Since the number of states and observables may
differ, $M$ need not be square. Clearly, $D$ and $\eta_t$ must be the
same size as $y_t$.

\paragraph{Identification Assumptions}
The representation above is both useful and problematic because it is so
flexible.  It is useful because many models can be written into state
space form, so we will be able to develop a common set of techniques for
a wide variety of models. It is problematic for exactly the same reason.
What exactly is the ``correct'' way to set up the transition and
observation equation matrices?

For now, I'm going to punt. That task is really left to the
econometrician. In particular, she chooses a particular model from a
broad class of models (VAR, SVAR, DSGE, Dynamic Factor Model), and the
matrix representations follow. The methods developed from here onwards
won't tell you which model to use. Rather, they'll tell you how to
efficiently estimate and conduct inference on $\theta$ and the sequence
states $\{s_t\}_0^T$ for \emph{any} model you choose to write down in
state space form.

\newpage
\subsection{Expanding the State Space}

In this section, we show two examples of expanding the state space
(introducing extra states), and why we might want to do that.

\subsubsection{Introducing Extra Lags}

Equation~\ref{ste} only explicitly incorporates one lag of the state
vector. But suppose $s_t$ depends upon more than one lag. Not a problem;
the representation in Equation~\ref{ste} will still work if we expand
the state space---that is, incorporate additional variables into our
state vector. Specifically, we can rewrite the State Transition Equation
(in stacked vector and block matrix form) as
\begin{align}
  \begin{bmatrix} s_{t} \\ s_{t-1}
  \end{bmatrix}
     &=
  \begin{bmatrix} C \\ \mathbf{0}
  \end{bmatrix}
  +\begin{bmatrix} T_1 & T_2 \\ I & \mathbf{0}
  \end{bmatrix}
  \begin{bmatrix} s_{t-1} \\ s_{t-2}
  \end{bmatrix}
  + \begin{bmatrix}
      \varepsilon_{t}  \\ \mathbf{0}
    \end{bmatrix}
  \label{augmented.lags}
\end{align}
So now our new state vector is no longer $s_t$, but the stacked $z_t:=(s_t \;\; s_{t-1})'$. In this formulation, $T_1$ captures the dependence of $s_t$ upon $s_{t-1}$, while $T_2$ captures the dependence upon $s_{t-2}$. The bottom half of the transition matrix above will enforce that $s_{t-1}=s_{t-1}$. The necessary changes to the measurement equation are obvious.

To incorporate still more lags, the extra modifications to the state
transition equation are similarly straightforward. In addition, it may
even be the case that we need to use extra lags for only a few elements
of $s_t$, rather than all elements of $s_t$. In such cases,
Equation~\ref{augmented.lags} can be simplified so that we augment the
state vector with only the necessary lags, rather than the vector
$s_{t-1}$ (on the lefthand side) in it's entirety. Only the most minor
of adjustments to the transition matrix would be necessary.


\subsubsection{Measurement Error in the State Vector}

While the two-equation framework set up in (\ref{ste}) and (\ref{moe})
might be the most intuitive representation of our system, it might be
easier (for programming or computational reasons) to remove measurement
error from the measurement/observation equation. We can do so by, again,
enlarging the state space and incorporating measurement error as extra
states. Here, we exploit the fact that states are flexible enough to be
anything, really: unobserved latent variables, observed data,
measurement error, etc. So the distinction between states and
observables is somewhat artifical; we can always throw everything we
want to track and model into the state vector.

So to begin, rearrange the terms in Equation~\ref{ste} and
Equation~\ref{moe} into new State Transition and Measurement Equations.
Again, we use stacked vector and block matrix form, augmenting the state
vector with extra rows, $s'_t$, which capture the contribution from the
measurement errors:
\begin{align}
  \text{State Transition Equation:} \quad
    \begin{bmatrix} s_{t} \\ s'_t \end{bmatrix}
    &= \begin{bmatrix} C \\ \mathbf{0} \end{bmatrix}
    + \begin{bmatrix} T & \mathbf{0} \\
    \mathbf{0} & \mathbf{0} \end{bmatrix}
    \begin{bmatrix} s_{t-1} \\ s'_{t-1} \end{bmatrix}
    + \begin{bmatrix} \varepsilon_{t} \\ \eta_t \end{bmatrix}
    \label{ste.withmerr}
  \\ \notag \\
  \text{Measurement Equation:} \quad
    y_{t} &= D +
    \begin{bmatrix} M & I \end{bmatrix}
    \begin{bmatrix} s_{t} \\ s'_t \end{bmatrix}
\end{align}
In this representation, $s'_t$ effectively ``carries'' the measurement
error from the state transition equation down to the measurement
equation. But any past contributions from measurement errors are
decisively zeroed out going forward, as we see in the new transition
matrix of Equation~\ref{ste.withmerr}.

This representation also allows us to introduce correlation between
measurement errors, $\eta_t$, and shocks to the states, $\varepsilon_t$.
Since Equation~\ref{ste.withmerr} is the new state transition equation,
we know that the error term $\begin{bmatrix} \varepsilon_t' & \eta_t'
\end{bmatrix}'$, we know it must have a covariance matrix $R'(\theta)$.
We can simply make the off-diagonal elements non-zero bewteen
measurement error terms and shocks to the original state transition
equation as specified in Equation~\ref{ste}.

\subsection{Examples within the State Space Framework}

A few examples can best illustrate how state space models work in practice. Rather than just listing equations and general forms, we will fully specify some typical examples in state space form.

By casting some familiar models into state space, we show that state space models really do unify and generalize many different ideas. In addition, we show that the state space framework can handle a larger class of problems, as the two layers of states and observables easily accommodate distinctions between ``true values'' we hope to discern and the noisy measures we actually observe---as in the GDP example below.\footnote{Regular time series analysis doesn't usually allow for such distinctions, treating the observed series as \emph{the} true value always.}

\subsubsection{AR Model}

Suppose that we have some variable $x_t$ that evolves according to an AR($p$) process, where $\mu$ denotes the mean of the series.\footnote{Both here and in the next subsection, $\mu$ is assumed to be known. Otherwise, it would need to be estimated, as we will describe in later sections.} In other words,
\[
  (x_t - \mu) = \sum^p_{i=1} \rho_i (x_{t-i} - \mu)
  + \varepsilon_t
\]
Since the state transition equation relates past and present, this is where we will express the autoregressive relationship, using the approach in Subsection (Extra Lags) to augment the state vector to include extra lags:
\[
  s_t =
  \begin{bmatrix} x_t - \mu \\ x_{t-1} - \mu \\ \vdots \\
    x_{t-p+1} - \mu \end{bmatrix}
  =
  \begin{bmatrix}
    \rho_1 & \rho_2 & \cdots & \rho_{p+1} & \rho_p \\
    1 & 0 & \cdots & 0 & 0 \\
    0 & 1 & \cdots & 0 & 0 \\
    \vdots & \vdots & \ddots & \vdots & \vdots \\
    0 & 0 & \cdots & 1 & 0 \\
  \end{bmatrix}
  \begin{bmatrix} x_{t-1} - \mu \\ x_{t-2} - \mu \\ \vdots \\
    x_{t-p}- \mu \end{bmatrix}
  + \begin{bmatrix} \varepsilon_t \\ 0 \\ \vdots \\ 0
  \end{bmatrix}
\]
Finally, we specify the measurement equation to account for the de-meaning of $x_t$ within the state transition equation. Since we don't consider the additional layer of measurement error within regular AR($p$) models, we don't add any term for the error:
\[
  y_t = \begin{bmatrix} x_t \end{bmatrix}
  = \mu +
  \begin{bmatrix}
  1 & 0 & \cdots & 0 \\
  \end{bmatrix}
  \begin{bmatrix} x_t - \mu \\ x_{t-1} - \mu \\ \vdots \\
    x_{t-p+1} - \mu \end{bmatrix}
\]
Thus, we have now embedded the simple AR($p$) model within a state space framework.

\subsubsection{MA Model}

Now, let's consider an MA($q$) model:
\[
  (x_t - \mu) = \varepsilon_t
  + \sum^q_{i=1} \theta_i  \varepsilon_{t-i}
\]
Since we'll need to keep track of lagged \emph{innovations}, we'll incorporate those as elements of our state vector, rather than lagged values of $x_t$.\footnote{Here, we see a great example of the flexibility that state space models offer---the many different ways they allow the econometrician to think about and model the system.} This gives a state transition equation of
\[
  s_t =
  \begin{bmatrix}
  \varepsilon_t \\ \varepsilon_{t-1} \\
  \vdots \\ \varepsilon_{t-q}
  \end{bmatrix}
  = \begin{bmatrix}
  0 & 0 & \cdots & 0 & 0 \\
  1 & 0 & \cdots & 0 & 0\\
  0 & 1 & \cdots & 0 & 0\\
  \vdots & \vdots & \ddots & \vdots & \vdots\\
  0 & 0 & \cdots & 1 & 0\\
  \end{bmatrix}
  \begin{bmatrix}
  \varepsilon_{t-1} \\ \varepsilon_{t-2} \\
  \vdots \\ \varepsilon_{t-q-1}
  \end{bmatrix}
  + \begin{bmatrix}
  \varepsilon_t \\ 0 \\ \vdots \\ 0
  \end{bmatrix}
\]
Which then leads to the following observation equation. Again, no term for measurement error is necessary:
\[
  y_t =
  \begin{bmatrix} x_t \end{bmatrix}
  = \mu +
  \begin{bmatrix} 1 & \theta_1 & \theta_2 & \cdots &
    \theta_q \end{bmatrix}
  \begin{bmatrix}
  \varepsilon_t \\ \varepsilon_{t-1} \\
  \vdots \\ \varepsilon_{t-q}
  \end{bmatrix}
\]

\subsubsection{GDP: Income and Expenditure}
We also present an example where there is some unobserved ``true'' level
of GDP that we hope to capture, using two alternative measures that
ostensibly measure the same thing---the income and expenditure measures
of GDP\@. However, because of measurement error in both series, they
provide only a ``noisy'' measure. This is a situation ideally suited to
a state space representation.

\clearpage
\subsection{Working with State Space Models}

In order to work with state space models, we need to be able to
estimate them and draw from the posterior distribution of parameters and
states.  The following sections will detail the methods to handle these
tasks, but a birds eye view will help organize thought and provide
motivation for the coming sections.
\begin{enumerate}
  \item \textbf{Kalman Filter}: Whether approaching state space models
    from a frequentist or Bayesian point of view, you'll need to
    construct the likelihood, $p(y_{1:T}|\theta)$. The Kalman Filter
    provides a recursive algorithm to construct the likelihood given
    known transition and measurement equation matrices.

\end{enumerate}



\newpage
\section{The Kalman Filter}

Within the state space framework detailed above, we now face the task of estimating the sequence of (possibly unobserved) states. To do so, we typically use the Kalman filter, a recursive procedure to estimate and forecast states over time.

Section~\ref{subsec:kfoutline} sketches the basic sequence of steps for
deriving the distributions of the (possibly unobserved) states and then
forecasting their future values. Next, Section~\ref{subsec:kfdetails}
describes this recursive filtering algorithm in greater detail.
Section~\ref{subsec:kfnormal} then follows with a detailed examination
of this special case of Gaussian errors, relying on conditional
expectations for MVN Random Variables as described in
Appendix~\ref{sec:mvncond}.

Throughout this entire section, we will assume that the matrices defined
in Equation~\ref{ste} and Equation~\ref{moe} are entirely \emph{known},
postponing estimation for a later section after first nailing down the
intuition.

\subsection{Outline of the Recursive Procedure}
\label{subsec:kfoutline}

Here's the basic Kalman Filter procedure to estimate and forecast the
state vector, $s_t$, and it's distribution given data vector $y_t$ for
which we have observations running from $t=1$ until $t=T$. Throughout, I
will use $\mathcal{I}_{t}$ to denote the set of information available at
time $t$, i.e. $y_1, \ldots, y_{t}$.\footnote{In the case where $t=0$,
we form a true prior in that you haven't observed any $y_t$, so you
don't have any data or information as a basis for the distribution of
$s_1$.} This procedure applies to all linear state space models as
written in Equations~\ref{ste} and~\ref{moe}:
\begin{enumerate}
\item Start with a prior for the state vector at time $t$, call it, call
  it $p(s_t |\; \mathcal{I}_{t-1})$.

\item Observe the time $t$ realized data point, $y_t$.

\item Use Bayes' Rule to ``filter'' out the noise and compute the
  \emph{filtering distribution}, $p(s_t |\; \mathcal{I}_{t})$,
  incorporating the information about newly observed $y_t$.

\item Compute the one-step-ahead \emph{predictive distribution},
  $p(s_{t+1} | \; \mathcal{I}_{t})$, based on the filtering distribution
  from Step (3) and the your model's law of motion as specified in the
  State Transition Equation.

\item Increment $t$ and return to step 1, taking the predictive
  distribution $p(s_{t+1} |\; \mathcal{I}_{t})$ as your prior.
\end{enumerate}
Note that many introductions to the Kalman Filter often frame the
recursive process in terms of the evolution of only the \emph{mean} and
\emph{variance} of $\{s_t\}$ over time. This is done because the Kalman
Filter is often applied in the case where errors are normally
distributed, in which case the mean and variance pin down the successive
distributions {entirely}.\footnote{This is a feature of multivariate
normal random variables.} However, the procedure outlined above and in
the next subsection is ``General'' in that it frames the recursive
process in terms of the full \emph{distributions} for $\{s_t\}$ over
time---i.e. $p(s_t|\mathcal{I}_t)$ rather than
$\mathbb{E}[s_t|\mathcal{I}_t]$ and $\text{Var}(s_t|\mathcal{I}_t)$.
Such an exposition then remains valid even when errors have a non-normal
distribution.

Going forward, the remainder of this section will put some more
structure on this basic procedure, filling in the mathematical details.
It will also cover that special case of normal errors, and say why this
assumption might not be as dumb as it seems.\footnote{Hint: Regardless
of the true error distributions, the Kalman Filter gives the best linear
projection estimates of the states. It's kind of like when you know your
data isn't normally distributed, but you still run regressions because
it gives the best linear approximation to the CEF. I see you, Josh
Angrist.} For that discussion, follow a minor yet very important detour
in two subsections.


\subsection{The General Kalman Filter}
\label{subsec:kfdetails}

Given a sequence of data points $\{y_t\}_{t=1}^T$ our goal is to
estimate the sequence of states $\{s_t\}^T_{t=1}$. Of course, this will
all be probabilistic. Unless a state is mapped directly to an
observable (without measurement error or other shocks), we won't be able
to know with certainty the true value of the states. We'll instead
compute a sequence of probability distributions for the states at each
point in time. Again, we assume throughout that the matrices of our
linear state space model defined by Equations~\ref{ste}
and~\ref{moe} are entirely known.


\paragraph{Prior Step} Suppose we're standing at time $t-1$, in full possession of all information up until then. Specifically, we know $y_1, \ldots, y_{t-1}$, denoted as the information set $\mathcal{I}_{t-1}$.

Additionally, suppose that we have a prior for $s_t$, given $\mathcal{I}_{t-1}$,
\begin{equation}
  \text{Prior:} \quad p(s_t | \; \mathcal{I}_{t-1})
  \label{pri}
\end{equation}
In the case where $t=1$, then this is a true prior since $\mathcal{I}_{0}$ will be the empty set, and we will have no available observations as a basis for this prior. However, when $t>1$, the Kalman Filter procedure will furnish a prior, which we will derive in full below.

\paragraph{Filtering Step}
With the above prior in hand, when we get to time $t$, we observe $y_t$ and should immediately update our estimate of the distribution for $s_t$, incorporating the new time $t$ information. This step is called the ``Filtering Step'' because our combination of both prior and data allows us to \emph{filter out} the noise in our estimates for $s_t$.

But how exactly do we do this? Bayes' rule along with the fact that
$\mathcal{I}_{t} = \{y_1, \ldots, y_t\}=\mathcal{I}_{t-1} \cup y_t$.
More specifically, we compute the filtering distribution
\begin{align*}
  p(s_t | \mathcal{I}_{t}) =
  p(s_t | \; y_t, \mathcal{I}_{t-1}) =
  \frac{p(y_t | s_t, \mathcal{I}_{t-1})
    \cdot p(s_t|\; \mathcal{I}_{t-1})
  }{p(y_t | \; \mathcal{I}_{t-1})}
\end{align*}
This doesn't look like we've gotten anywhere, but note that we can
simplify a bit. By the setup and assumptions in Equations~\ref{ste}
and~\ref{moe}, we know that past values $y_1, \ldots, y_{t-1}$ have no
bearing upon $y_t$ if we know the state, $s_t$. Hence $p(y_t|s_t,
\mathcal{I}_{t-1}) = p(y_t|s_t)$. In addition, since the denominator is
just a normalizing constant, we can simplify the expression further to
\begin{equation}
  \label{filt}
  \text{Filtering Distribution:} \quad
  p(s_t | \mathcal{I}_{t}) \propto p(y_t | s_t) \cdot
  p(s_t |\mathcal{I}_{t-1})
\end{equation}
This is a very friendly expression since we already have $p(s_t |
\mathcal{I}_{t-1})$ from our prior and, given the setup in
Equations~\ref{ste} and~\ref{moe}, the likelihood $p(y_t|s_t)$ is very
easy to compute once we condition on the state $s_t$.

In fact, the measurement equation determines the distribution
$p(y_t|s_t)$ entirely. Since the $\eta_t$ errors are mean zero with
covariance matrix, $H$, we know by construction that
\[
  E[y_t|s_t] = D + M s_t
  \qquad
  \text{Var}(y_t|s_t) = H
\]
Beyond the mean and variance, the full distribution is characterized by
the distribution we assume for the measurement errors.

\paragraph{Forecast Step} Now that we have our filtering distribution,
we compute the \emph{forecast distribution}, which is the one-step ahead
distribution of $s_{t+1}$ given $\mathcal{I}_{t}$. Again, Bayes' Rule is
useful
\begin{align*}
  p(s_{t+1} | \; \mathcal{I}_{t}) &=
    \int p(s_{t+1}, s_t |\; \mathcal{I}_{t}) \; ds_t \\
  &= \int p(s_{t+1} |  s_t, \mathcal{I}_{t})
    p(s_t |  \mathcal{I}_{t}) \; ds_t
\end{align*}
But note that $p(s_{t+1} | s_t, \mathcal{I}_{t}) = p(s_{t+1}|s_t)$ since according to the State Transition Equation, if we know $s_{t}$, the observations $y_1, \ldots, y_t$ provoide no additional information. This yields the final expression
\begin{align}
  \text{Forecasting Distribution:} \quad
  p(s_{t+1} | \; \mathcal{I}_{t})
  &= \int p(s_{t+1} |  s_t)
    p(s_t |  \mathcal{I}_{t}) \; ds_t
\end{align}
Again, this doesn't look much simpler, but upon closer inspection, we
can easily recognize the components. Namely, $p(s_{t+1}|s_t)$ is
characterized by the assumption about the errors in the State Transition
Equation. By construction,
\[
  E[s_{t+1}|s_t] = C + Ts_t
  \qquad
  \text{Var}(s_{t+1}|s_t) = R
\]
Beyond just the mean and variance, the full distribution is
determined by the assumed distribution of the errors.

Finally, we see that $p(s_t|\mathcal{I}_{t})$ is just the
filtering distribution we computed in the last step.

\paragraph{Recursive Step} What exactly makes this whole procedure recursive? Increment $t$, take the distribution $p(s_{t+1}|\;\mathcal{I}_{t-1})$ that we just computed, and let that be our prior for the next period. Repeat until we get to time $T$.
\\
\\
All of these steps simplify considerably and become much more concrete if we're willing to assume normal errors. But how big of an assumption is that? What are the practical consequences of such a choice? To answer these questions, we will take a minor detour for the sake of intuition and interpretation before delving into the particular case of the Kalman Filter under normal errors.

\clearpage

\subsection{Kalman Filter Under Normal Errors}
\label{subsec:kfnormal}

We now derive the Kalman Filter procedure in the case of normally
distributed errors, $\varepsilon_t$ and $\eta_t$. Since the normal
distribution is pinned down entirely by the mean and variance, we need
only characterize the evolution of these two objects to characterize the
evolution of the full distribution of the states. For simpler notation,
we will ignore the constant vectors, $C$ and $D$ throughout this
section.

\paragraph{Notation}
Taking advantage of this, we will adopt the following standard notation, letting $\mu$ and $\Sigma$ denote the mean and variance, respctively:
\begin{align*}
  E[s_t|\;\mathcal{I}_{t-1}] &= \mu_{t|t-1}
  \qquad
  \qquad
  E[s_t|\;\mathcal{I}_{t}] = \mu_{t|t}  \\
  \text{Var}(s_t|\;\mathcal{I}_{t-1}) &= \Sigma_{t|t-1}
  \qquad
  \quad
  \text{Var}(s_t|\;\mathcal{I}_{t}) = \Sigma_{t|t}
\end{align*}
So rather than directly specifying the sequence of distributions (prior,
filtering, and forecast), we need only specify the sequence of the
determinants of those distributions: the prior, filtering, and forecast
\emph{means and variances}.
%\[
%  p(s_t|\;\mathcal{I}_{t-1})
%  \qquad
%  p(s_t|\;\mathcal{I}_{t})
%  \qquad
%  p(s_{t+1}|\;\mathcal{I}_{t})
%\]
%we need only specify the sequence of the determinants of those distributions,
%\[
%  \begin{pmatrix} \mu_{t|t-1} & \Sigma_{t|t-1}
%  \end{pmatrix}
%  \qquad
%  \begin{pmatrix} \mu_{t|t} & \Sigma_{t|t} \end{pmatrix}
%  \qquad
%  \begin{pmatrix} \mu_{t+1|t} & \Sigma_{t+1|t} \end{pmatrix}
%\]

\paragraph{Prior Step}
Suppose that we have a Guassian prior for $s_t$, given $\mathcal{I}_{t-1}$,
\[
  s_t | \; \mathcal{I}_{t-1}
  \sim N(\mu_{t|t-1}, \Sigma_{t|t-1})
\]
In the case where $t=1$, then this is a true prior, and $\mu_{1|0}$ and
$\Sigma_{1|0}$ reflect an initial condition/guess. When $t>1$, the
Kalman Filter procedure will furnish a Gaussian prior, which we will
derive in full below.

\paragraph{Filtering Step}
Recall that the goal of the filtering step is to compute the
filtering distribution, $p(s_t|\mathcal{I}_{t})=p(s_t|y_t,
\mathcal{I}_{t-1})$. Now because we're assuming both $s_t$ and $y_t$ are
normally distributed (since the error terms are)
\begin{align*}
  \begin{bmatrix} s_t \\ y_t \end{bmatrix} | \;
  \mathcal{I}_{t-1}
  \sim
  N\left(\begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix},
  \begin{bmatrix} \Sigma_{11} & \Sigma_{12} \\
  \Sigma_{21} & \Sigma_{22} \end{bmatrix}
  \right)
\end{align*}
for some value of the terms $\mu_{i}$, and $\Sigma_{jk}$, where $i, j,
k\in\{1,2\}$. Now with this setup, it's clear how to compute the
filtering distribution: apply the result from the last subsection to get
$p(s_t|y_t, \mathcal{I}_{t-1}) = p(s_t | \;\mathcal{I}_{t})$. We just
need to pin down those terms.
\\
\\
{\sl Defining the Terms:} \/Throughout, well use the notation that
$E_{t-1}[\,\cdot\,] = E[\,\cdot\,|\mathcal{I}_{t-1}]$ to make things
more readable.
\begin{itemize}
  \item $\mu_1$ and $\Sigma_{11}$: These terms correspond
    to the mean and covariance matrix for $s_t |\;
    \mathcal{I}_{t-1}$. But we know these. We defined them
    in the prior step to be $\mu_{t|t-1}$ and
    $\Sigma_{t|t-1}$, respectively.

  \item $\mu_2$ and $\Sigma_{22}$: First, use Measurement
    Equation~\ref{moe} to get the mean
    \begin{align*}
      \mu_2 := E_{t-1}[y_t ] &=
        E_{t-1}[Ms_t + \eta_t ] =
        ME_{t-1}[s_t]
        + E_{t-1}[\eta_t ]\\
        &= M \mu_{t|t-1} + 0 = M\mu_{t|t-1}
    \end{align*}
    Now that we have the mean, let's get the variance of $y_t$:
    \begin{alignat*}{2}
      \text{From Measurement Equation} &\qquad
        \text{Var}_{t-1}(y_t)
        &&= \text{Var}_{t-1}(Ms_t + \eta_t) \\
      \text{Since $s_t\perp\eta_t$} &\qquad
        &&= \text{Var}_{t-1}(Ms_t)
        + \text{Var}_{t-1}(\eta_t)\\
      \text{Property of covariance matrices} &\qquad
        &&= M [\text{Var}_{t-1}(s_t)] M'
        + \text{Var}(\eta_t) \\
      \text{From Equations~\ref{ste} and~\ref{moe}} &\qquad
        &&= M\Sigma_{t|t-1} M' + H =: \Sigma_{22}
    \end{alignat*}

  \item Finally, let's define $\Sigma_{12} =
    (\Sigma_{21})^T$, using some of the results just
    obtained and again substituting in using the
    Measurement Equation.
    \begin{align*}
      \Sigma_{21} := E_{t-1}\left[(y_t-\mu_2)(s_t - \mu_1)'
        \right] &=
        E_{t-1}\left[(Ms_t+\eta_t-M\mu_{t|t-1})(s_t-\mu_{t|t-1})'
        \right]  \\
      &= E_{t-1}\left[\left\{\eta_t+ M(s_t-\mu_{t|t-1})\right\}
        (s_t-\mu_{t|t-1})' \right]  \\
      \text{Distribute}
      \qquad
      &= E_{t-1}\left[\eta_t(s_t-\mu_{t|t-1})'\right]]\\
      &\quad + E_{t-1}\left[M(s_t-\mu_{t|t-1})
        (s_t-\mu_{t|t-1})'\right]  \\
      \text{By definition of $\Sigma_{11}=\Sigma_{t|t-1}$}
      \qquad
      &= E_{t-1}\left[\eta_t\varepsilon'_t\right]
        + M\Sigma_{t|t-1} \\
      \text{Since $\varepsilon_t\perp \eta_t$} \qquad
      &= 0 + M\Sigma_{t|t-1}  = M\Sigma_{t|t-1}
    \end{align*}
\end{itemize}
Now that all of the components have been specified, we can fill in,
apply the result from Appendix~\ref{sec:mvncond}, and conclude (also
remembering that $\mathcal{I}_{t}=\mathcal{I}_{t-1} \cup \{y_t\}$):
\begin{alignat}{3}
  &&\begin{bmatrix} s_t \\ y_t \end{bmatrix} | \;
  \mathcal{I}_{t-1}
  &\sim
  N\left(\begin{bmatrix} \mu_{t|t-1} \\ M\mu_{t|t-1}
    \end{bmatrix},
  \begin{bmatrix}
    \Sigma_{t|t-1} & \Sigma_{t|t-1} M'
    \notag\\
    M\Sigma_{t|t-1} & M\Sigma_{t|t-1}M' + H
  \end{bmatrix}
  \right) \notag\\\label{normfilt}\\
  \Rightarrow \qquad
  \mu_{t|t} =&& E[s_t|y_t, \mathcal{I}_{t-1}]
    &= \mu_{t|t-1} + \Sigma_{t|t-1} M'
    \left(M\Sigma_{t|t-1}M' + H\right)^{-1} (y_t-M\mu_{t|t-1}) \notag\\
  \Sigma_{t|t} =&&
    \text{Var}(s_t|y_t, \mathcal{I}_{t-1})
    &= \Sigma_{t|t-1} - \Sigma_{t|t-1}M'
    \left(M\Sigma_{t|t-1}M' + H\right)^{-1} M\Sigma_{t|t-1} \notag
\end{alignat}
This result has a very nice interpretation. We see that our estimate of
the filtered mean $\mu_{t|t}$ is the sum of the prior mean $\mu_{t|t-1}$
plus the scaled error for $y_t$ relative to it's prior expectation
$M\mu_{t|t-1}$.  In addition, the information provided by $y_t$ allows
us to reduce our the variance in our estimate of $s_t$ to $\Sigma_{t|t}$
relative to the prior variance $\Sigma_{t|t-1}$.

\paragraph{Forecast Step} Now that we have our filtered mean and
variance estimates, we can apply the law of motion as written in State
Transition Equation~\ref{ste} to get the mean and variance of the
forecast for the states:
\begin{alignat*}{3}
  \mu_{t+1|t} =&& E[s_{t+1}|\;\mathcal{I}_{t}] &=
    E[Ts_t + R\varepsilon_t |\;\mathcal{I}_{t}] =
    TE[s_t | \mathcal{I}_{t}]
    + RE[\varepsilon_t |\;\mathcal{I}_{t}]  \\
    && &= T\mu_{t|t} + 0 = T\mu_{t|t} \\
  \Sigma_{t+1|t} = &&\text{Var}(s_{t+1}|\;\mathcal{I}_{t})
  &= \text{Var}(Ts_t + R\varepsilon_t |\;\mathcal{I}_{t})
  = T[\text{Var}(s_t|\;\mathcal{I}_{t})]T'
  + R[\text{Var}(\varepsilon_t|\;\mathcal{I}_{t})]R' \\
  && &= T\Sigma_{t|t}T' + RQR'
\end{alignat*}
A similarly straightforward application and writing-out of the
measurement equation will yield the following forecast mean and variance
for the observables:
\begin{align*}
  E[y_{t+1}|\;\mathcal{I}_{t}] &= T\mu_{t|t} \\
  \text{Var}(y_{t+1}|\;\mathcal{I}_{t})
    &= M\left(T\Sigma_{t|t}T' + RQR'\right)M' + H
\end{align*}

\subsection{Innovation Representation}

Instead of working directly with the states, we can work with the
innovations:
\begin{align*}
  v_t &:= y_t - \mu_{t|t-1}\\
  P_t &:= \Sigma_{t|t-1} \\
\end{align*}

\subsection{Long-Horizon Forecasts}

The section has so far only discussed the consruction of one step ahead
forecast distributions for states and observables. However, once we
reach the end of the sample and derive $p(s_T | \mathcal{I}_{T})$, we
will often want to forecast $s_{T+1}$, $s_{T+2}$, etc.\ along with
$y_{T+1}$, $y_{T+2}$, etc. So let's now characterize the distributions
of our forecasts.

For simplicity, we ignore the constant terms $C$ and $D$. We will also construct the $m$-step ahead distributions for any $t=1,\ldots,T$, not just $t=T$ since the results are the same.

\paragraph{State Forecasts} Start by applying the transition matrix to get the mean. All of the error terms will drop out:
\[
  E[s_{t+m} | \mathcal{I}_{t}] =
  T^m \mu_{t|t} =: \mu_{t+m|t}
\]
Now for the covariance matrix, we first construct the error:
\begin{align*}
  s_{t+m} - \mu_{t+m|t} &=
  \left(T^m s_t + T^{m-1} R\varepsilon_{t+1}
  + \ldots
  + TR\varepsilon_{t+m-1} + R\varepsilon_{t+m}\right)
  - T^m \mu_{t|t}\\
  &= T^m (s_t-\mu_{t|t}) + T^{m-1} R\varepsilon_{t+1}
  + \ldots
  + TR\varepsilon_{t+m-1} + R\varepsilon_{t+m}
\end{align*}
Now take the expectation of the squared error above to get the covariance matrix:
\begin{align*}
  \Sigma_{t+m|t} &:=
    E[(s_{t+m} - \mu_{t+m|t})'(s_{t+m} - \mu_{t+m|t})]\\
    &= T^m \Sigma_{t|t} (T^m)' + T^{m-1}RQ(RT^{m-1})'
      + \cdots + TRQR'T' + RQR'
\end{align*}

\paragraph{Observable Forecasts} From there, it's easy to see how we get the forecast distribution of the observables. To get the mean, recall the measurement equation:
\begin{align*}
  E[y_{t+m}|\;\mathcal{I}_{t}] &=
    E[Ms_{t+m} + \eta_{t+m}|\;\mathcal{I}_{t}]
    = ME[s_{t+m}|\;\mathcal{I}_{t}]
    + E[\eta_{t+m}|\;\mathcal{I}_{t}]\\
  &= M\mu_{t+m|t} + 0 = M T^m \mu_{t|t}
\end{align*}
Next, we construct the error of the forecast, which we then square to get the covariance matrix:
\begin{align*}
  y_{t+m} - E[y_{t+m}|\;\mathcal{I}_{t}] &=
    \left(Ms_{t+m} + \eta_{t+m}\right)
    - M\mu_{t+m|t}\\
  &= M\left(s_{t+m}-\mu_{t+m|t}\right) + \eta_{t+m}\\
  \Rightarrow\qquad
  E\left\{y_{t+m} - E[y_{t+m}|\;\mathcal{I}_{t-1}]
  \right\} &= M\Sigma_{t+m|t}M' + H
\end{align*}


\clearpage
\section{Smoothing}

The last section laid out in detail the recursive Kalman Filter
procedure for computing the likelihood and deriving a sequence of
distributions for the states:
\begin{equation}
  \label{distseq}
  N(\mu_{1|1}, \Sigma_{1|1}) \quad \ldots \quad  N(\mu_{T|T}, \Sigma_{T|T})
\end{equation}
If you only care about forecasting $s_{T+i}$ and $y_{T+i}$ for $i>0$,
then you're done.  The Kalman Filter gave you the best possible estimate
of the distribution of $s_T$.  Forecast forward from there.

However, we're typically not only interested in forecasting; we often
want to draw/simulate paths from the joint distribution of states and
obtain the best possible estimates of the distribution of states
from $t=1,\ldots,T$. More precisely, we want
\begin{enumerate}
  \item To draw/simulate paths $\{\tilde{s}_1,\ldots,\tilde{s}_T\}$
    from $p(s_{1:T}|\theta, y_{1:T})$, and
  \item Obtain estimates $\mu_{t|T} := E[s_t|\mathcal{I}_T]$ and
    $\Sigma_{t|T} := \text{Var}(s_t|\mathcal{I}_T)$ where
    $\mathcal{I}_T$ is the full information set.
\end{enumerate}

In both of these tasks, we see why the Kalman Filter is not enough.
Specifically, we shouldn't simply simulate a path
$\{\tilde{s}_1,\ldots,\tilde{s}_T\}$ by drawing $\tilde{s}_1$ from
$N(\mu_{1|1}, \Sigma_{1|1})$, then drawing $\tilde{s}_2$ from
$N(\mu_{2|2}, \Sigma_{2|2})$, and so on. That approach wouldn't account
for the correlation between successive draws of states (since
$\tilde{s}_1$ and $\tilde{s}_2$ are not independent). More precisely, we
want to draw paths from a sequence of \emph{conditional} distributions
of the states, not \emph{marginal} distributions that ignore
autocorrelation between states.

Second, Kalman Filter estimates of the state distributions don't use the
full information set.  The Kalman Filter proceeds from $t=1$ to $t=T$
without ever looking back and revising early estimates of
$\mu_{t|t}$ or $\Sigma_{t|t}$ for $t<T$ in light of later
information.

For all of these reasons, smoothing methods have been developed to solve
all of these problems, using the full information set $\mathcal{I}_T$ to
draw paths of the states and provide better estimates of the marginal
means and variances.

\subsection{The Key Conditional Distribution in Smoothing}
\label{sec:smoothresult}

Just as the normal-erros Kalman Filter used the result about conditional
distributions for MVN RV's (detailed in Appendix~\ref{sec:mvncond}),
we'll again apply this result in the context of smoothing under Gaussian
disturbances. Only now, we'll think about the effect that knowing the
future state $s_{t+1}$ has on our estimate of $s_t$, consistent with our
desire to do ``backward'' revisions/updates of the states.

From the forecast step in the Kalman filter procedure, we can fill in
almost everything we need, having already computed most objects of
interest:
\begin{equation}
  \label{smoothsetup}
  \left. \begin{bmatrix} s_t \\ s_{t+1} \end{bmatrix} \;\right\rvert
  \mathcal{I}_t
  \sim N\left(
  \begin{bmatrix} \mu_{t|t} \\ T\mu_{t|t} \end{bmatrix},
  \begin{bmatrix} \Sigma_{t|t} & \cdot \\
                  \cdot & T\Sigma_{t|t} T'+R \end{bmatrix},
  \right)
\end{equation}
Only the correlation between $s_t$ and $s_{t+1}$ remains to compute:
\begin{align*}
  E\left[(s_t-\mu_{t|t})(s_{t+1}-T\mu_{t|t})' | \mathcal{I}_t\right] &=
    E\left[(s_t-\mu_{t|t})(Ts_t + R\varepsilon_{t+1}-T\mu_{t|t})' |\;
      \mathcal{I}_t\right] \\
  \text{Distributing} \qquad
    &= E\left[(s_t-\mu_{t|t})(Ts_t -T\mu_{t|t})' |\;
      \mathcal{I}_t\right]
    + E\left[(s_t-\mu_{t|t})(R\varepsilon_{t+1})' |\;
      \mathcal{I}_t\right] \\
  &= E\left[(s_t-\mu_{t|t})(s_t -\mu_{t|t})' |\;
      \mathcal{I}_t\right] T' \\
    &\qquad
    + E\left[s_t\varepsilon_{t+1}' |\;
      \mathcal{I}_t\right] R'
    + \mu_{t|t}\left(E\left[\varepsilon_{t+1}' |\;
      \mathcal{I}_t\right]\right)R' \\\\
  \Rightarrow\quad \text{Cov}(s_t, s_{t+1}|\; \mathcal{I}_t)
      &= \Sigma_{t|t}T'
\end{align*}
where the last two terms dropped because $s_t \perp \varepsilon_{t+1}$
and $E[\varepsilon_t]=0$ for all $t$.

Finally, now that we have filled out all of the terms in
Equation~\ref{smoothsetup}, we can use the result in
Appendix~\ref{sec:mvncond} to derive the conditional distribution that
represents the key relationship in smoothing given normal errors:
\begin{alignat}{3}
  &&\left. \begin{bmatrix} s_t \\ s_{t+1} \end{bmatrix} \;\right\rvert
    \mathcal{I}_t
    &\sim N\left(
    \begin{bmatrix} \mu_{t|t} \\ T\mu_{t|t} \end{bmatrix},
    \begin{bmatrix} \Sigma_{t|t} & \Sigma_{t|t}T' \\
                    T\Sigma_{t|t} & T\Sigma_{t|t} T'+R \end{bmatrix}
    \right) \notag\\\label{smoothresult}\\
  \Rightarrow \quad
  %\mu_{t|T} :=
  &&E[s_t|s_{t+1}, \mathcal{I}_t] &=
      \mu_{t|t} + \Sigma_{t|t}T'\left(T\Sigma_{t|t} T'+R\right)^{-1}
      (s_{t+1}-T\mu_{t|t}) \notag\\
  %\Sigma_{t|T} :=
  &&\text{Var}\left(s_t|s_{t+1},\mathcal{I}_t\right)
    &= \Sigma_{t|t} - \Sigma_{t|t}T' \left(T\Sigma_{t|t} T'+R\right)^{-1}
      T\Sigma_{t|t}
  \notag
\end{alignat}
We'll come back to this recursive relationship in subsequent sections as
we draw from the full posterior distribution of the states.


\subsection{Simplifying the Joint Posterior of States}

Throughout this section, recall that our goal is to draw from the
posterior distribution of states
\begin{equation}
  p(s_{0:T}|\theta, y_{1:T})
\end{equation}
We will do this in a sequnce of steps:
\begin{enumerate}
  \item First, we can break this joint probability up into a product of
    conditionals:
    \begin{equation}
      \label{key2}
      p(s_{0:T}|y_{1:T},\theta) =
      \left[ \prod_{t=0}^{T-1} p(s_t|s_{t+1:T},y_{1:T},\theta) \right]
      p(s_T|y_{1:T},\theta)
    \end{equation}
  \item Next, we simplify further by recognizing that,
    $p(s_t|s_{t+1:T},y_{1:T},\theta) = p(s_t|s_{t+1:T},y_{1:t},\theta)$.
    That is because, conditional on future states $s_{t+1:T}$ and past
    data $y_{1:t}$, future observations $y_{t+1:T}$ provide no
    additional information about $s_t$:
    \begin{align*}
      y_{t+i} &= M s_{t+i} + \eta_{t+i}
      \quad \text{with } \eta_{t+i} \perp \{\varepsilon_0, \ldots,
      \varepsilon_t\} \qquad \forall \; i \geq 1 \\
      \Rightarrow\qquad
      p(s_t|s_{t+1:T},y_{1:T},\theta)
      &= p(s_t|s_{t+1:T},y_{1:t},\theta)
    \end{align*}
    That allows us to write Equation~\ref{key2} as
    \begin{equation}
      p(s_{0:T}|y_{1:T},\theta) =
      \left[ \prod_{t=0}^{T-1} p(s_t|s_{t+1:T},y_{1:t},\theta) \right]
      p(s_T|y_{1:T},\theta)
    \end{equation}
  \item Lastly, we can simplify again by recognizing that
    $p(s_t|s_{t+1}, y_{1:t},\theta) = p(s_t|s_{t+1:T},y_{1:t},\theta)$.
    Conditional on past data $y_{1:t}$ and the next state $s_{t+1}$, the
    entire future sequence of states $s_{t+2:T}$ provides no additional
    information about $s_t$.  To see this, first note that
    \begin{align}
      s_{t+1+i} = T^i s_{t+1} + \sum^i_{j=1} T^{i-j} R \varepsilon_{t+1+j}
      \qquad \forall \; i \geq 1
      \label{st1i}
    \end{align}
    We want to show that for all $i\geq1$, conditional on $s_{t+1}$ and
    $y_{1:t}$, the states $s_{t+1+i}$ and $s_t$ are independent.  Since
    everything is Guassian, it suffices to prove merely that
    $s_{t+1+i}|s_{t+1},y_{1:t}$ and $s_t|s_{t+1},y_{1:t}$ are
    uncorrelated.  So let's try that approach and write the
    conditional covariance matrix:
    \begin{align*}
      &E\left\{
        \left(s_t - E[s_t|s_{t+1},y_{1:t}]\right)
        \left(s_{t+1+i} - E[s_{t+1+i}|s_{t+1},y_{1:t}]\right)'
        | s_{t+1},y_{1:t}
      \right\}  \\
      \text{By~\ref{st1i}}
      &\quad\qquad =
      E\left\{\left.
        \left(s_t - E[s_t|s_{t+1},y_{1:t}]\right)
        \left(\sum^i_{j=1} T^{i-j} R \varepsilon_{t+1+j}\right)'
        \right\rvert s_{t+1},y_{1:t}
      \right\}  \\
      &\quad\qquad =
      E\left\{\left.
        \zeta_t
        \left(\sum^i_{j=1} T^{i-j} R \varepsilon_{t+1+j}\right)'
        \right\rvert s_{t+1},y_{1:t}
      \right\} \\\\
      &\text{where }
      \zeta_t :=  \left(s_t - E[s_t|s_{t+1},y_{1:t}]\right)
    \end{align*}
    But we can deduce the distribution of $\zeta_t | s_{t+1}, y_{1:t}$
    from work we did in Section~\ref{sec:smoothresult}, recalling
    Result~\ref{smoothresult} in particular:
    \begin{equation}
      \zeta_t| s_{t+1}, y_{1:t}\sim
      N(0, \Sigma_{t|t} - \Sigma_{t|t}T'
           \left(T\Sigma_{t|t} T'+R\right)^{-1} T\Sigma_{t|t})
    \end{equation}
    Now note that the distribution of $\zeta_t$ is only a function of
    $\Sigma_{t|t}$, which is independent of past realized values
    $y_{1:t}$. Moreover,

\end{enumerate}







\subsection{Simulation Smoother}



\subsection{Outline of the Recursive Procedure}

Again, we seek the distribution of $s_t$ given data $\{y_t\}^T_1$. This
applies to all linear state space models as written in
Equation~\ref{ste} and Equation~\ref{moe}:
\begin{enumerate}
  \item Run the Kalman Filter, storing the filtered
    probability distributions (or relevant parameters
    defining those distributions),
    $p(s_t|\mathcal{I}_{t-1})$ from $t=1,\ldots,T$.
  \item
\end{enumerate}


\clearpage
\section{Time-Varying State Space Models}

Suppose we want to consider time series models that
include time-varying coefficients. We can easily extend
the state space framework developed above to accommodate.




%\section{Filtering}
%
%Suppose we want to measure some latent state variable $x$. We will
%assume a \emph{prior} that is multivariate normal such that
%    \[ s_t \sim \text{N}(\hat{s}_t, \Sigma) \]
%Next, we ``measure'' $x$ by matching it to an observable in
%a \emph{measurement equation}:
%    \[ y = G x + v \qquad v\sim \text{N}(0, R) \]
%where $R$ is positive definite, while $G$ and $R$ are both
%$2 \times 2$. This forms the \emph{likelihood}.
%\\
%\\
%We then ``filter'' out the noise, updating our view of $x$ in
%light of the data in the filtering step using Bayes' Rule.
%Note, this is called ``filtering'' because we don't use the prior
%and likelihood to forecast into
%the future. We combine the prior with the likelihood only to filter
%out noise and get closer to the true value of $x$ based on
%the data, summarized in the posterior, or the
%\emph{filtering distribution}:
%\begin{align}
%    p(x \; | \; y) &= \frac{p(y \; | \; x) \cdot p(x)}{p(y)}
%    \propto p(y \; | \; x) \cdot p(x) \label{xgiveny} \\
%    &\propto \exp\left\{-\frac{1}{2}
%	\left( y - Gx \right)' R^{-1} \left(y-Gx\right)
%	\right\} \exp\left\{-\frac{1}{2}( x - \hat{x} )'
%	\Sigma^{-1} (x-\hat{x})\right\} \notag
%\end{align}
%Now let's expand the term in the lefthand exponential:
%\begin{align*}
%    A = \left( y - Gx \right)' R^{-1} \left(y-Gx\right) &=
%	\left( y' - x'G' \right) R^{-1} \left(y-Gx\right)
%    = \left( y'R^{-1} - x'G'R^{-1} \right)  \left(y-Gx\right) \\
%    &= \left( y'R^{-1}y - y'R^{-1} Gx - x'G'R^{-1} y
%	+ x'G'R^{-1} Gx\right)
%\end{align*}
%And now the same for the righthand exponential:
%\begin{align}
%     B = ( x - \hat{x} )' \Sigma^{-1} (x-\hat{x})
%	&= ( x' - \hat{x}' ) \Sigma^{-1} (x-\hat{x}) \notag\\
%    &=  (x'\Sigma^{-1} - \hat{x}'\Sigma^{-1})
%	(x-\hat{x}) \notag \\
%    &=  x'\Sigma^{-1} x - x'\Sigma^{-1} \hat{x} -
%	\hat{x}'\Sigma^{-1} x
%	+ \hat{x}'\Sigma^{-1} \hat{x} \label{B}
%\end{align}
%Adding the two exponentials, we get:
%\begin{align*}
%    C = A + B &= x' \left( \Sigma^{-1} + G'R^{-1}G\right) x
%	- x' (\Sigma^{-1} \hat{x} + G'R^{-1}y)
%	- (\hat{x}' \Sigma^{-1} + y' R^{-1}G) x  \\
%	& \qquad + \hat{x}' \Sigma^{-1} \hat{x} + y' R^{-1} y
%\end{align*}
%Now notice that Expression \ref{xgiveny} is the probability
%distribution of $x$ \emph{conditional} on $y$ and pretty
%much anything else that isn't $x$.  And because of the
%wonderful properties of the exponential function and the
%black-hole powers of the proportionality constant, we'll be
%able to simplify things nicely (and we'll worry that the
%distribution $p(x|y)$ integrates to one later on).
%
%So in the expression for $C$, the two terms
%in the second row \emph{don't} depend upon $x$. Therefore,
%letting $C(x)$ be the portion of $C$ that depends upon
%$x$, and letting $C(\lnot x)$ bet the additive terms which
%don't depend upon $x$, we can simplify
%\begin{align*}
%    p(x\; | \; y) &\propto \exp\left\{ -\frac{1}{2}
%	C \right\} = \exp\left\{ -\frac{1}{2}
%	\left[C(x) + C(\lnot x) \right]\right\}  \\
%    &\propto \exp\left\{ -\frac{1}{2}
%	C(x)\right\} +  \exp\left\{ -\frac{1}{2} C(\lnot x)
%	\right\}  \\
%    &\propto \exp\left\{ -\frac{1}{2}
%	C(x)\right\}
%\end{align*}
%We just absorb the portion not relevant to $p(x|y)$ into
%the proportionality constant.  This means our the work we
%did above to get $C$ simplifies our target expression to
%\begin{align}
%    p(x\;|\;y) &\propto \exp\left\{-\frac{1}{2} \left[
%	x' \left( \Sigma^{-1} + G'R^{-1}G\right) x
%	- x' (\Sigma^{-1} \hat{x} + G'R^{-1}y)
%	- (\hat{x}' \Sigma^{-1} + y' R^{-1}G) x  \right]\right\}
%	\label{tosimp}
%\end{align}
%\paragraph{Goal}
%Now this doesn't look too helpful, but with a little bit of
%work, we can turn this into the probability distribution
%for a multivariate normal random variable.
%In fact, the rest of the section may look complicated, but
%keep in mind the big picture: the likelihood and prior
%were both multivariate normal, so
%the posterior $p(x|y)$ is going to be normal. We just want
%to identify the mean vector and variance-covariance matrix;
%then we're home.
%
%\paragraph{Variance} So first, the {variance} of the
%normal distribution corresponding to $p(x|y)$ can
%be derived by examining Equation \ref{tosimp} and likening
%it to Equation \ref{B} (which gives the contents of the
%exponential in the prior MVN distribution of $x$).
%
%Namely, the inverse of the new variance,
%which we'll denote as $\Sigma^F$ will be sandwiched in
%between $x'$ and $x$ in Equation \ref{tosimp}, just as it
%was sandwiched between $x'$ and $x$ in Equation \ref{B}.
%We use this fact, along with the
%the Woodbury matrix identity (stated in
%the appendix) to derive:
%\begin{align}
%    \Sigma^{F} &= \left( \Sigma^{-1} + G'R^{-1}G\right)^{-1}
%	\notag \\
%    \text{Woodbury Identity} \Rightarrow
%	\qquad &=  \Sigma - \Sigma G'(R
%	    + G\Sigma G')^{-1}
%	    G\Sigma
%	    \label{covar}
%\end{align}
%\paragraph{Mean}
%Next, we want to get the {mean} of the distribution of
%$p(x|y)$, which we'll denote by $\hat{x}^F$.  Again, once we
%take a second and compare Expression \ref{tosimp}
%to Expression \ref{B}, it's becomes clear from inspection
%that we must have
%\begin{equation}
%    \label{notobvious}
%    (\Sigma^{-1} \hat{x} + G'R^{-1}y)
%	= \left( \Sigma^{-1} + G'R^{-1}G\right) Z
%\end{equation}
%To see this,
%liken the lefthand side of Equation \ref{notobvious} (which
%itself comes from Expression \ref{tosimp}) to
%the result of the matrix multiplication $\Sigma^{-1}\hat{x}$ in
%Equation \ref{B}. To get the righthand side, use the fact
%that we \emph{know} the Equation \ref{notobvious} analogue
%to Equation \ref{B}'s $\Sigma^{-1}$, which we just
%derived in the variance section and called $\Sigma^F$.
%\\
%\\
%So all that's left to do is solve for $Z$ in Equation
%\ref{notobvious}.  The result will turn out to be our mean
%vector for the posterior, $\hat{x}_F$:
%\begin{align}
%    \label{mean}
%    \hat{x}^F = Z
%        &= \hat{x}
%        + \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
%        \left( y - G \hat{x} \right)
%\end{align}
%If you want to see the nasty linear algebra that gets you
%to this result, you can check out the appendix. Or you can
%you just take this result as given and save yourself an
%hour of painstaking derivation and eye-crossing complications,
%unlike myself.\footnote{But if you \emph{do} look at the appendix,
%you might just give my semi-wasted hour some meaning, in which
%case---thank you.}
%\\
%\\
%Putting together the expressions for the mean and variance
%(see Equations \ref{mean} and \ref{covar}, respectively)
%of the posterior estimate for $x|y$ (i.e. the ``filtering
%distribution''), we get that
%\begin{align}
%    x | y &\sim \text{N} \left(\hat{x}^F, \; \Sigma^F\right)
%    \label{filtered} \\
%    \notag\\
%    \text{where} \quad \hat{x}^F &= \hat{x}
%	+ \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
%	\left( y - G \hat{x} \right)  \notag \\
%    \Sigma^F &= \Sigma - \Sigma G'(R
%	    + G\Sigma G')^{-1}
%	    G\Sigma \notag
%\end{align}
%Notice that our new ``filtered'' mean is simply a
%combination of our prior mean, $\hat{x}$, and
%a transformation of the ``error'' between our
%observed value and the prior guess for that
%observable ($y - G\hat{x}$).
%
%\newpage
%\paragraph{Recap} Okay, so what did we just do?
%\begin{enumerate}
%    \item We took a Multivariate Normal (MVN) prior to
%	summarize our beliefs about a latent, imperfectly
%    observable state variable $x$.
%    \item Knowing that we'll observe some data, $y$, which
%	provides a ``noisy'' measure of $x$, we postulated a
%	likelihood $p(y|x)$ that is also MVN.
%    \item Then, using Bayes' Rule, we combine the information
%	contained in our prior $p(x)$ and the data (via
%	the likelihhod $p(y|x)$) to get a ``filtered''
%	distribution of $x$, $p(x|y)$, given the data and our
%	prior.
%\end{enumerate}
%Why might this long, tortuous, painful process help us in
%economics?  Well, imagine that in our model, there's some
%state for the ``natural rate of unemployment,'' denoted by $x$.
%Now of course, we can't observe that value.  But we'll have
%economic statistics, like measurements of unemployment itself along
%with other informative statistics such as GDP
%and hours, which might provide information about the natural
%rate of unemployment.
%However, those statistics are imperfect and noisy.  The
%Kalman Filter gives us a way to combine those noisy estimates
%in with our beliefs in a principled, sensible manner.
%
%
%\section{Forecasting Step}
%
%Now let's make our model a little more dynamic and consider
%forecasting ahead. To do so, we specify a model
%of how the state, $x$, evolves.  To make it easy on ourselves,
%let's assume everything's Gaussian (woohoo! that's easy):
%\begin{equation}
%    \label{lom}
%    x_{t+1} = Ax_t + w_{t+1} \qquad w_t \sim \text{N}(0, H)
%\end{equation}
%Now, we want to come up with a \emph{predictive distribution}
%given our prior and the current information encapsulated in
%our filtering distribution, $p(x|y)$. Since we're assuming
%everything is normal, we need only pin down the
%mean and variance of the forecast, since linear combinations
%of Gaussian variables are Gaussian.
%
%Of course, these kinds of things are well known for
%MVN random variables, which has the nice properties
%\begin{align*}
%    E[AX] &= A E[X] = A \mu \\
%    \text{Var}(AX) &= A \text{Var}(X) A' = A\Sigma A' \\
%    \text{where} \quad X &\sim \text{N}(\mu, \Sigma)
%\end{align*}
%Now let's use these facts, along with the assumption
%that we're predicting $x_{t+1}$ by starting with a
%\emph{filtered} $x_t$ (denoted $x^F_t$ which has the
%distribution in Equation \ref{filtered}), and
%assuming $x^F_t$ is uncorrelated with $w_{t+1}$:
%\begin{align}
%    E[x_{t+1}] &= E\left[A{x}^F_{t} + w_{t+1} \right]
%        = AE\left[{x}^F_{t}\right] + E\left[w_{t+1}
%            \right] \notag\\
%        &= A \hat{x}^F_{t} + 0 = A \hat{x}^{F}_t
%            \label{intfore_mean}\\
%    \text{Var}({x}_{t+1}) &=
%        \text{Var}(A{x}^F_{t} + w_{t+1})
%        = A\text{Var}\left({x}^F_{t}\right)A'
%            +\text{Var}(w_{t+1})\notag \\
%        &= A\Sigma^F_t A' + H \label{intfore_var}
%\end{align}
%where $\hat{x}^F_t$ and $\Sigma_t^F$ are as above in Equation
%\ref{filtered}. This characterizes the distribution for the
%one step ahead forecasting distribution.
%
%\newpage
%Now, we can simplify what we have a bit more by defining
%the \emph{Kalman Gain}:
%\begin{equation}
%    \label{kalgain}
%    K_\Sigma = A\Sigma G' (R + G\Sigma G')^{-1}
%\end{equation}
%We see the practical use of this by subbing in the full
%expressions for $\hat{x}_t^F$ and $\Sigma_t^F$ into Equations
%\ref{intfore_mean} and \ref{intfore_var} above,
%and then simplifying our expressions for the
%mean and variance as a function of the Kalman Gain:
%\begin{align}
%    \hat{x}_{t+1} &= E[x_{t+1}] =
%        A\left\{ \hat{x}_t
%	    + \left[\Sigma_t G' (R + G \Sigma_t G')^{-1}  \right]
%        \left( y - G \hat{x}_t \right) \right\} \notag \\
%        &= A\hat{x}_t + K_{\Sigma_t} (y - G \hat{x}_t)
%        \label{foremean} \\
%    \Sigma_{t+1} &= \text{Var}(x_{t+1}) =
%        A \left\{ \Sigma_t - \Sigma_t G'(R
%	    + G\Sigma_t G')^{-1}
%        G\Sigma_t \right\} A' + H \notag \\
%    &= A\Sigma_t A' - K_{\Sigma_t} G \Sigma_t A' + H
%        \label{forevar}
%\end{align}
%
%
%\section{Full Recursive Procedure}
%
%Now we need to build up the recursive algorithm to forecast
%further into the future. Let $t$ be the current time period,
%and we proceed as follows:
%\begin{enumerate}
%    \item Start with a prior in the current period at
%        time $t$, as given above
%        \[ p_{t}(x) \sim \text{N}\left(\hat{x}_t, \;
%            \Sigma_t\right) \]
%    \item Observe the current measurement, $y_t$.
%    \item Update and filter out the noise as we did in
%        the Filtering Section to get, you guessed it,
%        the filtering distribution: $p_t(x | y) =
%        \text{N}(\hat{x}^F_t, \Sigma^F_t)$.
%    \item Compute the predictive distribution
%        $p_{t+1}(x) = \text{N}(\hat{x}_{t+1}, \Sigma_{t+1})$
%        from the filtering distribution, $p_t(x|y)$, and
%        the law of motion in Equation \ref{lom}.
%    \item Increment $t$. Return to step 1, taking
%        the predictive distribution, $p_{t+1}(x)$, as
%        the prior.
%\end{enumerate}
%
%
%\section{Convergence}
%
%Now since $x_{t}$ is random from the perspective
%of time $t-1$ (i.e. there is some irreducable uncertainty
%resulting from shocks at time $t$), we know that $\Sigma_t$
%will never be zero, unless $w_t$ in Equation \ref{lom} is
%degenerate. However, we might ask whether $\Sigma_t$, our
%measure of uncertainty for our prediction $\hat{x}_t$
%of $x_t$, will ever converge to a \emph{constant} matrix over
%time.
%
%Recall how $\Sigma_t$ evolves, as specified in Equation
%\ref{forevar} (substituting in for the Kalman Gain,
%$K_\Sigma$), which gives the non-linear difference equation:
%\begin{equation}
%    \label{sig_euler}
%    \Sigma_{t+1} = A\Sigma_t A' - K_{\Sigma_t} G \Sigma_t A' + H
%\end{equation}
%If it were the case that $\Sigma_t$ converges to some fixed
%matrix, then there would be a fixed point, $\Sigma^*$, satisfying
%Equation \ref{sig_euler} as follows:
%\begin{equation}
%    \label{riccati}
%    \Sigma^* =
%        A\Sigma^* A' - A\Sigma^* G' (R + G\Sigma^* G')^{-1} G \Sigma^* A' + H
%\end{equation}
%This is known as the \emph{Discrete Time Algebraic Riccati Equation}.
%A sufficient condition for convergence is that all the eigenvalues of
%$A$, $\lambda_i$, satisfy $|\lambda_i|<1$.
%


\clearpage
\section{Just the Equations}

Bare bones section that just collects equations in one place. Assumes
linear state space models of form
\begin{align}
  \text{Transition:} \quad
    s_{t} &= C(\theta) + T(\theta) s_{t-1}
    + R(\theta)\varepsilon_{t}\
    \quad \mathbb{E}[\varepsilon_t] = 0
    \quad \mathbb{E}[\varepsilon_t \varepsilon'_t] =  Q(\theta) \\
  \text{Measurement:} \quad
    y_{t} &= D(\theta) + M(\theta) s_{t} + \eta_{t}
    \qquad\qquad \mathbb{E}[\eta_t] =  0
    \quad \mathbb{E}[\eta_t \eta'_t] =  H(\theta)
\end{align}


\subsection{Kalman Filter under Normal Errors}

Forecast step, given $\mu_{t|t-1}$ and $\Sigma_{t|t-1}$:
\begin{alignat*}{3}
  \mu_{t|t-1} &= C + T\mu_{t-1|t-1} \\
  \Sigma_{t|t-1} &= T\Sigma_{t-1|t-1}T' + RQR'
\end{alignat*}
Filtering step:
\begin{alignat}{3}
  \mu_{t|t}
    &= \mu_{t|t-1} + \Sigma_{t|t-1} M'
    \left(M\Sigma_{t|t-1}M' + H\right)^{-1} (y_t-D-M\mu_{t|t-1}) \notag\\
  \Sigma_{t|t}
    &= \Sigma_{t|t-1} - \Sigma_{t|t-1}M'
    \left(M\Sigma_{t|t-1}M' + H\right)^{-1} M\Sigma_{t|t-1} \notag
\end{alignat}


%%%%% APPPENDIX %%%%%%%%%%%
%
\clearpage
\appendix


\section{Conditional Distributions with Normal Errors}
\label{sec:mvncond}

Suppose that there is a multivariate normal random variable $Z$---a
vector that can be partitioned into two pieces and written
\[
  Z \sim N(\mu, \Sigma) \quad\Leftrightarrow\quad
  \begin{bmatrix} Y \\ X \end{bmatrix}
  \sim
  N\left(\begin{bmatrix} \mu_Y \\ \mu_X \end{bmatrix},
  \begin{bmatrix} \Sigma_{YY} & \Sigma_{YX} \\
  \Sigma_{XY} & \Sigma_{XX} \end{bmatrix}
  \right)
\]
Then the distribution of $Y$ given $X$ is
\begin{align}
  Y | X \sim &N(\hat{\mu}, \hat{\Sigma})  \notag\\
  \label{reg} \\
  \text{where} \quad
  \hat{\mu} = \mu_Y + \Sigma_{YX} \Sigma^{-1}_{XX}
  (X_X-\mu_X)  & \quad \quad
  \hat{\Sigma} = \Sigma_{YY} - \Sigma_{YX} \Sigma^{-1}_{XX}
    \Sigma_{XY}
  \notag
\end{align}

\paragraph{Intuition}
Consider the case where $Y$ and $X$ are scalars, not vectors. Then we
see in the second term of the sum for $\hat{\mu}$ that an above-average
realization of $X$ will lead us to \emph{upwardly} revise a purely
unconditional forecast of $Y$ above the mean $\mu_Y$ (provided
$\Sigma_{YX}>0$, otherwise we revise down).

In addition, provided that the correlation $\Sigma_{YX} = \Sigma_{XY}$
is non-zero, we will revise \emph{down} the variance of $Y$ relative to
the baseline of $\Sigma_{YY}$. This follows because the observation of
$X$ has provided valuable information about $X$.


\paragraph{The Normality Assumption}
Consider your basic regression with
\begin{align}
  \label{regex}
  Y_i = \alpha + \beta X_i + \varepsilon_t
\end{align}
In Intro Stat, any discussion of regression analysis starts by assuming
that the errors, $\varepsilon_t$, are normally distributed, which is
equivalent to assuming that $Y_i$ and the regressors in $X_i$ are,
together, jointly normally distributed---i.e.  $\begin{bmatrix} Y_i &
  X^T_i \end{bmatrix}^T$ is  multivariate normal.

Then, if you get to intermediate Stat, your professor starts to retreat
on the normality assumptions. In particular, you learn that it doesn't
have to be the case that the variables are, in fact, jointly normally
distributed. It could just be that you want the best \emph{linear
predictor} of $Y_i$ given $X_i$. In that case, you care about regression
estimates only because they provide the best linear approximation of the
conditional expectation function, $E[Y_i|X_i]$. Alternatively, you might
also hear that linear regression gives the best linear ``projection'' of
$Y_i$ onto $X_i$.

Well, that's our ticket. If you look at Result~\ref{reg}, you'll notice
that we're getting a kind of \emph{regression estimate} of $Y$ given
$X$. To be even more explicit, we might write
\[
  E[Y|X] = \mu_Y + \beta (X - \mu_X)
\]
where $\beta= \Sigma_{YX}\Sigma^{-1}_{XX}$. This is just like
Regression~\ref{regex} above, only here, we regress \emph{vector} (not
scalar) $Y$ on vector $X$. However, the intuition remains the same.

Therefore, Kalman Filter estimates that assume normally distributed
errors are not as nefarious as they seem. Since Kalman Filter estimates
of the states under the normality assumption will follow directly from
Result~\ref{reg} above (as we will see in the next subsection), we can
motive the Kalman Filter with normal errors by framing it as a recursive
procedure to find the best \emph{linear estimates} or \emph{projection
estimates} of the states.



\section{Woodbury Matrix Identity}

For matrices $A$, $U$, $C$, and $V$:
\begin{equation}
    (A+UCV)^{-1} = A^{-1} - A^{-1} U(C^{-1} + VA^{-1}U)^{-1}
	VA^{-1}
\end{equation}
Now consider the special case we have above with the
Kalman filter:
\begin{equation}
    \label{special}
    (A + V'CV)^{-1} = A^{-1} - A^{-1} V'(C^{-1} + VA^{-1}V')^{-1}
	VA^{-1}
\end{equation}

\section{Derivation of the Mean}

Recall what we want to show.  For $\hat{x}_F \equiv Z$, we want
to show that
\begin{align*}
    (\Sigma^{-1} \hat{x} + G'R^{-1}y)
	&= \left( \Sigma^{-1} + G'R^{-1}G\right) Z \\
    \Rightarrow
    \hat{x}_F = Z
        &= \hat{x}
        + \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
        \left( y - G \hat{x} \right)
\end{align*}
And so we solve this equation by using the Woodbury matrix
identity representation from above:
\begin{align*}
    (\Sigma^{-1} \hat{x} + G'R^{-1}y) &=
	\left( \Sigma^{-1} + G'R^{-1}G\right) Z \\
    \Rightarrow \quad Z &=
	\left( \Sigma^{-1} + G'R^{-1}G\right)^{-1}
	(\Sigma^{-1} \hat{x} + G'R^{-1}y) \\
    Z &=
	\left( \Sigma - \Sigma G'(R
	+ G\Sigma G')^{-1}
	G\Sigma\right) \left(\Sigma^{-1} \hat{x}
	+ G'R^{-1}y\right)
\end{align*}
Now let's simplify $\hat{x}_F = Z$ a bit,
expanding out the multiplication:
\begin{align*}
    \hat{x}_F = Z &=
	\left( \Sigma - \Sigma G'(R
	+ G\Sigma G')^{-1}
	G\Sigma\right) \left(\Sigma^{-1} \hat{x}
	+ G'R^{-1}y\right) \\
    \text{FOIL} \quad &= \hat{x} + \Sigma G' R^{-1} y -
	\left[\Sigma G' (R + G \Sigma G')^{-1} G \Sigma\right]
	\left[ \Sigma^{-1} \hat{x} \right]  \\
    &\qquad - \left[\Sigma G' (R+ G \Sigma G')^{-1}G\Sigma \right]
	\left[G' R^{-1} y \right] \\
    \text{Simpify} \quad &= \hat{x} + \Sigma G' R^{-1} y -
	\left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
	\left( G \hat{x} \right)  \\
    &\qquad - \Sigma G' (R+ G \Sigma G')^{-1}G\Sigma
	G' R^{-1} y  \\
    \text{Change Order} \quad &= \hat{x}
	- \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
	\left( G \hat{x} \right)  \\
    &\qquad
	+ \Sigma G'  R^{-1} y
	- \Sigma G' (R+ G \Sigma G')^{-1}G\Sigma
	G' R^{-1} y \\
    \text{Regroup} \quad &= \hat{x}
	- \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
	\left( G \hat{x} \right)  \\
    &\qquad
	+ \Sigma G'  \left\{ R^{-1}
	-  (R+ G \Sigma G')^{-1}G\Sigma
	G' R^{-1} \right\} y
\end{align*}
Okay, now let's take a breather.  We'll make this a bit
easier on ourselves, and just consider simplifying the guy
in the brackets, $\{\}$ by using
$A^{-1} A = I$ with a very special choice of $A$:
\begin{align*}
    \left\{ R^{-1}  -  (R+ G \Sigma G')^{-1}G\Sigma
	G' R^{-1} \right\}   &=
	(R+ G \Sigma G')^{-1} (R+ G \Sigma G') R^{-1}  \\
    &\qquad -  (R+ G \Sigma G')^{-1}G\Sigma
	G' R^{-1} \\
    \text{Group} \quad &=   (R+ G \Sigma G')^{-1} \left[ (R+ G \Sigma G') R^{-1}
	-  G\Sigma   G' R^{-1}\right] \\
    \text{Distribute} \quad &=   (R+ G \Sigma G')^{-1} \left[ RR^{-1}
	+ G \Sigma G'R^{-1} -  G\Sigma   G' R^{-1}\right] \\
    \text{Simplify} \quad &=   (R+ G \Sigma G')^{-1} \left[ I
	+ 0\right] \\
    &=   (R+ G \Sigma G')^{-1}
\end{align*}
Substituting back in above for the term in braces,
$\{\}$, we get the following expression
for $Z = \hat{x}_F$:
\begin{align}
    \hat{x}_F = Z &= \hat{x}
	- \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
	\left( G \hat{x} \right)
	+ \Sigma G'  (R+ G \Sigma G')^{-1} y \notag \\
    &= \hat{x}
	+ \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
	\left( y - G \hat{x} \right)
\end{align}

\end{document}



%%%% INCLUDING FIGURES %%%%%%%%%%%%%%%%%%%%%%%%%%%%

   % H indicates here
   %\begin{figure}[h!]
   %   \centering
   %   \includegraphics[scale=1]{file.pdf}
   %\end{figure}

%   \begin{figure}[h!]
%      \centering
%      \mbox{
%	 \subfigure{
%	    \includegraphics[scale=1]{file1.pdf}
%	 }\quad
%	 \subfigure{
%	    \includegraphics[scale=1]{file2.pdf}
%	 }
%      }
%   \end{figure}


%%%%% Including Code %%%%%%%%%%%%%%%%%%%%%5
% \verbatiminput{file.ext}    % Includes verbatim text from the file
% \texttt{text}	  % includes text in courier, or code-like, font
