\documentclass[12pt]{article}

\author{Matthew D. Cocci}
\title{Applied Stochastic Analysis}
\date{\today}

%% Formatting & Spacing %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry} % most detailed page formatting control
\usepackage{fullpage} % Simpler than using the geometry package; std effect
\usepackage{setspace}
%\onehalfspacing
\usepackage{microtype}


%% Header %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage{fancyhdr}
%\pagestyle{fancy}
%\lhead{}
%\rhead{}
%\chead{}
%\setlength{\headheight}{15.2pt}
    %---Make the header bigger to avoid overlap

%\renewcommand{\headrulewidth}{0.3pt}
    %---Width of the line

%\setlength{\headsep}{0.2in}
    %---Distance from line to text


%% Mathematics Related %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{amsthm} %allows for labeling of theorems
\usepackage{accents}
\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{ex}[thm]{Example}

\theoremstyle{remark}
\newtheorem*{rmk}{Remark}
\newtheorem*{note}{Note}

% Below supports left-right alignment in matrices so the negative
% signs don't look bad
\makeatletter
\renewcommand*\env@matrix[1][c]{\hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{*\c@MaxMatrixCols #1}}
\makeatother


%% Font Choices %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
%\usepackage{blindtext}


%% Figures %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{graphicx}
\usepackage{subfigure}
    %---For plotting multiple figures at once
%\graphicspath{ {Directory/} }
    %---Set a directory for where to look for figures


%% Hyperlinks %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{hyperref}
\hypersetup{
    colorlinks,
        %---This colors the links themselves, not boxes
    citecolor=black,
        %---Everything here and below changes link colors
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

%% Including Code %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{verbatim}
    %---For including verbatim code from files, no colors

\usepackage{listings}
\usepackage{color}
\definecolor{mygreen}{RGB}{28,172,0}
\definecolor{mylilas}{RGB}{170,55,241}
\newcommand{\matlabcode}[1]{%
    \lstset{language=Matlab,%
        basicstyle=\footnotesize,%
        breaklines=true,%
        morekeywords={matlab2tikz},%
        keywordstyle=\color{blue},%
        morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},%
        identifierstyle=\color{black},%
        stringstyle=\color{mylilas},%
        commentstyle=\color{mygreen},%
        showstringspaces=false,%
            %---Without this there will be a symbol in
            %---the places where there is a space
        numbers=left,%
        numberstyle={\tiny \color{black}},%
            %---Size of the numbers
        numbersep=9pt,%
            %---Defines how far the numbers are from the text
        emph=[1]{for,end,break,switch,case},emphstyle=[1]\color{red},%
            %---Some words to emphasise
    }%
    \lstinputlisting{#1}
}
    %---For including Matlab code from .m file with colors,
    %---line numbering, etc.

%% Bibliographies %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage{natbib}
    %---For bibliographies
%\setlength{\bibsep}{3pt} % Set how far apart bibentries are

%% Misc %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{enumitem}
    %---Has to do with enumeration
\usepackage{appendix}
\usepackage{pdfpages}
    %---For including whole pdf pages as a page in doc


%% User Defined %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newcommand{\nameofcmd}{Text to display}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BODY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}
\maketitle

\tableofcontents

\clearpage
\section{Week 1: Probability Review}

\subsection{Elements of Probability Theory}

\begin{defn}
The \emph{sample space} $\Omega$ is the set of all elementary outcomes
of some statistical experiment.
\end{defn}
\begin{rmk}
The definition of an ``elementary outcome'' is rather loose and heavily
depedendent upon what you define the ``experiment'' to be. For example,
if you define the experiment to be a single coin toss, then the
elementary outcomes are heads (H) and tails (T), implying $\Omega =
\{H,T\}$. However, you could also define an experiement to be tossing
$N$ coins or tossing a coin $N$ times, in which case the elementary
outcomes are $N$-tuples with each element in $\{H,T\}$.
\end{rmk}



\begin{enumerate}
  \item Pavliotis Appendix B, p 303-319; Skip B.5.1 and B.4 is optional
  \item Lecture notes 1, 2 from 2014
  \item Homework 1,2 and Solutions from 2014
  \item Appendix A.4 from Durrett
  \item K \& S Ch 1-3 p 37
\end{enumerate}

\section{Markov Chains}

\subsection{References}
\begin{enumerate}
  \item Koralev and Sinai Ch 5.1-5.5
\end{enumerate}

\subsection{Discrete Time, Discrete Space}

\begin{defn}
The process $\{X_n\}$ is a \emph{discrete time, discrete space Markov
chain} if it satisfies the \emph{Markov Property}:
\begin{align*}
  P(X_n = x_n | X_{n-1}=x_{n-1}, \ldots, X_0 =x_0)
\end{align*}
In words, the distribution for $X_{n+1}$ only depends upon its state at
time $n$. All history prior to time $n$ is Duncan-Hines irrelevant.
We can define the evolution of the states and probabilities of a Markov
Chain in terms of transition matrix.
\end{defn}
\begin{rmk}
I will denote discrete-time Markov Chains by $\{X_n\}$ rather than
$\{X_t\}$ to suggest via notation that the time domain is $\mathbb{N}$,
not $\mathbb{R}$.
\end{rmk}

\begin{defn}
A \emph{stochastic matrix} $P=(p_{ij})_{n\times n}$ is a matrix the sum
of each row (across columns) equals 1, i.e.
\begin{align*}
  \forall j \qquad \sum_j p_{ij} = 1
\end{align*}
\end{defn}

\begin{defn}
A \emph{transition matrix} $P(n)$ is a non-negative stochastic matrix
where entry $p(n)_{ij}$ denotes the probability of transitioning from
state $i$ to state $j$ from time $n$ to $n+1$:
\begin{align*}
  p(n)_{ij} = P(X_{n+1}=j | X_n=i)
\end{align*}
It is clear that $P(n)$ must be a stochastic matrix, because by summing
across columns, we're summing across the states $X_n$ could move to.
Since it has to move somewhere and probabilities sum to 1, the row-sums
of $P(n)$ must equal 1. Combining this with the non-negativity of
probabilities, our two conditions for a transition matrix are:
\begin{enumerate}
  \item $p(n)_{ij}>0$ for all $i,j$.
  \item $P(n)$ is stochastic.
\end{enumerate}
\end{defn}

\begin{defn}
The process $\{X_n\}$ is a \emph{homogenous Markov Chain} if
\begin{align*}
  P(n) = P(m) \qquad \forall m,n\geq 0
\end{align*}
In words, transition probabilities do not depend upon the time of
transition. In these cases, we drop time from the notation so that
$P(n)$ becomes $P$ and $p_{ij}(n)$ becomes $p_{ij}$.
\end{defn}

\begin{rmk}
From here on, we will exclusively work with homogeneous Markov Chains.
\end{rmk}

\begin{thm}{\emph{(Chapman-Komogorov Equation)}}
For a homogeneous Markov Chain, we can compute $m$ step ahead transition
probabilities as follows:
\begin{align*}
  P(X_{n+m}=j | X_{n}=i) = \sum_k P(X_{n+m}=j| X_\ell=k)
    P(X_\ell = k| X_n=i)
  \qquad
  n \leq \ell \leq n+m
\end{align*}
In words, break the probability of moving from $i$ to $j$ in $m$ steps
into a smaller problem: $i$ to $m$ then $m$ to $i$ for some intermediate
step $m$.
\end{thm}

\begin{thm}{\emph{(Forward Kolmorogov Equation)}}
This relationship tells us how to evolve distributions. In particular,
if $X_n\sim \mu^{(n)}$ where $\mu^{(n)}$ is a row vector or
probabilities summing to 1, then $\mu^{(n+1)}$, the distribution of
$X_{n+1}$ can be computed
\begin{align*}
  \mu^{(n+1)} = \mu^{(n)} P
\end{align*}
\end{thm}

\begin{thm}{\emph{(Backward Komogorov Equation)}}
This theorem tells us how to evolve moments and expected values. In
particular, for a function $f$ and Markov chain $\{X_n\}$ taking on any
of $m$ possible values, define column vector
\begin{align*}
  u_n =
  \begin{pmatrix}
    u^{(1)}_n & \cdots & u^{(k)}_n & \cdots & u^{(m)}_n
  \end{pmatrix}'
  \quad\text{where}\quad
  u^{(k)}_n := \mathbb{E}[f(X_n)|X_0=k]
\end{align*}
Then we have that
\begin{align*}
  u_{n+1} = P u_n
\end{align*} \end{thm}
\begin{proof}
Law of Iterated Expectations:
\begin{align*}
  u_{n+1}^{(i)} &= \mathbb{E}[f(X_{n+1})|X_0=i]\\
  \text{By definition}\qquad
  &= \sum_j f(j) P(X_{n+1}=j |X_0=i)\\
  \text{Chapman-Komogorov}\qquad
  &= \sum_j f(j) \left(\sum_k P(X_{n+1}=j |X_1 = k) P(X_1=k|X_0=i)\right)\\
  &= \sum_k \left(\sum_j f(j) P(X_{n+1}=j |X_1 = k)\right) P(X_1=k|X_0=i)\\
  \text{By Homogeneity}\qquad
  &= \sum_k \left(\sum_j f(j) P(X_{n}=j |X_0 = k)\right) P(X_1=k|X_0=i)\\
  &= \sum_k \mathbb{E}[f(X_n)|X_0=k] \cdot P(X_1=k|X_0=i)\\
  &= \sum_k u^{(k)}_n \cdot P(X_1=k|X_0=i)\\
  &= P_{i,\cdot} u_n
\end{align*}
where $P_{i,\cdot}$ denotes the $i$th row. Stacking this result across
the $i$, we get $u_{n+1}=Pu_n$.
\end{proof}

\begin{thm}{\emph{(Alternative Backward Komogorov Equation)}}
For a function $f$, Markov chain $\{X_n\}$, and fixed time $N\geq n$,
define column vector
\begin{align*}
  v_n =
  \begin{pmatrix}
    v^{(1)}_n & \cdots & v^{(k)}_n & \cdots & v^{(m)}_n
  \end{pmatrix}'
  \quad\text{where}\quad
  v^{(k)}_n := \mathbb{E}[f(X_N)|X_n=k]
\end{align*}
Then we have that
\begin{align*}
  u_{n+1} = P u_n
\end{align*}
\end{thm}

\begin{rmk}
In both formulations of the Backward Equation, we have functions of time
and of a starting point, $u^{(k)}_n$ and $v^{(k)}_n$. However, for $u$,
the starting time is fixed, while we can vary the time \emph{from} or
\emph{after} the starting point. On the other hand, for $v$, the ending
time is fixed and $v$ varies as function of some time \emph{before} or
\emph{until} that terminal time. It is, therefore, from $v$ that the
name ``Backward Equation'' arises, as we can solve \emph{backwards}
moments and functions of the state prior to some terminal time.
\end{rmk}

\subsection{Continuous Time, Discrete Space}

\begin{defn}
The process $X=\{X_t\}_{t\geq 0}$ is a \emph{continuous time, discrete
space Markov Chain} if $X$ takes on only a discrete set of values in a finite or countable state space $S$ and if
\begin{align*}
  P(X_{t_n} = i_{n} | X_{t_{n-1}} = i_{n-1}, \ldots X_{t_1} = i_{1})
  =
  P(X_{t_n} = i_{n} | X_{t_{n-1}} = i_{n-1})
\end{align*}
for all states $i_1,\ldots,i_n\in S$ and times $t_1<\cdots<t_n$.
\end{defn}

Now that time isn't neatly divide into discrete intervals, we can't
define a transition matrix since there's not necessarily a standard unit
of time between jumps. There are then two approaches:
\begin{enumerate}
  \item Consider the \emph{generator} $Q$, which is like an limit of a
    transition as the time step goes to~0.
  \item Describe the distribution of jump times of $X_t$, defined as
    $\tau_1, \tau_2,\ldots$, and then treat $X_t$ like a discrete time
    Markov Chain jumping at these times.
\end{enumerate}

\begin{defn}{(Transition Probabilities in Cts. Time)}
For a continuous time, discrete space Markov Chain, the \emph{transition
probability} $p_{ij}(s,t)$ at time $s$ for time step $t$ is defined
\begin{align*}
  p_{ij}(s,t) = P(X_{t+s}=j|X_s=i)
\end{align*}
We can then collect these in a transition matrix $P(s,t) =
(p_{ij}(s,t))$. Note that $P(s,0) = I$ for all $s$.

If $X$ is a homogeneous Markov Chain, then we drop the argument $s$ and
simply have $p_{ij}(t)$, the probability of transitioning from $i$ to
$j$ in $t$ units of time. Similarly the matrix of transition
probabilities becomes simply $P(t)$.
\end{defn}

\begin{rmk}
Again, we'll consider only homogeneous Markov Chains from now on.
\end{rmk}

\begin{defn}{(Chapman-Kolmorogov)}
Similar to the discrete-time case, we have
\begin{align*}
  p_{ij}(t+s) = \sum_k p_{ik}(t) p_{kj}(s)
  \quad \Leftrightarrow \quad
  P(t+s) = P(t)P(s)
\end{align*}
\end{defn}

\section{Week 4: Stochastic Processes and Spectral Representation}

\begin{enumerate}
  \item Pavliotis 1.1, 1.2
  \item Koralev and Sinai, Ch 12, 15.3, 15.7, 16
\end{enumerate}

\subsection{Stationary Processes}

Strong stationarity imposes structure on the fdds. Weak stationarity
only imposes structure on the mean and covariance functions.

\subsection{Spectral Measure}

\begin{thm}\emph{(Bochner's Theorem)}
Suppose you have a covariance function $C(t)$ of a weakly stationary
stochastic process $X_t$ (weakly stationary implying that $C(t)$ is
positive semi-definite), then there exists a finite measure $F(\lambda)$
such that $C(t)$ can be represented as
\begin{align*}
  C(t) = \int_\mathbb{R} e^{i\lambda t} dF(\lambda)
\end{align*}
The measure $F$ is called the \emph{spectral measure} of $X(t)$.
\end{thm}

\begin{defn}
If the spectral measure $F$ is absolutely continuous w.r.t.\ the
Lebesgue measure on $\mathbb{R}$, then
\begin{align*}
  dF(\lambda) = S(\lambda)d\lambda
  \quad \Rightarrow\quad
  C(t)
    &= \int^\infty_{-\infty} e^{i\lambda t} S(\lambda) d\lambda \\
  \Leftrightarrow
  S(\lambda)
    &= \frac{1}{2\pi} \int^\infty_{-\infty} e^{-i\lambda t} C(t) dt
\end{align*}
Note that the function $S(\lambda)$ is non-negative. Moreover, if we
want to come up with covariance functions, we can just write down
spectral density functions $S(\lambda)$ then compute the Fourier
transform to recover the corresponding $C(t)$.
\end{defn}

\subsection{Spectral Representation}

We saw how to obtain the spectral measure for a \emph{covariance
function} of a weakly stationary process. Now we specify the spectral
representation of a stationary stochastic process \emph{itself}.

\begin{thm}\emph{(Spectral Theorem)}
Given a stationary mean-zero stochastic process $X_t$ with spectral
distribution function $F(\lambda)$, there exists a complex-valued
process $Z(\lambda)$ such that
\begin{align*}
  X_t = \int^\infty_{-\infty} e^{i\lambda t} dZ(\lambda)
\end{align*}
where $Z$ (call the \emph{spectral process}) has the following
properties:
\begin{enumerate}
  \item Orthogonal Increments: For disjoint intervals
    $[\lambda_1,\lambda_2]$ and $[\lambda_3,\lambda_4]$,
    \begin{align*}
      E\left[
        (Z(\lambda_2)-Z(\lambda_1))
        \overline{(Z(\lambda_4)-Z(\lambda_3))}
      \right] = 0
    \end{align*}
  \item Spectral Weight: For $\lambda_1\leq \lambda_2$,
    \begin{align*}
      E\left\lvert Z(\lambda_2)-Z(\lambda_1)\right\rvert^2
      = F(\lambda_2)-F(\lambda_2)
    \end{align*}
\end{enumerate}
\end{thm}
\begin{rmk}
This looks something like the Ito integral, except the measure of the
interval $[\lambda_1,\lambda_2]$ in the integral above is
$Z(\lambda_2)-Z(\lambda_1)$, not $W(\lambda_2)-W(\lambda_1)$.
\end{rmk}

\section{Week 5}

\section{Week 6}

\subsection{Generating Random Variables}

Suppose that we can generate $U([0,1])$ RV's. Then we can generate a
whole lot of other, more complex distributions with the methods in this
section.

\begin{thm}\emph{(Inverse Transform Method)}
Suppose that random variable $Y$ has some invertible cumulative
distribution $F_Y(y)$. Then if $X\sim U([0,1])$, the random variable
$Y = F^{-1}(X)$ will have cumulative distribution function $F_Y$.
\end{thm}

\begin{proof}
We can simply use definitions:
\begin{align*}
  P(Y\leq y) = P(F_Y^{-1}(X) \leq y) = P(X \leq F_Y(y)) = F_Y(y)
\end{align*}
\end{proof}

\begin{rmk}
Intuitively, we are choosing probabilities on $[0,1]$ by drawing $X\sim
U([0,1])$, i.e.\ we are choosing values in the range of $F_Y(y)$. We
then invert, using the fact that $F_Y$ is a one-to-one, to find the
corresponding draw $Y$ in the domain of $F_Y(y)$ that would have given
us $F_Y(y) = X$.

Though exceedingly straightforward, this procedure has the following
drawbacks: not all cdf's are easily invertible. In fact, most aren't.
Only uniform, exponential, Cauchy, Weibull, logistic, and discrete RV's
can use this approach.
\end{rmk}

\begin{thm}\emph{(Acceptance-Rejection)}
Suppose that we want to draw from $p(x)$. Let $g(x)$ be a any function
such that
\begin{enumerate}
  \item $0 \leq p(x) \leq g(x)$, i.e. $g$ ``covers'' $p$.
  \item $\int^\infty_{-\infty} g \; dx = M < \infty$.
  \item We have an analytic expression for $G^{-1}(x)$, where $G(x) =
    \int_{-\infty}^x g \; dx$.
\end{enumerate}
Then we can generate draws $X_i$ for an arbitrary pdf $p(x)$ using the
following algorithm:
\begin{enumerate}
  \item Draw $U_1\sim U([0,1])$
  \item Set a proposed draw $X'_i = G^{-1}(MU_1)$, where $M$ (as defined
    above) normalizes $g$ so that it is a proper probability
    distribution.
  \item Draw $U_2\sim U([0, g(X_i)])$.
  \item If $U_2 \leq p(X'_i)$, set $X_i = X'_i$ (i.e.\ accept $X'_i$).
    Otherwise, reject and try again.
\end{enumerate}
Proceed this way for $i=1,\ldots,N$.
\end{thm}
\begin{rmk}
Intuitively, we're drawing (via the inverse transform method) from the
distribution of $g(x)$ (properly normalized so it integrates to 1).
We're then only retaining those draws that fall under the curve of the
true distribution $p(x)$ so that the frequencies of draws match the
distribution of $p(x)$, not that of $g(x)$.
\end{rmk}

This works well for low deimsions, but in higher dimensions, rejection
sampling is actually pretty bad. Your covering $g(x)$ will leave a lot
of gaps between itself and the true distribution $p(x)$, especially at
the ``corners'', hence you will reject a lot. Instead, use MCMC methods.

\subsection{Monte Carlo Integration}

The general idea of Monte Carlo integration is to approximate the
integral by discretizing over a grid. However, the grid of points is
randomly chosen rather than deterministic and evenly spaced.

Throughout this subsection, we will want to compute something like the
following:
\begin{equation}
  I(f) = \int^b_a f(x) \; dx
  \label{mcint}
\end{equation}
In small dimensions (like Expression~\ref{mcint} above), grid
approximations work. In higher dimensions, The best approach will be
Monte Carlo integration.

\begin{thm}
Suppose we would like to approximate Expression~\ref{mcint}. We can do so by drawing $X_i \sim U[a,b]$ for $i=1,\ldots,N$ (large) and computing
\begin{align}
  \label{mcintapprox}
  \hat{I}(f) = \frac{1}{N} \sum^N_1 f(X_i)
\end{align}
In higher dimensions, we simply draw $X_i \sim U^d(D)$ where $d$ is the
number of dimensions and $D$ is the domain. The variance of the error is
\begin{align*}
  E[\hat{I}(f) - I(f)]^2
  &= E\left[ \left( \frac{1}{N}\sum^N_{i=1} f(X_i) \right)-I(f)\right]^2\\
  &= \frac{1}{N^2}E\left[ \sum^N_{i=1} \left(f(X_i)-I(f)\right)\right]^2\\
  \text{Since the $X_i$ are iid} \qquad
  &= \frac{1}{N^2}\sum^N_{i=1} E\left[ f(X_i)-I(f)\right]^2\\
  &= \frac{1}{N^2}\sum^N_{i=1} E\left[ \left( f(X_i) \right)- I(f)\right]^2\\
\end{align*}
\end{thm}

Notice that we drew from a (possibly multi-dimensional) uniform
distribution in computing $\hat{I}(f)$ in~\ref{mcintapprox}. But in the
case where

\begin{thm}
\end{thm}

\clearpage
\section{Forward and Backward Equations}

In the sections above, we considered SDEs of the form
\begin{align*}
  dX_t = b(X_t,t) dt + \sigma(X_t,t) dW_t
\end{align*}
We then tried to solve these to find expressions for the \emph{paths} of $X_t$ as a function of time and Brownian motion paths as follows:
\begin{align*}
  X_t = f(t,W_t)
\end{align*}
In this section, we try another approach. Here, we try instead to
describe the evolution of the probability distribution of $X_t$ and of
functions or moments of $X_t$ using PDE methods. Since $X_t$ is Markov
(by the fact that it solves the above SDE with particular smoothness and
growth conditions on $b$ and $\sigma$), we will often deal with the
transition density:
\begin{align*}
  p(x,t|y,s) := P(X_t\in [x,x+dx) \; | \; X_s=y)
\end{align*}

\begin{defn}
Given a function $f\in C_c^\infty(\mathbb{R}^d)$ and a time-homogeneous
process (multi-dimensional) stochastic process $X_t$, define the
\emph{generator} of $X_t$
\begin{align*}
  (\mathscr{A}f)(x)=
  \lim_{t\rightarrow0} \frac{E[f(X_t)|X_0=x]-f(x)}{t}
  &= (\mathscr{L}f)(x)
\end{align*}
where $\mathscr{L}$ is the linear operator
\begin{align*}
  \mathscr{L}f &= b \cdot \nabla f
  + \frac{1}{2} \left(\sigma \sigma^T:\nabla^2 f\right)\\
  \Leftrightarrow \qquad
  &= \sum_i b_i \frac{\partial f}{\partial x_i}
  + \frac{1}{2} \sum_i \sum_j \left(\sigma \sigma^T\right)
    \frac{\partial^2 f}{\partial x_i \partial x_j}
\end{align*}
where $\nabla^2 f$ is the Hessian matrix of $f$, and $A:B :=
\text{tr}(A^T B)$.
\end{defn}
\begin{proof}
The result follows directly from Ito's Lemma. Therefore apply
multi-dimensional Ito's Lemma to $f(X_t)$ for homogeneous process $X_t$:
\begin{align*}
  df(X_t) &=
  \left(b\cdot \nabla f + \frac{1}{2}\sigma\sigma^T : \nabla^2 f\right)
  dt
  + \nabla f\cdot \sigma \;dW_t\\
  f(X_t) - f(X_s) &=
  \int^t_s
  \left(b\cdot \nabla f + \frac{1}{2}\sigma\sigma^T : \nabla^2 f\right)
  d\tau
  +
  \int^t_s
  \nabla f\cdot \sigma \;dW_\tau
\end{align*}
Now take conditional expectation $E[\;\cdot\;|X_s=x]$ and use the fact
that the Ito Integral has expectation of zero:
\begin{align*}
  E[f(X_t)|f(X_s)=x] - f(x) &=
  E\left[
  \int^t_s
  \left(b\cdot \nabla f + \frac{1}{2}\sigma\sigma^T : \nabla^2 f\right)
  d\tau
  |f(X_s)=x\right]\\
  &\qquad
  +
  E\left[
  \int^t_s
  \nabla f\cdot \sigma \;dW_\tau
  |f(X_s)=x\right]
  \\
  &=
  E\left[ \int^t_s (\mathscr{L} f)(X_\tau) d\tau \;\big|\:f(X_s)=x\right] + 0
\end{align*}
From there, we can compute the limit that defines the generator to get:
\begin{align*}
  (\mathscr{A}f)(x)
  &=\lim_{t\rightarrow0} \frac{E[f(X_t)\;|\;f(X_s)=x] - f(x)}{t}\\
  &=\lim_{t\rightarrow0} \frac{1}{t}
  E\left[ \int^t_s (\mathscr{L} f)(X_\tau) d\tau \; \big|\:f(X_s)=x\right]\\
  &=(\mathscr{L}f)(x)
\end{align*}
where the last step follows from the Dominated Convergence Theorem since
$f$ and all of its derivatives are bounded (K\&S p 323).
\end{proof}

\begin{thm}{(Forward Kolmogorov Equation and Fokker-Planck Equation)}
There are two formulations:
\begin{enumerate}
  \item The transition probability density $p(x,t|y,s)$ solves
    \begin{align*}
      \frac{\partial p}{\partial t} = \mathscr{L}^*_x p
      \qquad p(x,s|y,s) = \delta(x-y)
    \end{align*}
    where $\mathscr{L}^*$ is defined
    \begin{align*}
      \mathscr{L}^*f_x = -\nabla_x \cdot (b f)
      +\frac{1}{2}\nabla^2_x : (a f)
    \end{align*}
    This is the adjoint of $\mathscr{L}$ meaning that
    on the Hilbert Space with inner product
    $\langle\cdot,\cdot\rangle_{L^2}$,\footnote{%
      The inner product $\langle\cdot,\cdot\rangle_{L^2}$ is defined as
      \begin{align*}
        \langle f,g\rangle_{L^2}
        &= \int_X fg\;d\mu
      \end{align*}
    }
    we have that $\langle\mathscr{L}f,g\rangle_{L^2} =\langle
    f,\mathscr{L}^*g\rangle_{L^2}$

  \item If $\rho_0(x)$ is the initial probability desnity and
    $\rho(x,t)$ is the density at time $t$, then $\rho(x,t)$ solves
    \begin{align}
      \frac{\partial \rho}{\partial t} = \mathscr{L}^* \rho
      \qquad \text{where } \; \rho(x,0) = \rho_0(x)
      \label{fpeqn}
    \end{align}
\end{enumerate}
\end{thm}
\begin{proof}
We take each case separately:
\begin{enumerate}
  \item By Ito's Lemma and results we saw above, we can write:
    \begin{align*}
      E[f(X_t) \;|\; X_s=y] -f(y)
      &= E\left[\int^t_s (\mathscr{L}f(X_\tau) d\tau \;\big|\;
          f(X_s)=y\right]
    \end{align*}
    Writing the expectation out explicitly,
    \begin{align*}
      \int_{\mathbb{R}^d} f(x)p(x,t|y,s)\;dx  -f(y)
      &= \int_{\mathbb{R}^d} \int^t_s
        (\mathscr{L}f)(x) \cdot p(x,\tau|y,s)\; d\tau dx
    \end{align*}
    Differentiating both sides with respect to $t$,
    \begin{align*}
      \int_{\mathbb{R}^d} f(x) \frac{\partial p}{\partial t}\;dx
      &= \int_{\mathbb{R}^d}
        (\mathscr{L}f)(x) \cdot p\; dx
    \end{align*}
    And this holds for all test functions $f$, so $p$ is a weak
    solution.
\end{enumerate}
\end{proof}

\subsection{Probability Flux}

Let's write out the Fokker-Planck Equation (\ref{fpeqn}) as follows:
\begin{align*}
  \frac{\partial\rho}{\partial t}
  &= \nabla \cdot \left( -b\rho + \frac{1}{2}\nabla \cdot (a\rho)\right)\\
  \Leftrightarrow\qquad
  0&=
  \frac{\partial\rho}{\partial t}
  + \nabla \cdot \underaccent{\bar}{j}
  \qquad
  \text{where}\;
  \underaccent{\bar}{j} = b\rho - \frac{1}{2}\nabla\cdot(a\rho)
\end{align*}
This is a conservation law for $\rho$, showing that any increase in
probability must be counterbalanced by $\nabla \cdot
\underaccent{\bar}{j}$ and vice versa.

%% APPPENDIX %%

% \appendix






%% APPPENDIX %%

% \appendix




\end{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%% SAMPLE CODE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    %% BIBLIOGRAPHIES %%

        \cite{LabelInSourcesFile}  %Use in text; cites
        \citep{LabelInSourcesFile} %Use in text; cites in parens

        \nocite{LabelInSourceFile} % Includes in refs w/o specific citation
        \bibliographystyle{apalike}  % Or some other style

        % To ditch the ``References'' header
        \begingroup
        \renewcommand{\section}[2]{}
        \endgroup

        \bibliography{sources} % where sources.bib has all the citation info

    %% SPACING %%

        \vspace{1in}
        \hspace{1in}


    %% INCLUDING PDF PAGE %%

        \includepdf{file.pdf}


    %% INCLUDING CODE %%

        \verbatiminput{file.ext}
            %---Includes verbatim text from the file
        \texttt{text}
            %---Renders text in courier, or code-like, font

        \matlabcode{file.m}
            %---Includes Matlab code with colors and line numbers


    %% INCLUDING FIGURES %%

        % Basic Figure with size scaling
            \begin{figure}[h!]
               \centering
               \includegraphics[scale=1]{file.pdf}
            \end{figure}

        % Basic Figure with specific height
            \begin{figure}[h!]
               \centering
               \includegraphics[height=5in, width=5in]{file.pdf}
            \end{figure}

        % Figure with cropping, where the order for trimming is  L, B, R, T
            \begin{figure}
               \centering
               \includegraphics[trim={1cm, 1cm, 1cm, 1cm}, clip]{file.pdf}
            \end{figure}


        % Side by Side figures
            \begin{figure}[h!]
                \centering
                \mbox{\subfigure{
                    \includegraphics[scale=1]{file1.pdf}
                }\quad\subfigure{
                    \includegraphics[scale=1]{file2.pdf}
                }
                }
            \end{figure}


