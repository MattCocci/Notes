\documentclass[a4paper,12pt]{article}

\author{Matt Cocci}
\title{Stochastic Analysis}
\date{\today}

%% Formatting & Spacing %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry} % most detailed page formatting control
\usepackage{fullpage} % Simpler than using the geometry package; std effect
\usepackage{setspace}
%\onehalfspacing
\usepackage{microtype}

%% Formatting %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage[margin=1in]{geometry}
    %   Adjust the margins with geometry package
%\usepackage{pdflscape}
    %   Allows landscape pages
%\usepackage{layout}
    %   Allows plotting of picture of formatting



%% Header %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage{fancyhdr}
%\pagestyle{fancy}
%\lhead{}
%\rhead{}
%\chead{}
%\setlength{\headheight}{15.2pt}
    %   Make the header bigger to avoid overlap

%\fancyhf{}
    %   Erase header settings

%\renewcommand{\headrulewidth}{0.3pt}
    %   Width of the line

%\setlength{\headsep}{0.2in}
    %   Distance from line to text


%% Mathematics Related %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{amsthm} %allows for labeling of theorems
\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{ex}[thm]{Example}

\theoremstyle{remark}
\newtheorem*{rmk}{Remark}
\newtheorem*{note}{Note}

% Below supports left-right alignment in matrices so the negative
% signs don't look bad
\makeatletter
\renewcommand*\env@matrix[1][c]{\hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{*\c@MaxMatrixCols #1}}
\makeatother


%% Font Choices %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
%\usepackage{blindtext}


%% Figures %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{graphicx}
\usepackage{subfigure}
    %   For plotting multiple figures at once
%\graphicspath{ {Directory/} }
    %   Set a directory for where to look for figures


%% Hyperlinks %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{hyperref}
\hypersetup{
    colorlinks,
        %   This colors the links themselves, not boxes
    citecolor=black,
        %   Everything here and below changes link colors
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

%% Including Code %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{verbatim}
    %   For including verbatim code from files, no colors

\usepackage{listings}
\usepackage{color}
\definecolor{mygreen}{RGB}{28,172,0}
\definecolor{mylilas}{RGB}{170,55,241}
\newcommand{\matlabcode}[1]{%
    \lstset{language=Matlab,%
        basicstyle=\footnotesize,%
        breaklines=true,%
        morekeywords={matlab2tikz},%
        keywordstyle=\color{blue},%
        morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},%
        identifierstyle=\color{black},%
        stringstyle=\color{mylilas},%
        commentstyle=\color{mygreen},%
        showstringspaces=false,%
            %   Without this there will be a symbol in
            %   the places where there is a space
        numbers=left,%
        numberstyle={\tiny \color{black}},%
            %   Size of the numbers
        numbersep=9pt,%
            %   Defines how far the numbers are from the text
        emph=[1]{for,end,break,switch,case},emphstyle=[1]\color{red},%
            %   Some words to emphasise
    }%
    \lstinputlisting{#1}
}
    %   For including Matlab code from .m file with colors,
    %   line numbering, etc.

%% Bibliographies %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{natbib}
    %---For bibliographies
%\setlength{\bibsep}{3pt} % Set how far apart bibentries are

%% Misc %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{enumitem}
    %   Has to do with enumeration
\usepackage{appendix}
%\usepackage{natbib}
    %   For bibliographies
\usepackage{pdfpages}
    %   For including whole pdf pages as a page in doc


%% User Defined %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\newcommand{\nameofcmd}{Text to display}
\newcommand*{\Chi}{\mbox{\large$\chi$}} %big chi
    %   Bigger Chi



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BODY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}
\maketitle
\tableofcontents

\clearpage

\section{Introduction}

This document aims to bring together the elements of probability,
measure theory, and stochastic calculus useful for the anlysis of
stochastic process that have particular relevance in finance and
economics.

\section{Measure Theory Foundations}

\section{Probability with Measure Theory}

\begin{defn}
The \emph{sample space} $\Omega$ is the set of all \emph{elementary}
outcomes of some statistical experiment. For a given experiment, only
one $\omega \in \Omega$ can occur when we conduct and observe that
experiement.  So that if we know $\omega_0 \in \Omega$ happened, then no
other $\omega_i \in \Omega$ can have occured, where
$\omega_i\neq\omega_0$.
\end{defn}
\begin{rmk}
The definition of an ``elementary outcome'' is really loosely defined
and heavily depedendent upon what you define the ``experiment'' to be.
For example, if you define the experiment to be a single coin toss, then
the elementary outcomes are heads (H) and tails (T), implying $\Omega =
\{H,T\}$. However, you could also define an experiement to be tossing
$N$ coins or tossing a coin $N$ times, in which case the elementary
outcomes are $N$-tuples with each element in $\{H,T\}$.

It's really up to you, and in practice, it probably doesn't matter that
much, reason being we don't often have to work with elements $\omega\in
\Omega$. Rather, we often work with random variables (defined below)
that correspond \emph{directly} (one-for-one) to elements
$\omega\in\Omega$, but take on values in $\mathbb{R}$ so that we work
with something more familiar and less awkward.
\end{rmk}

\begin{defn}
For a given sample space, $\Omega$, we can define a $\sigma$-algebra
$\mathscr{F}$ on $\Omega$ that contains subsets of $\Omega$ called
\emph{events}. Taken together, the double $(\Omega,\mathscr{F})$ define
a measurable space that we can attach a probability measure to.
\end{defn}
\begin{rmk}
Because a $\sigma$-algebra is closed under countable unions,
interesections, and complements, it provides a natural way to think
about collections of elementary outcomes that we might care about. Said
another way, the definition of a $\sigma$-algebra results gives us
pretty much all of the sets we'd like to assign probabilities to.
\end{rmk}

\subsection{The Notion of a $\sigma$-algebra}

Next, we define a $\mathbf{\sigma}$-\textbf{algebra},
which I'll denote as
$\mathcal{F}$ to be a collection of subsets of the sample space, a
collection of events, which
exhibits the following properties:
\begin{itemize}
   \item[i.] $\Omega \in \mathcal{F}$ and $\emptyset \in \mathcal{F}$.
      Intuitively, it ensures something will happen.
   \item[ii.] If the set $B \subset \Omega$ is in $\mathcal{F}$,
      then so is it's complement, i.e. $\Omega \setminus B \in
      \mathcal{F}$.
   \item[iii.] Countable unions and intersections of elements of
      $\mathcal{F}$ are also in the $\mathcal{F}$.  Mathematically,
      \[ B_i \in \mathcal{F} \; \forall i \; \Rightarrow
	 \bigcup_{i=1}^{\infty} B_i \in \mathcal{F} \]
      \[ B_i \in \mathcal{F} \; \forall i \; \Rightarrow
	 \bigcap_{i=1}^{\infty} B_i \in \mathcal{F} \]
\end{itemize}
Any set $X \in \mathcal{F}$ is called a
\textbf{measurable set}.\footnote{Just as Topology is based on open
sets, which are members of some $\sigma$-algebra, so too is Measure
Theory baed on measurable sets which are members of some
$\sigma$-algebra.} Note by the way we defined a $\sigma$-algebra,
the measurable sets, or events, in $\mathcal{F}$ will fail to be
disjoint.



\subsection{Simplest Example}

For an even simpler example than die rolling of something that is
a perfectly valid $\sigma$-algebra, we
sometimes take the power set of $\Omega$---the collection of all
possible subsets of $\Omega$---to be our $\sigma$-algebra.  It will
surely satisfy the necessary properties, and it happens to be very easy
to denote.

\subsection{Big Picture}

One of the reasons why we employ two levels of complexity in having
\emph{both} a sample space, $\Omega$,
and a $\sigma$-algebra, $\mathcal{F}$, is that it allows us to
properly make sense of complements of sets.  Specifically, if $A \in
\mathcal{F}$ represents rolling a 1, it's a natural thing in
probability to want to talk about the chances of \emph{not} rolling
a 1---the complement of $A$. The preceding definitions make that a
little more tractable.

Specifically, if we try to talk about $A$'s complement, that only
makes sense if $\mathcal{F}$ is built upon the foundation of a
more ``meta'' set. \footnote{I use ``meta'' to avoid using a term
like ``higher'' or ``bigger'' because, typically, the $\sigma$-algebra
will be bigger than or at least as big as $\Omega$ in cardinality,
and I don't want to cause any confusion. And
in addition, I wanted to talk about using the word ``meta'' so that
I can reasonably call this footnote ``meta-meta.''}
For example, if we want to talk about
the complement, $A^C$, without specifying that ``meta'' set, we could
technically say that aliens landing on Earth tomorrow is in the
complement of $A$---for it's definately not the event where you
roll a 1. But it's not very relevant, and our upcoming definition of
probability would force us to attach a probability to this as
well---something not as easily quantified as rolling a die.

Therefore using a ``meta'' set, called the sample space $\Omega$
reduces the class of outcomes or events to what's relevant. We can
just specify $\Omega$ to be the outcomes from rolling a die, and we
rid ourselves of many headaches, additional considerations, and
inter-planetary considerations.

\subsection{Measure}

Once we have a $\sigma$-algebra, we can pair the sample space with it's
$\sigma$-algebra to form what's called a
\textbf{measurable space}, which is simply the ordered pair
$(\Omega, \mathcal{F})$.  From there, we can start assigning
probabilities to those elements in the $\sigma$-algebra which all have
some chance of occurring.  To do so, we will use a special
type of function, called a measure.

A \textbf{measure} is a function that maps sets into real numbers.
In our case, we will define a specific type of measure, a
\textbf{probability measure}, as a
function that has as it's domain a $\sigma$-algebra and maps measurable
sets in the $\sigma$-algebra into the
real line, subject to a few conditions. More precisely, it has the
following characteristics:
\begin{itemize}
   \item[i.] If $P$ is our probability measure and $\mathcal{F}$ is
      our $\sigma$-algebra, then
	 \[ P: \mathcal{F} \rightarrow \mathbb{R} \]
   \item[ii.] $ P(F) \in [0,1]$ for all measurable sets
      $F \in \mathcal{F}$. In addition, $P(\Omega) =1$.
   \item[iii.] Our probability measure satisfies the probability axioms.
      And if $F_i$ are all disjoint and members of the $\sigma$-algebra,
      then
	 \[ p( \cup F_i) = \sum P(F_i) \]
\end{itemize}

\paragraph{Definition} Now that we have our definition of a probability,
I just want to define a common term more precisely.  Specifically,
if a property is true \emph{except} for an event of probability 0,
then we say that property holds ``almost surely.''

\subsection{Probability Space}

So now we have a way of assigning probabilities to any arbitrary event in our measurable space, $(\Omega, \mathcal{F})$. If we
join the probability measure, $P$, to our measurable space, we obtain a proper \textbf{Probability Space}.  It is defined as
the ordered triplet
\[(\Omega, \mathcal{F}, P) \]

\subsection{Measurable Function and Random Variables}

One of the fundamental notions of probability is that of a random
variable; therefore, making the definition more rigorous
deserves some attention.

So let's start with the notion of a \textbf{measurable} function.
If $(\Omega_1, \mathcal{F}_1)$ and $(\Omega_2, \mathcal{F}_2)$ are two
measurable spaces then, a function
   \[ f: (\Omega_1, \mathcal{F}_1) \rightarrow (\Omega_2, \mathcal{F}_2)
      \]
is a measurable function if
   \[ f^{-1}(B) \in \mathcal{F}_1, \;\; \forall B \in\mathcal{F}_2 \]
In words, a function is measurable if the pre-image of an element in
the $\sigma$-algebra of the co-domain is in the
$\sigma$-algebra of the domain.  Simply, it preserves the structure
between two measurable spaces, sending measurable sets
in one measurable space to measurable sets in the other.

Turning to probability, suppose  that we have our probability space,
$(\Omega_1, \mathcal{F}_1, P)$, and another measurable space,
$(\Omega_2,\mathcal{F}_2)$.  Then an
$\mathbf{(\Omega_2, \mathcal{F}_2)}$\textbf{-valued random variable}
is a \emph{measurable function}
\[ X: (\Omega_1, \mathcal{F}_1) \rightarrow (\mathbb{R},
   \mathcal{F}_2) \]

Since $X$ is a measurable function, we know that
   \[ X^{-1}(B) \in \mathcal{F}_1, \;\; \forall B \in \mathcal{F}_2\]
in which case we say that $X$ is $\mathcal{F}_1$-measurable.
To clarify further
   \[ X^{-1}(B) = \left\{ \omega \in \Omega_1 | X(\omega)
      \in B \right\} \]

\paragraph{Note} Oftentimes, we'll just take the set
$\mathcal{F}_2$ to be some properly
defined $\sigma$-algebra on the real line, like the Borel Set
(defined below).

\subsection{Sigma Algebras Generated by Random Variables}

Above, we assumed that we knew the $\sigma$-algebra for
$\Omega_1$ already---that it was given. But we
could just as well \emph{generate} one from some random variable $X$,
and this generated $\sigma$-algebra could very well differ from
$\mathcal{F}_1$.

So let's assume that $X$ is a random variable
   \[X: (\Omega_1,\mathcal{F}_1) \rightarrow
      (\mathbb{R},\mathcal{F}_2).\]
Then the $\sigma$-algebra generated by $X$, denoted by $\sigma(X)$, is
defined as \emph{all} sets of the form
   \[ \sigma(X) := \{ \omega \in \Omega_1 | X(\omega) \in A \}, \;\;
      \forall \; A \subset \mathbb{R} \]
which can be written more compactly as
   \[\sigma(X)  = \{ X^{-1}(A) | A\subset \mathbb{R}  \} \]

\paragraph{Definition} Finally, if $\mathcal{G}$ is a
sub-$\sigma$-algebra of the set $\mathcal{F}$ defined above, then the
random variable $X$ is $\mathcal{G}$-measurable if
   \[ \sigma(X) \subset \mathcal{G} \]

Let's give a concrete example.  Suppose $\Omega$ consists of all the
possible combination of up and down moves in a binomial tree.  $X$ is
a random variable denoting stock price.  Then for a set of real numbers
representing the possible prices the stock could take on (this is
our $A \subset \mathbb{R}$), the set $\sigma(X)$ will be the sigma
algebra resulting from the set of all possible paths that that the
stock could have taken to get to those prices in $A$.

\subsection{Random Variables and Their Distributions}

A random variable is actually quite distinct from its distribution.  Recall that a Random Variable is just a mapping from the
sample space $\Omega$ into something more tractable, like the real line.  Therefore, we could discuss this mapping--the random variable--
without ever considering probabilities.

However, oftentimes we will want to discuss probabilities, but the sufficiently general definition of the random variable just given
offers a lot of flexibility.  So much, in fact, that a random variable could have more than one distribution, as we know occurs in
stock process which have traditional probabilities and also \emph{risk-neutral} probabilities (or \emph{pseudo-probabilities}).

So let's define a \textbf{distribution} as a measure that assigns probabilities to the real numbers that a random variable generates
(after being passed an element in the sample space).  The most natural distribution is the induced measure, $\mathcal{L}_X$ defined
as follows
\[ \mathcal{L}_X(A) := P \{ X \in A \}, \;\; A \subset \mathbb{R} \]

Let's unpack that. If $A$ is a subset of the real line, it the random variable may or may not take on values in that subset, so we want
a notion of probability.  Well, we can take the pre-image, $X^{-1}(A)$, and look at all those elements of the sample space that map to
$A \subset \mathbb{R}$ under the random variable $X$.  Then, once we have elements of the sample space, we can use our traditional notion
of the $\sigma$-algebra, $\mathcal{F}$, and the probability measure $P$ that are already defined on the probability space to assign
the probabilities.

Thus, we can associate probabilities with our random variable so long as there exists a distribution measure, like $\mathcal{L}_X$.
But recall that $\mathcal{L}_X$ was not unique.  It's simply a function to assign probabilities to values that the random variable can
take on.  We could consider other measures that also accomplish this, and that insight legitimizes the use of such things as
\emph{risk-neutral probabilities}.

\subsection{Lebesgue Measure and the Lebesgue Integral}

\subsection{Introduction}

The \textbf{Lebesgue Measure} is the standard way of assigning a measure to subsets of $n$-dimensional Euclidean space.  If we restrict
to $\mathbb{R}$, then the Lebesgue Measure of intervals is simply the length. But rather than consider all of $\mathbb{R}$, we'll
restrict further to \emph{Borel Sets}.

This will allow us to construct the \emph{Lebesgue Integral}, a generalization of the Riemann Integral.

\subsection{Borel Sets}

The \emph{Borel $\sigma$-algebra}, denoted $\mathcal{B}(\mathbb{R})$, is the smallest $\sigma$-algebra containing (and, in a sense,
generated by) all open intervals
in $\mathbb{R}$.

\paragraph{Examples} The following are a few samples of Borel Sets in $\mathcal{B}(\mathbb{R})$:
\begin{itemize}
   \item{Every open interval of the form $(a,b)$.}
   \item{The open rays $(a,+\infty)$ and $(-\infty,b)$.}
   \item{All unions of the form
	 \[ B_1 \cup B_2, \;\; B_1,B_2 \in \mathcal{B}(\mathbb{R}) \]
      }
   \item{All complements of sets in $\mathcal{B}(\mathbb{R})$, since it's a sigma algebra. Note that this implies all \emph{closed}
      intervals in $\mathbb{R}$ are Borel Sets as well, in addition to all half-open and half-closed intervals.}
   \item{All one point sets, $a\in\mathbb{R}$, as we see that it is in the intersection of other Borel Sets, implying inclusion in
	 $\mathcal{B}(\mathbb{R})$ since it's a $\sigma$-algebra
	 \[ \{a \} = \bigcap_{n=1}^{\infty} \left( a - \frac{1}{n}, a + \frac{1}{n} \right). \]
      }
   \item{The last item implies that all finite countable collections of points in $\mathbb{R}$ are Borel Sets too. Therefore, the set
      of all rational numbers is Borel since coutable, and the set of all irrational numbers is Borel since it's the complement of a
      set in the sigma algebra.}
\end{itemize}

However, it should be noted that not all sets of real numbers are Borel Sets.  In particular, any non-Borel set must be uncountable
(though the opposite is not ture, as shown above).

\subsection{Lebesgue Measure}

Let's start more generally and define a \emph{measure} on $(\mathbb{R},\mathcal{B}(\mathbb{R}))$ to be a function
\[ \mu: \mathcal{B} \rightarrow [0,\infty) \]
with the following properties
\begin{itemize}
   \item[i.]{$\mu(\emptyset) = \emptyset$.}
   \item[ii.]{If $A_1, A_2, \ldots$ are disjoing sets in $\mathcal{B}(\mathbb{R})$, then
	 \[ \mu\left(\bigcup_{k=1}^{\infty} A_k\right) =  \bigcup_{k=1}^{\infty} \mu(A_k). \]
      }
\end{itemize}

We define the \textbf{Lebesgue Measure} on $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ to the measure $\mu_0$ that assigns the measure of
each interval to be its length.

\subsection{Functions in This World}

Let $f$ be a function
\[ f: \mathbb{R} \rightarrow \mathbb{R}. \]
We say that $f$ is \textbf{Borel-Measurable} if
\[ A \in \mathcal{B}(\mathbb{R}) \Rightarrow f^{-1}(A) \in \mathcal{B}(\mathbb{R}). \]
Or equivalently, we could say that we want the $\sigma$-algebra generated by $f$ to be contained in $\mathcal{B}(\mathbb{R})$.

\subsection{The Lebesgue Integral}

Let $I$ be the \emph{indicator function}.  We define
\[ A := \{ x \in \mathbb{R}| I(x) =1 \} \]
to be the set \emph{indicated by I}.

The \textbf{Lebesgue Integral} of $I$ is defined
\[ \int_{\mathbb{R}} I d\mu_0 = \mu_0(A). \]


\section{Stochastic Processes}

Throughout this section, we will explore stochastic processes building
from the simple case of a discrete state space in discrete time to the
most general case of an infinite state in continuous time, relaxing constraints through the subsections.

However, before proceeding, I here lay down the most generaly
definitions for stochastic process, which will we restrict to special
cases later on.

\subsection{General Definitions}

\begin{defn}{\citep{pavliotis}}
Let $T$ be an ordered set, $(\Omega,\mathscr{F},\mathbb{P})$ be a
probability space where $\Omega$ is the sample space, and
$(E,\mathscr{G})$ be a measurable space.

A \emph{stochastic process} is a collection of random variables $X =
\{X_t | t\in T\}$ such that for each $t\in T$, $X_t:
(\Omega,\mathscr{F},\mathbb{P})\mapsto (E,\mathscr{G})$ is a random
variable taking on values in its state space $E$.
\end{defn}

\begin{rmk}
Though it might not be obvious at first, a stochastic process dependends
upon two arguments: some $\omega\in\Omega$ and some $t\in T$. Therefore
the following representations are equivalent: $X_t$, $X_t(\omega)$,
$X(t,\omega)$ where the notation used will depend upon context.

Therefore, we might first think about $X(t,\omega)$ fixing $\omega$ and
letting $t$ vary. This corresponds to choosing a realization $\omega$ of
some experiment and looking at the resulting \emph{trajectory} of the
process.

On the other hand, we might fix $t$ and think about the different values
that $X(t,\omega)$ might take on depending upon the trajectory that is
realized in some experiment.
\end{rmk}

\begin{defn}
A process $\{X_t\}$ satisfies the \emph{Markov Property} if the
\begin{align*}
\mathbb{P}\left(X_{s+t} | \{X_{s-\varepsilon}\}_{\forall\varepsilon>0}\right)
= \mathbb{P}\left(X_{s+t} | X_{s}\right)
\end{align*}
In other words, only the latest state $X_s$ matters for the future distribution of $X_t$

\end{defn}

\subsection{Discrete State Space, Discrete Time}

\begin{defn}
A \emph{discrete space, discrete time Markov chain} is a stochastic
process $\{X_{t_i}\}_{t_i\in T}$ for some finite or countable set $T$
that satisfies
\begin{equation}
  P(X_n = x_n | X_{n-1} = x_{n-1}, \ldots
  X_0 = x_0) = P(X_n = x_n | X_{n-1}=x_{n-1})
\end{equation}
In words, only the most recent state matters for the future.
\end{defn}

\subsection{Infinite State Space, Discrete Time}
\subsection{Infinite State Space, Continuous Time}

\section{Stochastic Differential Equations}

Ordinary differential equations allow us to naturally relate rates of
change for some function to time and the value of the function itself:
\begin{align*}
  \frac{dy(t)}{dt} = b(t,y(t))
\end{align*}
Now, we want to modify this to allow random noise to influence the
change in the value of some stochastic process:
\begin{align*}
  \frac{dX_t}{dt} = b(t,X_t) + \sigma(t,X_t) \xi_t
\end{align*}
where $\xi_t$ is some random variable representing ``noise.'' (Though
because of some mathematical technicalities, we can't really define
$\xi_t$ this way since it is like a derivative, but one that cannot
exist. So we'll need to move to a definition with integrals that can be
properly defined.)



\clearpage
\bibliographystyle{apalike}  % Or some other style
\bibliography{biblio} % where sources.bib has all the citation info





\end{document}
