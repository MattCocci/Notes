\documentclass[a4paper,12pt]{article}

\author{Matthew Cocci}
\title{Kalman Filter}
\date{\today}
\usepackage{enumitem} %Has to do with enumeration	
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm} %allows for labeling of theorems
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
%\usepackage{blindtext}
\usepackage{graphicx}
%\usepackage[hidelinks]{hyperref} % For internal/external linking. 
				 % [hidelinks] removes boxes
% \usepackage{url} % allows for url display, non-clickable
%\numberwithin{equation}{section} 
   % This labels the equations in relation to the sections 
      % rather than other equations
%\numberwithin{equation}{subsection} %This labels relative to subsections
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
%\setkomafont{disposition}{\normalfont\bfseries}
\usepackage{appendix}
\usepackage{fullpage}
\usepackage{subfigure} % For plotting multiple figures at once
\usepackage{verbatim} % for including verbatim code from a file
%\usepackage{natbib} % for bibliographies

\begin{document}
\maketitle

% \tableofcontents %adds it here

\section{Introduction}

State Space Models and the Kalman Filter together rank among those ``Hugely Important Things I Never Knew Existed'' following my undergrad education. 

They're hugely important because they embed as special cases many concepts in time series and dynamics. In fact, in such cases, you can almost always fall back on the toolkit developed here. It doesn't take much work to cast ARMA models, dynamic factor models, and other important concepts into state space model form, viewing those applications as special cases within the broader state space framework.

So the first portion will consist of describing state space models and, naturally, the very important concept of state space. The second portion will consider how the Kalman Filter can be applied to such models.

\section{State Space Models}

\subsection{Basic Building Blocks}

State space models describe how certain states evolve over time,\footnote{Hence, state space models capture the ``dynamics'' of a system.} where \emph{states} consist of observed and/or unobserved variables of interest. The evolution of these states are informed by series we can directly measure, called \emph{observables}.

The \emph{states} in our model (which we'll collect into a state vector) might include GDP growth, inflation, unemployment, an unobserved ``business cycle'' component driving the dynamics of many series, a synthetic index indicating investment prospects, or any number of objects that we want to quantify, model, and forecast. With our states, we then define the \emph{state space} as the set of all values our state vector can assume. In other words, it's the multi-dimensional space spanned by our state vector. 

To quantify and model the states, we use \emph{observables}---series we can directly measure and observe---to inform our estimates of the states, which we cannot always directly measure. So just to reiterate, the biggest distinction between states and observables: observables \emph{always} have a directly measurable series associated with them, while states might not.


\subsection{State Space Models in Two Equations}

State space models essentially reduce to two fundamental equations:
\begin{align}
  \text{State Transition Equation:} \quad
    s_{t} &= C + T s_{t-1} + \varepsilon_{t} \label{ste}\
    \quad\quad E[\varepsilon_t] = 0
    \quad E[\varepsilon_t \varepsilon'_t] =  R \\
  \text{Measurement Equation:} \quad
    y_{t} &= D + M s_{t} + \eta_{t} \label{moe}
    \quad\qquad E[\eta_t] =  0 
    \quad E[\eta_t \eta'_t] =  Q 
\end{align}
Additionally, it is also assumed that $\varepsilon_t$ and $\eta_t$ are uncorrelated, iid, and independent of past values. And while $\varepsilon_t$ and $\eta_t$ are typically assumed to be normal, we wrote them here in the more general (yet equally valid) represenetation above. Later on, we will discuss the extra subtetly that non-normal errors introduce into the interpretation.


\paragraph{State Transition Equation} Equation \ref{ste} describes how the state vector, $s_t$, evolves over time; it's a law of motion. In words, the state vector next period is a function of the previous period's state vector, plus some innovation or disturbance.  Since we iterate on the state vector $s_{t-1}$ to get the next period $s_{t}$, it's clear that $T$ must be square, while $C$ and $\varepsilon_t$ are vectors the same size as $s_t$.

But since the states might be unobserved (so that they do not have a directly measurable series associated with them), we have to relate it to the data somehow, which is where the next equation comes in.

\paragraph{Measurement Equation} Equation \ref{moe}, sometimes called the ``Observation Equation'', relates the states to the directly measurable observables, allowing for potential ``measurement error'' captured by $\eta_t$. More succinctly, $M$ is a matrix that maps states to observables. Since the number of states and observables may differ, $M$ need not be square. Clearly, $D$ and $\eta_t$ must be the same size as $y_t$.

\paragraph{Note on Free Parameters} (UPDATE THIS)
When we write down the model, we will need to pre-specify certain parameters in both equations.
While our goal will be estimate in Equation \ref{ste} has to be estimated ($\{s_t\}$, $T$, $R$), the matrix $M$ will need to be pre-specified by the econometrician. Matrix $M$ makes explicit our idea of the relationship between the observables we see and the deep underlying model dynamics that (we think) drive what's observed. Of course, this relationship cannot be estimated; it can only be imposed via $M$.

\newpage
\subsection{Expanding the State Space}

In this section, we show two examples of expanding the state space (introducing extra states), and why we might want to do that. 

\subsubsection{Introducing Extra Lags}

Equation \ref{ste} only explicitly incorporates one lag of the state vector. But suppose $s_t$ depends upon more than one lag. Not a problem; the representation in Equation \ref{ste} will still work if we expand the state space. Specifically, we can rewrite the State Transition Equation (in stacked vector and block matrix form) as 
\begin{align}
  \begin{bmatrix} s_{t} \\ s_{t-1}
  \end{bmatrix}
     &= 
  \begin{bmatrix} C \\ \mathbf{0} 
  \end{bmatrix}
  +\begin{bmatrix} T_1 & T_2 \\ I & \mathbf{0}
  \end{bmatrix}
  \begin{bmatrix} s_{t-1} \\ s_{t-2}
  \end{bmatrix}
  + \begin{bmatrix} 
      \varepsilon_{t}  \\ \mathbf{0}
    \end{bmatrix}
  \label{augmented.lags} 
\end{align}
So now our new state vector is no longer $s_t$, but the stacked $z_t:=(s_t \;\; s_{t-1})'$. In this formulation, $T_1$ captures the dependence of $s_t$ upon $s_{t-1}$, while $T_2$ captures the dependence upon $s_{t-2}$. The bottom half of the transition matrix above will enforce that $s_{t-1}=s_{t-1}$. The necessary changes to the measurement equation are obvious.

To incorporate still more lags, the modifications to the state transition equation are similarly straightforward. In addition, it may even be the case that we need to use extra lags for only a few elements of $s_t$, rather than all elements of $s_t$. In such cases, Equation \ref{augmented.lags} can be simplified so that we augment the state vector with only the necessary lags, rather than $s_{t-1}$ (on the lefthand side) in it's entirety. Only the most minor of adjustments to the transition matrix would be necessary.


\subsubsection{Measurement Error as a State}

While the two-equation framework set up in (\ref{ste}) and (\ref{moe}) might be the most intuitive representation of our system, it might be easier (for programming or computational reasons) to remove measurement error from the measurement/observation equation. We can do so by, again, enlarging the state space and incorporating any measurement error as extra states.

So we now rearrange the terms in Equations \ref{ste} and \ref{moe} into new State Transition and Measurement Equations. Again, we use stacked vector and block matrix form, augmenting the state vector with extra rows, $s'_t$, which capture the contribution from the measurement errors:
\begin{align}
  \text{State Transition Equation:} \quad
    \begin{bmatrix} s_{t} \\ s'_t \end{bmatrix}
    &= \begin{bmatrix} C \\ \mathbf{0} \end{bmatrix}
    + \begin{bmatrix} T & \mathbf{0} \\ 
    \mathbf{0} & \mathbf{0} \end{bmatrix}
    \begin{bmatrix} s_{t-1} \\ s'_{t-1} \end{bmatrix}
    + \begin{bmatrix} \varepsilon_{t} \\ \eta_t \end{bmatrix}
    \label{ste.withmerr}
  \\ \notag \\
  \text{Measurement Equation:} \quad
    y_{t} &= D + 
    \begin{bmatrix} M & \mathbf{0} \end{bmatrix}
    \begin{bmatrix} s_{t} \\ s'_t \end{bmatrix}
\end{align}
In this representation, $s'_t$ effectively ``carries'' the measurement error from the state transition equation down to the measurement equation. But any past contributions from measurement errors are decisively zeroed out going forward, as we see in the new transition matrix of Equation (\ref{ste.withmerr}).


\subsection{Examples within the State Space Framework}

A few examples can best illustrate how state space models work in practice. Rather than just listing equations and general forms, we will fully specify some typical examples in state space form.

By casting some familiar models into state space, we show that state space models really do unify and generalize many different ideas. In addition, we show that the state space framework can handle a larger class of problems, as the two layers of states and observables easily accommodate distinctions between ``true values'' we hope to discern and the noisy measures we actually observe---as in the GDP example below.\footnote{Regular time series analysis doesn't usually allow for such distinctions, treating the observed series as \emph{the} true value always.}

\subsubsection{AR Model}

Suppose that we have some variable $x_t$ that evolves according to an AR($p$) process, where $\mu$ denotes the mean of the series.\footnote{Both here and in the next subsection, $\mu$ is assumed to be known. Otherwise, it would need to be estimated, as we will describe in later sections.} In other words,
\[
  (x_t - \mu) = \sum^p_{i=1} \rho_i (x_{t-i} - \mu) 
  + \varepsilon_t
\]
Since the state transition equation relates past and present, this is where we will express the autoregressive relationship, using the approach in Subsection (Extra Lags) to augment the state vector to include extra lags:
\[
  s_t = 
  \begin{bmatrix} x_t - \mu \\ x_{t-1} - \mu \\ \vdots \\
    x_{t-p+1} - \mu \end{bmatrix}
  = 
  \begin{bmatrix}
    \rho_1 & \rho_2 & \cdots & \rho_{p+1} & \rho_p \\
    1 & 0 & \cdots & 0 & 0 \\
    0 & 1 & \cdots & 0 & 0 \\
    \vdots & \vdots & \ddots & \vdots & \vdots \\
    0 & 0 & \cdots & 1 & 0 \\
  \end{bmatrix}
  \begin{bmatrix} x_{t-1} - \mu \\ x_{t-2} - \mu \\ \vdots \\
    x_{t-p}- \mu \end{bmatrix}
  + \begin{bmatrix} \varepsilon_t \\ 0 \\ \vdots \\ 0 
  \end{bmatrix}
\]
Finally, we specify the measurement equation to account for the de-meaning of $x_t$ within the state transition equation. Since we don't consider the additional layer of measurement error within regular AR($p$) models, we don't add any term for the error:
\[
  y_t = \begin{bmatrix} x_t \end{bmatrix}
  = \mu + 
  \begin{bmatrix}
  1 & 0 & \cdots & 0 \\
  \end{bmatrix}
  \begin{bmatrix} x_t - \mu \\ x_{t-1} - \mu \\ \vdots \\
    x_{t-p+1} - \mu \end{bmatrix}
\]
Thus, we have now embedded the simple AR($p$) model within a state space framework.

\subsubsection{MA Model}

Now, let's consider an MA($q$) model: 
\[
  (x_t - \mu) = \varepsilon_t 
  + \sum^q_{i=1} \theta_i  \varepsilon_{t-i}
\]
Since we'll need to keep track of lagged \emph{innovations}, we'll incorporate those as elements of our state vector, rather than lagged values of $x_t$.\footnote{Here, we see a great example of the flexibility that state space models offer---the many different ways they allow the econometrician to think about and model the system.} This gives a state transition equation of 
\[
  s_t = 
  \begin{bmatrix}
  \varepsilon_t \\ \varepsilon_{t-1} \\
  \vdots \\ \varepsilon_{t-q}
  \end{bmatrix}
  = \begin{bmatrix}
  0 & 0 & \cdots & 0 & 0 \\
  1 & 0 & \cdots & 0 & 0\\
  0 & 1 & \cdots & 0 & 0\\
  \vdots & \vdots & \ddots & \vdots & \vdots\\
  0 & 0 & \cdots & 1 & 0\\ 
  \end{bmatrix}
  \begin{bmatrix}
  \varepsilon_{t-1} \\ \varepsilon_{t-2} \\
  \vdots \\ \varepsilon_{t-q-1}
  \end{bmatrix}  
  + \begin{bmatrix}
  \varepsilon_t \\ 0 \\ \vdots \\ 0 
  \end{bmatrix}
\]
Which then leads to the following observation equation. Again, no term for measurement error is necessary:
\[
  y_t = 
  \begin{bmatrix} x_t \end{bmatrix}
  = \mu +  
  \begin{bmatrix} 1 & \theta_1 & \theta_2 & \cdots &
    \theta_q \end{bmatrix}
  \begin{bmatrix}
  \varepsilon_t \\ \varepsilon_{t-1} \\
  \vdots \\ \varepsilon_{t-q}
  \end{bmatrix}
\]

\subsubsection{GDP: Income and Expenditure}
We also present an example where there is some unobserved ``true'' level of GDP that we hope to capture, using two alternative measures that ostensibly measure the same thing---the income and expenditure measures of GDP. However, because of measurement error in both series, they provide only a ``noisy'' measure. This is a situation ideally suited to a state space representation.


\newpage
\section{Kalman Filter and Smoother}

Within the state space framework detailed above, we know face the task of estimating the sequence of (possibly unobserved) states. To do so, we typically use the Kalman filter, a recursive procedure to forecast and estimate states over time. The next section will illustrate 

\subsection{Basic Idea and Terminology}

Here's the basic procedure associated with the Kalman
Filter to estimate and forecast the state vector, $s_t$, given data vector $y_t$ for which we have observations running from $t=1$ until $t=T$. Thereafter, we will construct forecasts.
\begin{enumerate}
\item Start with a prior for the state vector at time $t$, call it, call it $p(s_t | s_{t-1}, y_{t-1})$. In the case where $t=1$, this is a true prior in that you don't use any data. 
\item Observe the realized data point, $y_t$. 
\item ``Filter'' out the noise and compute the ``filtering distribution'': $p(s_t | y_t)$.
\item Compute the predictive distribution, $p(s_{t+1} | s_t, y_t)$, based on the filtering distribution and the your model's law of motion. 
\item Take Increment $t$ and return to step 1, taking
the predictive distribution as your prior.
\end{enumerate} The remainder of this section will put some more structure to this basic idea, filling in the mathematical details. But first, a minor but very important detour.

\subsection{Regression and Conditional Distributions with Multivariate Normal RV's}

Suppose that There is a multivariate normal random variable $X$, which can be partitioned into two pieces and written
\[
  X \sim N(\mu, \Sigma) \quad\Leftrightarrow\quad
  \begin{bmatrix} X_1 \\ X_2 \end{bmatrix}
  \sim 
  N\left(\begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix},
  \begin{bmatrix} \Sigma_{11} & \Sigma_{12} \\
  \Sigma_{21} & \Sigma_{22} \end{bmatrix} 
  \right)
\]

\section{Filtering Step}

Suppose we want to measure some latent state variable $x$. We will 
assume a \emph{prior} that is multivariate normal such that
    \[ x \sim \text{N}(\hat{x}, \Sigma) \]
Next, we ``measure'' $x$ by matching it to an observable in
a \emph{measurement equation}:
    \[ y = G x + v \qquad v\sim \text{N}(0, R) \]
where $R$ is positive definite, while $G$ and $R$ are both 
$2 \times 2$. This forms the \emph{likelihood}.
\\
\\
We then ``filter'' out the noise, updating our view of $x$ in
light of the data in the filtering step using Bayes' Rule.
Note, this is called ``filtering'' because we don't use the prior
and likelihood to forecast into
the future. We combine the prior with the likelihood only to filter
out noise and get closer to the true value of $x$ based on
the data, summarized in the posterior, or the
\emph{filtering distribution}:
\begin{align}
    p(x \; | \; y) &= \frac{p(y \; | \; x) \cdot p(x)}{p(y)} 
    \propto p(y \; | \; x) \cdot p(x) \label{xgiveny} \\
    &\propto \exp\left\{-\frac{1}{2}
	\left( y - Gx \right)' R^{-1} \left(y-Gx\right)
	\right\} \exp\left\{-\frac{1}{2}( x - \hat{x} )' 
	\Sigma^{-1} (x-\hat{x})\right\} \notag
\end{align}
Now let's expand the term in the lefthand exponential:
\begin{align*}
    A = \left( y - Gx \right)' R^{-1} \left(y-Gx\right) &= 
	\left( y' - x'G' \right) R^{-1} \left(y-Gx\right) 
    = \left( y'R^{-1} - x'G'R^{-1} \right)  \left(y-Gx\right) \\
    &= \left( y'R^{-1}y - y'R^{-1} Gx - x'G'R^{-1} y 
	+ x'G'R^{-1} Gx\right)
\end{align*}
And now the same for the righthand exponential:
\begin{align}
     B = ( x - \hat{x} )' \Sigma^{-1} (x-\hat{x}) 
	&= ( x' - \hat{x}' ) \Sigma^{-1} (x-\hat{x}) \notag\\
    &=  (x'\Sigma^{-1} - \hat{x}'\Sigma^{-1})   
	(x-\hat{x}) \notag \\
    &=  x'\Sigma^{-1} x - x'\Sigma^{-1} \hat{x} - 
	\hat{x}'\Sigma^{-1} x
	+ \hat{x}'\Sigma^{-1} \hat{x} \label{B}
\end{align}
Adding the two exponentials, we get:
\begin{align*}
    C = A + B &= x' \left( \Sigma^{-1} + G'R^{-1}G\right) x 
	- x' (\Sigma^{-1} \hat{x} + G'R^{-1}y)
	- (\hat{x}' \Sigma^{-1} + y' R^{-1}G) x  \\
	& \qquad + \hat{x}' \Sigma^{-1} \hat{x} + y' R^{-1} y 
\end{align*}
Now notice that Expression \ref{xgiveny} is the probability
distribution of $x$ \emph{conditional} on $y$ and pretty
much anything else that isn't $x$.  And because of the
wonderful properties of the exponential function and the
black-hole powers of the proportionality constant, we'll be
able to simplify things nicely (and we'll worry that the
distribution $p(x|y)$ integrates to one later on).  

So in the expression for $C$, the two terms
in the second row \emph{don't} depend upon $x$. Therefore,
letting $C(x)$ be the portion of $C$ that depends upon
$x$, and letting $C(\lnot x)$ bet the additive terms which
don't depend upon $x$, we can simplify
\begin{align*}
    p(x\; | \; y) &\propto \exp\left\{ -\frac{1}{2}
	C \right\} = \exp\left\{ -\frac{1}{2}
	\left[C(x) + C(\lnot x) \right]\right\}  \\
    &\propto \exp\left\{ -\frac{1}{2}
	C(x)\right\} +  \exp\left\{ -\frac{1}{2} C(\lnot x) 
	\right\}  \\
    &\propto \exp\left\{ -\frac{1}{2}
	C(x)\right\}
\end{align*}
We just absorb the portion not relevant to $p(x|y)$ into
the proportionality constant.  This means our the work we
did above to get $C$ simplifies our target expression to
\begin{align}
    p(x\;|\;y) &\propto \exp\left\{-\frac{1}{2} \left[
	x' \left( \Sigma^{-1} + G'R^{-1}G\right) x 
	- x' (\Sigma^{-1} \hat{x} + G'R^{-1}y)
	- (\hat{x}' \Sigma^{-1} + y' R^{-1}G) x  \right]\right\}
	\label{tosimp}
\end{align}
\paragraph{Goal}
Now this doesn't look too helpful, but with a little bit of 
work, we can turn this into the probability distribution
for a multivariate normal random variable. 
In fact, the rest of the section may look complicated, but
keep in mind the big picture: the likelihood and prior
were both multivariate normal, so 
the posterior $p(x|y)$ is going to be normal. We just want
to identify the mean vector and variance-covariance matrix;
then we're home.

\paragraph{Variance} So first, the {variance} of the 
normal distribution corresponding to $p(x|y)$ can
be derived by examining Equation \ref{tosimp} and likening
it to Equation \ref{B} (which gives the contents of the 
exponential in the prior MVN distribution of $x$).  

Namely, the inverse of the new variance,
which we'll denote as $\Sigma^F$ will be sandwiched in 
between $x'$ and $x$ in Equation \ref{tosimp}, just as it 
was sandwiched between $x'$ and $x$ in Equation \ref{B}.
We use this fact, along with the 
the Woodbury matrix identity (stated in 
the appendix) to derive:
\begin{align}
    \Sigma^{F} &= \left( \Sigma^{-1} + G'R^{-1}G\right)^{-1} 
	\notag \\
    \text{Woodbury Identity} \Rightarrow
	\qquad &=  \Sigma - \Sigma G'(R 
	    + G\Sigma G')^{-1}
	    G\Sigma
	    \label{covar}
\end{align}
\paragraph{Mean} 
Next, we want to get the {mean} of the distribution of 
$p(x|y)$, which we'll denote by $\hat{x}^F$.  Again, once we
take a second and compare Expression \ref{tosimp}
to Expression \ref{B}, it's becomes clear from inspection 
that we must have 
\begin{equation}
    \label{notobvious}
    (\Sigma^{-1} \hat{x} + G'R^{-1}y) 
	= \left( \Sigma^{-1} + G'R^{-1}G\right) Z
\end{equation}
To see this, 
liken the lefthand side of Equation \ref{notobvious} (which 
itself comes from Expression \ref{tosimp}) to
the result of the matrix multiplication $\Sigma^{-1}\hat{x}$ in
Equation \ref{B}. To get the righthand side, use the fact
that we \emph{know} the Equation \ref{notobvious} analogue
to Equation \ref{B}'s $\Sigma^{-1}$, which we just 
derived in the variance section and called $\Sigma^F$.
\\
\\
So all that's left to do is solve for $Z$ in Equation
\ref{notobvious}.  The result will turn out to be our mean
vector for the posterior, $\hat{x}_F$:
\begin{align}
    \label{mean}
    \hat{x}^F = Z 
        &= \hat{x} 
        + \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
        \left( y - G \hat{x} \right)  
\end{align}
If you want to see the nasty linear algebra that gets you
to this result, you can check out the appendix. Or you can 
you just take this result as given and save yourself an
hour of painstaking derivation and eye-crossing complications,
unlike myself.\footnote{But if you \emph{do} look at the appendix,
you might just give my semi-wasted hour some meaning, in which 
case---thank you.}
\\
\\
Putting together the expressions for the mean and variance
(see Equations \ref{mean} and \ref{covar}, respectively)
of the posterior estimate for $x|y$ (i.e. the ``filtering
distribution''), we get that
\begin{align}
    x | y &\sim \text{N} \left(\hat{x}^F, \; \Sigma^F\right) 
    \label{filtered} \\
    \notag\\
    \text{where} \quad \hat{x}^F &= \hat{x} 
	+ \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
	\left( y - G \hat{x} \right)  \notag \\
    \Sigma^F &= \Sigma - \Sigma G'(R 
	    + G\Sigma G')^{-1}
	    G\Sigma \notag
\end{align}
Notice that our new ``filtered'' mean is simply a 
combination of our prior mean, $\hat{x}$, and 
a transformation of the ``error'' between our
observed value and the prior guess for that
observable ($y - G\hat{x}$).

\newpage
\paragraph{Recap} Okay, so what did we just do? 
\begin{enumerate} 
    \item We took a Multivariate Normal (MVN) prior to 
	summarize our beliefs about a latent, imperfectly 
    observable state variable $x$. 
    \item Knowing that we'll observe some data, $y$, which
	provides a ``noisy'' measure of $x$, we postulated a 
	likelihood $p(y|x)$ that is also MVN. 
    \item Then, using Bayes' Rule, we combine the information
	contained in our prior $p(x)$ and the data (via
	the likelihhod $p(y|x)$) to get a ``filtered'' 
	distribution of $x$, $p(x|y)$, given the data and our
	prior.
\end{enumerate} 
Why might this long, tortuous, painful process help us in
economics?  Well, imagine that in our model, there's some 
state for the ``natural rate of unemployment,'' denoted by $x$.  
Now of course, we can't observe that value.  But we'll have
economic statistics, like measurements of unemployment itself along 
with other informative statistics such as GDP
and hours, which might provide information about the natural
rate of unemployment.
However, those statistics are imperfect and noisy.  The
Kalman Filter gives us a way to combine those noisy estimates
in with our beliefs in a principled, sensible manner.


\section{Forecasting Step}

Now let's make our model a little more dynamic and consider 
forecasting ahead. To do so, we specify a model
of how the state, $x$, evolves.  To make it easy on ourselves,
let's assume everything's Gaussian (woohoo! that's easy):
\begin{equation}
    \label{lom}
    x_{t+1} = Ax_t + w_{t+1} \qquad w_t \sim \text{N}(0, Q)
\end{equation}
Now, we want to come up with a \emph{predictive distribution}
given our prior and the current information encapsulated in 
our filtering distribution, $p(x|y)$. Since we're assuming
everything is normal, we need only pin down the
mean and variance of the forecast, since linear combinations
of Gaussian variables are Gaussian.  

Of course, these kinds of things are well known for  
MVN random variables, which has the nice properties
\begin{align*}
    E[AX] &= A E[X] = A \mu \\
    \text{Var}(AX) &= A \text{Var}(X) A' = A\Sigma A' \\
    \text{where} \quad X &\sim \text{N}(\mu, \Sigma)
\end{align*}
Now let's use these facts, along with the assumption
that we're predicting $x_{t+1}$ by starting with a 
\emph{filtered} $x_t$ (denoted $x^F_t$ which has the 
distribution in Equation \ref{filtered}), and 
assuming $x^F_t$ is uncorrelated with $w_{t+1}$:
\begin{align}
    E[x_{t+1}] &= E\left[A{x}^F_{t} + w_{t+1} \right] 
        = AE\left[{x}^F_{t}\right] + E\left[w_{t+1} 
            \right] \notag\\
        &= A \hat{x}^F_{t} + 0 = A \hat{x}^{F}_t
            \label{intfore_mean}\\
    \text{Var}({x}_{t+1}) &= 
        \text{Var}(A{x}^F_{t} + w_{t+1}) 
        = A\text{Var}\left({x}^F_{t}\right)A' 
            +\text{Var}(w_{t+1})\notag \\
        &= A\Sigma^F_t A' + Q \label{intfore_var}
\end{align}
where $\hat{x}^F_t$ and $\Sigma_t^F$ are as above in Equation 
\ref{filtered}. This characterizes the distribution for the
one step ahead forecasting distribution.

\newpage
Now, we can simplify what we have a bit more by defining 
the \emph{Kalman Gain}:
\begin{equation}
    \label{kalgain}
    K_\Sigma = A\Sigma G' (R + G\Sigma G')^{-1}
\end{equation}
We see the practical use of this by subbing in the full
expressions for $\hat{x}_t^F$ and $\Sigma_t^F$ into Equations 
\ref{intfore_mean} and \ref{intfore_var} above,
and then simplifying our expressions for the
mean and variance as a function of the Kalman Gain:
\begin{align}
    \hat{x}_{t+1} &= E[x_{t+1}] = 
        A\left\{ \hat{x}_t
	    + \left[\Sigma_t G' (R + G \Sigma_t G')^{-1}  \right]
        \left( y - G \hat{x}_t \right) \right\} \notag \\
        &= A\hat{x}_t + K_{\Sigma_t} (y - G \hat{x}_t) 
        \label{foremean} \\
    \Sigma_{t+1} &= \text{Var}(x_{t+1}) = 
        A \left\{ \Sigma_t - \Sigma_t G'(R 
	    + G\Sigma_t G')^{-1}
        G\Sigma_t \right\} A' + Q \notag \\
    &= A\Sigma_t A' - K_{\Sigma_t} G \Sigma_t A' + Q
        \label{forevar}
\end{align}


\section{Full Recursive Procedure}

Now we need to build up the recursive algorithm to forecast 
further into the future. Let $t$ be the current time period, 
and we proceed as follows:
\begin{enumerate}
    \item Start with a prior in the current period at 
        time $t$, as given above
        \[ p_{t}(x) \sim \text{N}\left(\hat{x}_t, \; 
            \Sigma_t\right) \]
    \item Observe the current measurement, $y_t$.
    \item Update and filter out the noise as we did in
        the Filtering Section to get, you guessed it,
        the filtering distribution: $p_t(x | y) = 
        \text{N}(\hat{x}^F_t, \Sigma^F_t)$.
    \item Compute the predictive distribution 
        $p_{t+1}(x) = \text{N}(\hat{x}_{t+1}, \Sigma_{t+1})$
        from the filtering distribution, $p_t(x|y)$, and
        the law of motion in Equation \ref{lom}.
    \item Increment $t$. Return to step 1, taking
        the predictive distribution, $p_{t+1}(x)$, as
        the prior.
\end{enumerate}


\section{Convergence}

Now since $x_{t}$ is random from the perspective
of time $t-1$ (i.e. there is some irreducable uncertainty
resulting from shocks at time $t$), we know that $\Sigma_t$
will never be zero, unless $w_t$ in Equation \ref{lom} is 
degenerate. However, we might ask whether $\Sigma_t$, our
measure of uncertainty for our prediction $\hat{x}_t$
of $x_t$, will ever converge to a \emph{constant} matrix over
time. 

Recall how $\Sigma_t$ evolves, as specified in Equation 
\ref{forevar} (substituting in for the Kalman Gain, 
$K_\Sigma$), which gives the non-linear difference equation:
\begin{equation}
    \label{sig_euler}
    \Sigma_{t+1} = A\Sigma_t A' - K_{\Sigma_t} G \Sigma_t A' + Q
\end{equation}
If it were the case that $\Sigma_t$ converges to some fixed
matrix, then there would be a fixed point, $\Sigma^*$, satisfying 
Equation \ref{sig_euler} as follows:
\begin{equation}
    \label{riccati}
    \Sigma^* =
        A\Sigma^* A' - A\Sigma^* G' (R + G\Sigma^* G')^{-1} G \Sigma^* A' + Q
\end{equation}
This is known as the \emph{Discrete Time Algebraic Riccati Equation}.
A sufficient condition for convergence is that all the eigenvalues of
$A$, $\lambda_i$, satisfy $|\lambda_i|<1$. 








%%%% APPPENDIX %%%%%%%%%%%

\newpage
\appendix

\section{Woodbury Matrix Identity}

For matrices $A$, $U$, $C$, and $V$:
\begin{equation}
    (A+UCV)^{-1} = A^{-1} - A^{-1} U(C^{-1} + VA^{-1}U)^{-1}
	VA^{-1}
\end{equation}
Now consider the special case we have above with the
Kalman filter:
\begin{equation}
    \label{special}
    (A + V'CV)^{-1} = A^{-1} - A^{-1} V'(C^{-1} + VA^{-1}V')^{-1}
	VA^{-1}
\end{equation}

\section{Derivation of the Mean}

Recall what we want to show.  For $\hat{x}_F \equiv Z$, we want
to show that
\begin{align*}
    (\Sigma^{-1} \hat{x} + G'R^{-1}y) 
	&= \left( \Sigma^{-1} + G'R^{-1}G\right) Z \\
    \Rightarrow 
    \hat{x}_F = Z 
        &= \hat{x} 
        + \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
        \left( y - G \hat{x} \right)  
\end{align*}
And so we solve this equation by using the Woodbury matrix
identity representation from above:
\begin{align*}
    (\Sigma^{-1} \hat{x} + G'R^{-1}y) &= 
	\left( \Sigma^{-1} + G'R^{-1}G\right) Z \\
    \Rightarrow \quad Z &=
	\left( \Sigma^{-1} + G'R^{-1}G\right)^{-1} 
	(\Sigma^{-1} \hat{x} + G'R^{-1}y) \\
    Z &= 
	\left( \Sigma - \Sigma G'(R 
	+ G\Sigma G')^{-1}
	G\Sigma\right) \left(\Sigma^{-1} \hat{x} 
	+ G'R^{-1}y\right)
\end{align*}
Now let's simplify $\hat{x}_F = Z$ a bit, 
expanding out the multiplication:
\begin{align*}
    \hat{x}_F = Z &= 
	\left( \Sigma - \Sigma G'(R 
	+ G\Sigma G')^{-1}
	G\Sigma\right) \left(\Sigma^{-1} \hat{x} 
	+ G'R^{-1}y\right) \\
    \text{FOIL} \quad &= \hat{x} + \Sigma G' R^{-1} y - 
	\left[\Sigma G' (R + G \Sigma G')^{-1} G \Sigma\right]
	\left[ \Sigma^{-1} \hat{x} \right]  \\
    &\qquad - \left[\Sigma G' (R+ G \Sigma G')^{-1}G\Sigma \right]
	\left[G' R^{-1} y \right] \\
    \text{Simpify} \quad &= \hat{x} + \Sigma G' R^{-1} y - 
	\left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
	\left( G \hat{x} \right)  \\
    &\qquad - \Sigma G' (R+ G \Sigma G')^{-1}G\Sigma 
	G' R^{-1} y  \\
    \text{Change Order} \quad &= \hat{x} 
	- \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
	\left( G \hat{x} \right)  \\
    &\qquad 
	+ \Sigma G'  R^{-1} y 
	- \Sigma G' (R+ G \Sigma G')^{-1}G\Sigma  
	G' R^{-1} y \\
    \text{Regroup} \quad &= \hat{x} 
	- \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
	\left( G \hat{x} \right)  \\
    &\qquad 
	+ \Sigma G'  \left\{ R^{-1}  
	-  (R+ G \Sigma G')^{-1}G\Sigma  
	G' R^{-1} \right\} y 
\end{align*}
Okay, now let's take a breather.  We'll make this a bit
easier on ourselves, and just consider simplifying the guy
in the brackets, $\{\}$ by using 
$A^{-1} A = I$ with a very special choice of $A$:
\begin{align*}
    \left\{ R^{-1}  -  (R+ G \Sigma G')^{-1}G\Sigma  
	G' R^{-1} \right\}   &=   
	(R+ G \Sigma G')^{-1} (R+ G \Sigma G') R^{-1}  \\
    &\qquad -  (R+ G \Sigma G')^{-1}G\Sigma  
	G' R^{-1} \\
    \text{Group} \quad &=   (R+ G \Sigma G')^{-1} \left[ (R+ G \Sigma G') R^{-1}  
	-  G\Sigma   G' R^{-1}\right] \\
    \text{Distribute} \quad &=   (R+ G \Sigma G')^{-1} \left[ RR^{-1} 
	+ G \Sigma G'R^{-1} -  G\Sigma   G' R^{-1}\right] \\
    \text{Simplify} \quad &=   (R+ G \Sigma G')^{-1} \left[ I 
	+ 0\right] \\
    &=   (R+ G \Sigma G')^{-1} 
\end{align*}
Substituting back in above for the term in braces, 
$\{\}$, we get the following expression
for $Z = \hat{x}_F$:
\begin{align}
    \hat{x}_F = Z &= \hat{x} 
	- \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
	\left( G \hat{x} \right)  
	+ \Sigma G'  (R+ G \Sigma G')^{-1} y \notag \\
    &= \hat{x} 
	+ \left[\Sigma G' (R + G \Sigma G')^{-1}  \right]
	\left( y - G \hat{x} \right)  
\end{align}

\end{document}



%%%% INCLUDING FIGURES %%%%%%%%%%%%%%%%%%%%%%%%%%%%

   % H indicates here 
   %\begin{figure}[h!]
   %   \centering
   %   \includegraphics[scale=1]{file.pdf}
   %\end{figure}

%   \begin{figure}[h!]
%      \centering
%      \mbox{
%	 \subfigure{
%	    \includegraphics[scale=1]{file1.pdf}
%	 }\quad
%	 \subfigure{
%	    \includegraphics[scale=1]{file2.pdf} 
%	 }
%      }
%   \end{figure}
 

%%%%% Including Code %%%%%%%%%%%%%%%%%%%%%5
% \verbatiminput{file.ext}    % Includes verbatim text from the file
% \texttt{text}	  % includes text in courier, or code-like, font
