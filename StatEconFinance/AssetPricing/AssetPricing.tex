\documentclass[a4paper,12pt]{scrartcl}

\author{Matthew Cocci}
\title{Asset Pricing}
\date{\today}
\usepackage{enumitem} %Has to do with enumeration	
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm} %allows for labeling of theorems
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{blindtext}
\usepackage{graphicx}
%\usepackage[hidelinks]{hyperref} % For internal/external linking. 
				 % [hidelinks] removes boxes
% \usepackage{url} % allows for url display, non-clickable
%\numberwithin{equation}{section} 
   % This labels the equations in relation to the sections 
      % rather than other equations
%\numberwithin{equation}{subsection} %This labels relative to subsections
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\setkomafont{disposition}{\normalfont\bfseries}
\usepackage{appendix}
\usepackage{subfigure} % For plotting multiple figures at once
\usepackage{verbatim} % for including verbatim code from a file
\usepackage{natbib} % for bibliographies

\begin{document}
\maketitle

% \tableofcontents %adds it here

\section{Introduction}

If all of Asset Pricing needed to be reduced to one simple,
general, yet wholly appropriate epithet, a decent starting
point would be ``Price equals expected discounted payoff.''
\\
\\
To segment the discussion further, John Cochrane suggests the
following two classes of pricing approaches in his 
Asset Pricing book:
\begin{enumerate}
    \item {\sl Absolute Pricing}: ``Pricing assets by exposure
	to fundamental sources of macroeconomic risk.'' This
	approach includes general equilibrium models. 
    \item {\sl Relative Pricing}: This type of pricing considers
	only how an asset should be priced relative to 
	other assets that can be bought and sold in the
	market. Black-Scholes and any arbitrage arguments
	would fall under this category.
\end{enumerate}
However, many asset pricing approaches are a blend of the two.
\\
\\
To be more specific, we can reduce asset pricing to two 
equations:
\begin{equation}
    p_t = E[m_{t+1} x_{t+1} ]
\end{equation}
\begin{equation}
    m_{t+1} = f(\text{data, parameters})
\end{equation}
where $p_t$ is the asset price, $x_{t+1}$ is the asset's payoff,
and $m_{t+1}$ is the stochastic discount factor.
This approach joins together what used to be separate theories so
that pricing stocks, bonds, and options now represent special
cases of this more general framework summarized by the equations above.


\newpage
\section{Asset Pricing Facts}

There are a number of empirical observations that have been made
over the years, and this section will detail their conclusions
and main insights.

\subsection{Equity Premium and Risk}

We'll beging by thinking about the \emph{Equity Premium}, which 
is the returns to stocks above and beyond bonds (so if you borrow
in bonds and lend in stocks): $E[R^{\text{stocks}}-R^{\text{bonds}}]$.
Here are the facts:
\begin{enumerate}
    \item The equity premium is \emph{big}, about 7\%.
    \item There's a lot of risk in stocks: there's a greater 
	standard deviation in returns (although we'll think about
	risk a bit differently). Stock returns are also correlated
	with macro variables.
    \item Compared with stocks returns, GDP and Consumption growth are much
	more stable, though they do vary a bit (with the standard deviation
	being much closer to bond returns' volatility than stock returns).
\end{enumerate}

\subsection{Time-Varying Risk Premium}

Now we want to consider what explains the Equity Premium. For that,
we regress returns on some signal we hope will explain future returns.
Here's a few regressions. The main result will be that 
\emph{excess returns} are forecastable---that is, the time-varying
reward for risk can be forecast. We're not forecasting raw rate. 
Now onto facts:
\begin{enumerate}
    \item {\sl Old View}: Regression of returns on lagged returns:
	    \[ R_{t+1} = a + b R_t + \varepsilon_{t+1} \]
	This regresion typically yields a value for $b$ around
	0, in which case future returns given returns today
	are more or less \emph{random}.  The main result:
	\begin{equation}
	    \label{oldview}
	    ER_{t+1} = E[a + 0\cdot R_t + \varepsilon_{t+1}] = a 
	\end{equation}
	in which case \emph{expected returns} are large and constant.
    \item {\sl New View}: The old view, encapsulated in Equation \ref{oldview}, 
	drove theory for many years. But now, we have a different
	picture: there are variables that forecast stock returns.
	Now, we run the regression
	\begin{equation}
	    \label{newview}
	    R^e_{t\rightarrow t+k} = a + b \left(\frac{D_t}{P_t}\right)
		+ \varepsilon_{t+k}
	\end{equation}
	where $R^e$ is the excess return over bonds, $D_t$ is current 
	dividends, and $P_t$ is current price. From this regression,
	we get a large, positive regression coefficient.
	So we actually \emph{can} predict returns over the business
	cycle via this dividend/price ratio (but it's still tough
	in the short run).

    \item {\sl New View Interpretation}: The dividend yield $(D_t/P_t)$, which
	is the inverse of prices, turns out to vary a lot over time.
	Moreover, if you buy when the dividend yield ratio is 
	\emph{high} (so that prices are low), you will earn high
	returns in expectation.  Vice versa for a low dividend yield
	ratio (so high prices). 

	Moreover, we can get the standard deviation in the expected returns over
	time, which is the fitted value $ER^e_{t\rightarrow t+k} = a + b 
	E\left(D_t/P_t\right)$ from Equation \ref{newview}. It turns
	out that expected returns \emph{also vary}, and they vary
	\emph{substatially}, at about 6\%. 
	
	Recall that it was puzzling
	that stocks should earn 7\% over bonds. Now we're saying that 
	they earn 7\% over bonds \emph{and} vary with a standard 
	deviation of about 6\% a year. Average \emph{changes} in 
	$ER^e_{t\rightarrow t+k}$ are about as much as the average
	confounding \emph{level}.\footnote{Of course, \emph{actual}
	returns vary even more than expected returns---recall about
	17\%.}
    \item {\sl Why do prices vary?}: We know that the dividend/price
	ratio varies a lot, but it's mostly driven by prices. Why?
	Well, we used to think
	\begin{equation}
	    \label{oldidea}
	    \text{High Prices} \Rightarrow \text{High Future Growth} 
		\Rightarrow \text{High E[Future Dividends]}
	\end{equation}
	But if we run the regression implied by Equation \ref{oldidea},
	\begin{equation}
	    \label{oldideareg}
	    \frac{D_{t+k}}{D_t} = a + b \left(\frac{D_t}{P_t}\right) 
		+ \varepsilon_{t+k}
	\end{equation}
	we find out that the logic of \ref{oldidea} is \textbf{wrong}.
	The regression coefficient in Equation \ref{oldideareg} is
	negligible and there is no explanatory power (as 
	reflected in the $R^2$).  So actaully
	\begin{equation}
	    \label{newidea}
	    \text{High Prices} \Rightarrow \text{Low Future E[Returns]}
	\end{equation}
	So it's not that dividends will adjust if prices are high
	and low---dividends are remarkably stable relative to prices!
	Instead, \emph{prices} will adjust.
	\\
	\\
	In short: high prices are correlated with a good economy,
	when people are willing to bear more risk.  So returns will
	be low. Vice versa for low prices.
\end{enumerate}


\newpage
\subsection{The Cross Section of Stock Returns}

We talked about returns over time in the previous sections. Now 
let's consider the facts about how returns vary \emph{across assets}
at a given time.
\begin{enumerate}
    \item {\sl Market Cap}: Small stocks earn more on average than
	large stocks.  They are also riskier.
    \item {\sl Growth vs. Value}: Value stocks (high book to value)
	tend to earn more.
    \item {\sl Capital Asset Pricing Model}: This model predicts
	returns based on the correlation between the asset and
	the market portfolio.
    \item {\sl Multifactor Model}: This model was put forward by
	Fama and French to capture the extra variation in returns
	that the Capital Asset Pricing Model failed to explain.
	This is the modern view. Specifically, Fama and French posit
	\begin{equation}
	    \label{ff3fm}
	    ER^{e,i} = \alpha_i + b_iE[R^m - R^f] + h_i E(\text{hml})
		+ s_i E(\text{smb})
	\end{equation}
	where $E($hml$)$ represents ``high minus low'' (for 
	value minus growth stocks)
	and $E($smb$)$ for ``small minus big'' (for market cap).
    \item {\sl Stock Market Volatility:} We used to think volatility
	was pretty constant over time.  Now we know that the
	variance of returns changes over time.
\end{enumerate}


\newpage
\section{Asset Pricing Theory Overview}

This section is about understanding the fundamental formula for all
of asset pricing: 
\begin{equation}
    \label{pemx}
    P_t = E_t[M_{t+1} X_{t+1}]
\end{equation}
But first, 
since we'll start talking about preferences below, we'll eventually
need a utility function ato some point.  In order to move the 
discussion along below, we consider that portion in the next
section instead.

\subsection{Utility Detour}

So first, we'll consider a simple utility function for two-period
consumption, which covers $t$ and $t+1$---the relevant time periods
in Equation \ref{pemx}. Spefically, we'll define
\begin{equation}
    \label{util}
    U(C_t, C_{t+1}) = U(C_t) + \beta E_t\left[U(C_{t+1})\right]
\end{equation}
where $\beta$ is the discount factor with respect to \emph{time},
\textbf{not} risk which depends upon the shape of the utility function.
Equation \ref{util} above is a very simple form which we can generalize
further if we choose.
\\
\\
For the \emph{internal}, one-period utility function, $U(\cdot)$, we'll want
the normal properties of utility, $U'>0$ and $U''<0$, which leads
us to define the simple \emph{power function utility}
\begin{equation}
    \label{upwr}
    U(C) = \frac{C^{1-\gamma}-1}{1-\gamma} \quad\Rightarrow\quad
	U'(C) = C^{-\gamma}
\end{equation}
This utility function also has the property that as $\gamma\rightarrow 1$,
$U(C) = \ln C$.

\subsection{Understanding the Components}

Now let's take each component of Equation \ref{pemx} in turn:
\begin{enumerate}
    \item $X_{t+1}$: This is the \emph{payoff} (in gross
	terms, not net, percentage, etc.) at time $t+1$.  Often, $X_{t+1}$ 
	will be random---it's a random variable.
    \item $P_t$: To get this payoff, $X_t$, you have to pay some price $P_t$ today. Note that
	it is possible for $P_t$ to equal 0, like it might in a bet (nothing
	today, +1 tomorrow if I win, -1 if I lose). No money changes hands.
    \item $M_{t+1}$: Recall Equation \ref{util} above.  It left
	us free parameters, $\beta$ and $\gamma$, which allow us
	to tweak ``impatience'' and time sensitivity of consumption 
	($\beta$) as well as risk-aversion via curvature ($\gamma$).
	This gives us everything we need to charactertize the discount
	factor, $M_{t+1}$.
\end{enumerate}

\newpage
\subsection{Deriving P=E(MX)}

Let's now figure out the price an investor assigns to a risky
payoff.  It reduces to a utility maximization problem:
\begin{align*}
    \max_{\xi} \quad U(C_t - \xi P_t) + \beta E_t\left[U(C_{t+1} + \xi X_{t+1})\right]
\end{align*}


\newpage
\section{Classic Issues in Finance}



%%%% APPPENDIX %%%%%%%%%%%

\newpage
\appendix


\section{Discrete Time Review}

\subsection{Basic Building Block}

The basic building block is random iid noise:
    \[ \varepsilon_t \sim \text{iid} \qquad
	E_t\varepsilon_{t+1} = 0 \qquad 
	E_t\varepsilon^2_{t+1} = \sigma_\varepsilon^2
    \]
where $E_t(\cdot)$ represents the expectation \emph{conditional} on
the information at time $t$. In practice, that means any variable
with a $t$ subscript inside a expectation, variance, covariance, etc.
operator can be taken out because it is \emph{known} at time $t$.
\\
\\
Often $\varepsilon_t$ will be draws
from a normal distribution, but they don't have to be.

\subsection{Canonical AR(1) Model}

More complicated than simple random noise, we have the AR(1) process,
which is written in one of either two standard ways, with the latter
being more common as we move to continuous time:
\begin{align*}
    x_{t+1} &= \rho x_t + \varepsilon_{t+1} \qquad 
	E_t\varepsilon_{t+1} = 0 \qquad
	E_t\varepsilon^2_{t+1} = \sigma^2_\varepsilon \\
    x_{t+1} &= \rho x_t + \sigma_\varepsilon \varepsilon_{t+1} \qquad 
	E_t\varepsilon_{t+1} = 0 \qquad
	E_t\varepsilon^2_{t+1} = 1 
\end{align*}
From there, it's easy to show via the linearity property of the 
expectation operator and by successive substitution that
\begin{align*}
    E_t x_{t+1} &= E_t[\rho x_t + \varepsilon_{t+1}] \\
    &= \rho x_t \\
    E_t x_{t+k} &= \rho^k x_t
\end{align*}
As for the variance conditional on information at time $t$, denoted
by $\text{Var}_t$, we get
\begin{align*}
    \text{Var}_t(x_{t+1}) &= \text{Var}_t(\rho x_t + \varepsilon_{t+1}) \\
	&= \sigma_\varepsilon^2 \\
    \text{Var}_t(x_{t+2}) &= \text{Var}_t(\rho x_{t+1} + \varepsilon_{t+2}) \\
	&= \text{Var}_t(\rho x_{t+1}) + \text{Var}_t(\varepsilon_{t+2}) 
	    + 2 \; \text{Cov}_t(\rho x_{t+1}, \; \varepsilon_{t+2}) \\
	&= \rho^2 \; \text{Var}_t(x_{t+1}) + \text{Var}_t(\varepsilon_{t+2}) 
	    + 0 
	= \rho^2 \sigma_\varepsilon^2 + \sigma_\varepsilon^2 \\
	&= (1+\rho^2) \sigma_\varepsilon^2 \\
    \text{Var}_t(x_{t+k}) &= (1 + \rho^2 + \cdots + \rho^{2(k-1)}) 
	\sigma^2_\varepsilon
\end{align*}
The last line we prove by induction.
\begin{proof} In the case of $k=3$, which we will take as the base
case,
\begin{align*}
    \text{Var}_t(x_{t+3}) &=  \text{Var}_t(\rho x_{t+2} + \varepsilon_{t+3}) \\
    &=\rho^2 \; \text{Var}_t(x_{t+2}) + \text{Var}_t(\varepsilon_{t+3})
	+ \text{Cov}_t(x_{t+2}, \; \varepsilon_{t+3}) \\
    \text{Var($x_{t+2}$) from above } \quad &= \rho^2 ( 1 + \rho^2) \sigma^2_\varepsilon 
	+ \sigma^2_\varepsilon + 0 \\
    &= (1 + \rho^2 + \rho^4) \sigma^2_\varepsilon 
\end{align*}
So the base case holds.  Now assume it holds for arbitrary $k$,
and show that the condition also holds for $k+1$:
\begin{align*}
    \text{Var}_t(x_{t+k+1}) &= \text{Var}_t(\rho x_{t+k} + 
	\varepsilon_{t+k+1}) \\
    &= \rho^2 \; \text{Var}_t( x_{t+k}) + \text{Var}_t(\varepsilon_{t+k+1})
	+ \text{Cov}_t(x_{t+k}, \; \varepsilon_{t+k+1}) \\
    &= \rho^2 (1 + \rho^2 + \cdots + \rho^{2(k-1)})\sigma^2_\varepsilon
	+ \sigma^2_\varepsilon \\
    &= (1 + \rho^2 + \cdots + \rho^{2([k+1]-1)})\sigma^2_\varepsilon
\end{align*}
so it holds for $k+1$.
\end{proof}

\subsection{Canonical MA(1) Model}

The basic form of the moving average MA(1) model, with conditional 
means:
\begin{align*}
    x_{t+1} &= \varepsilon_{t+1} + \theta \varepsilon_t  
    \qquad E_t \varepsilon_{t+1} = 0, \quad 
	E^2_t \varepsilon_{t+1} = \sigma^2_\varepsilon
\end{align*}
The first moments for the process, conditional on information 
at time $t$, are as follows:
\begin{align*}
    \Rightarrow \quad E_t x_{t+1} &= E_t\varepsilon_{t+1} + E_{t} [\theta \varepsilon_t ]\\
		&= \theta \varepsilon_t \\
    E_t x_{t+2} &= E_t[ \varepsilon_{t+2}  + \theta \varepsilon_{t+1} ] 
	= E_t[\varepsilon_{t+2}] + E_t[ \theta \varepsilon_{t+1} ] \\
    &= 0 \\
    E_t x_{t+k} &= 0
\end{align*}
Now for the conditional variances, dropping the covariance terms
which we included above
since innovations at different times are always independent:
\begin{align*}
    \text{Var}_t(x_{t+1}) &= \text{Var}_t(\varepsilon_{t+1} +
	\theta \varepsilon_t) \\
	&= \text{Var}_t(\varepsilon_{t+1}) 
	    + \theta^2 \; \text{Var}_t(\varepsilon_t)  \\
	&= \sigma_\varepsilon^2 \\
    \text{Var}_t(x_{t+k}) &= 
	\text{Var}_t(\varepsilon_{t+k} + \theta \varepsilon_{t+k-1}) \\
	&=  \text{Var}_t(\varepsilon_{t+k}) 
	    + \theta^2 \text{Var}_t(\varepsilon_{t+k-1}) \\
	&=  (1 + \theta^2) \sigma_\varepsilon^2 \\
\end{align*}
   
\newpage
\subsection{Unconditioanl Moments}

So far, all of the means and variances above were \emph{conditional}
on information at time $t$.  So that implies computing $E_t x_{t+1}$
and $\text{Var}_t(x_{t+1})$ via the formulas above requires knowledge 
of $x_t$.
\\
\\
{\sl Mean}:
However, suppose you wanted to generate the series from scratch.  What
is the \emph{unconditional} mean and variance so that you can draw
$x_t$ \emph{without} prior values $x_{t-1}, x_{t-2}, \ldots$?
\begin{align*}
    Ex_t &= E[\rho x_{t-1}] + E\varepsilon_t \\
	&= \rho Ex_{t-1} + 0  \\
    \Rightarrow \quad Ex_t &= 0
\end{align*}
The last line follows because the unconditional average $Ex_t$ must
equal the unconditional average $Ex_{t-1}$, forcing the expecation
to be zero.
\\
\\
{\sl Variance}: Now we do the same thing for the variance. We'll
also use the fact that the unconditional variance for $x_t$ must
equal that for $x_{t-1}$, which allows us to solve:
\begin{align*}
    \text{Var}(x_{t}) &= \text{Var}(\rho x_{t-1} + \varepsilon_t) \\
    &= \rho^2 \; \text{Var}(x_{t-1}) + \text{Var}( \varepsilon_t) \\
	\text{Using $\text{Var}(x_{t-1}) = \text{Var}(x_{t})$:} \quad
    &= \rho^2 \; \text{Var}(x_{t}) + \sigma_\varepsilon^2 \\
    \Rightarrow \quad \text{Var}(x_{t}) &= 
	\frac{\sigma^2_\varepsilon}{1-\rho^2}
\end{align*}


\subsection{Translating Between AR and MA Models}

{\sl AR to MA}: First, 
you can transform an AR(1) model into a MA($\infty$) model
by ``solving'' the AR model through successive substitution:
\begin{align*}
    x_t &= \rho x_{t-1} + \varepsilon_t \\
    &= \rho (\rho x_{t-2} + \varepsilon_{t-1}) + \varepsilon_t \\
    &= \rho^2 x_{t-2} + \rho \varepsilon_{t-1}) + \varepsilon_t \\
    &= \quad \vdots \qquad \vdots \\
    &= \sum^\infty_{j=1} \rho^j \varepsilon_{t-j}
\end{align*}
{\sl MA to AR}: Similarly, you can transform an MA(1) model to
an AR($\infty$) model as follows:


\newpage
\section{Continuous Time}

\subsection{Brownian Motion}

We define Brownian Motion, the continuous version of the random walk,
as follows:
\begin{enumerate}
    \item Normal Increments for all $\Delta \in \mathbb{R}$:
	\[ z_{t+\Delta} - z_t \sim \text{N}(0, \; \Delta) \]
    \item Independence of non-overlapping increments.
    \item Non-overlapping increments of the same length are
	identically (and normally) distributed.
\end{enumerate}

\subsection{Fundamental Building Block, $dz_t$}

Just as random noise, $\varepsilon_t$ was the basic building block
for discrete time, the analogous building block in continuous time is
\begin{equation}
    dz_t = \lim_{\Delta \rightarrow 0} z_{t + \Delta} - z_t
\end{equation}
Note, $d$ is \emph{forward} difference operator.
\\
\\
We also have the result that $dz$ is of size (or order) $\sqrt{dt}$ 
(which is equivalent to the limit of $\Delta$), since recall
\begin{align*}
    \text{Var}(z_{t + \Delta} - z_t) &= \Delta \\
    \Leftrightarrow \quad \text{Sd}(z_{t + \Delta} - z_t) &= 
	\sqrt{\Delta}
\end{align*}
So now we can see why $z_t$ is not differentiable.  Namely, if 
we tried to consider $dz_t/dt$, we know that $dz_t$ is of order
$\sqrt{dt}$; therefore, the ratio $dz_t/dt$ diverges to $\pm \infty$
since $dt$ is close to zero, while the numerator, $dz_t$ of order
$\sqrt{dt}$, is larger. So we can talk about \emph{the change}, $dz_t$,
because that change is going to be very small over short time horizons.
But we can't talk about the \emph{rate of change}, because compared
to ``the change'' in the process, the change in time is smaller still,
such that the ratio diverges.
\\
\\
{\sl Moments}: Next, we have
\begin{align*}
    E_t dz_t &= 0 \\
    \text{Var}_t(dz_t) &= dt \\
    \text{Cov}(dz_t, \; dz_s) &= 0 \qquad s\neq t
\end{align*}


\newpage
\section{Price-Dividend and Return Linearizations}

\subsection{The Identity}

We'll derive an approximation to an identity that says the following:
there are three potential reasons the price-dividend ratio might be 
high:
\begin{enumerate}
    \item Investors expect dividends to rise.
    \item Investors expect low future returns, so future cashflows
	are discounted at a lower than usual rate. This leads
	to higher prices.
    \item Investors expect prices to rise forever, giving an 
	adequate return even if there are no dividends.
\end{enumerate}
Now, we asserted above that Option 2 is the correct observation.
But how can we test that?  We'll, let's derive the identity that
lays out the theory behind Options 1-3.
\\
\\
Start with an identity, and do some rearranging, letting $R$ equal
gross returns (price increases plus dividends), $D$ be dividends, 
and $P$ be price.
\begin{align}
    1 &= R^{-1}_{t+1} R^{}_{t+1} = R^{-1}_{t+1} \frac{P_{t+1} + D_{t+1}}{P_t} \notag \\
    \Leftrightarrow \quad \frac{P_t}{D_t} &= 
	R^{-1}_{t+1} \left( 1 + \frac{P_{t+1}}{D_{t+1}}\right) \frac{D_{t+1}}{D_t}
	\label{pdid} \\
    \Leftrightarrow \quad {P_t} &= 
	R^{-1}_{t+1} \left( {D_{t+1}} + {P_{t+1}}\right) 
	\label{pid} 
\end{align}
Now, we can iterate forward Equation \ref{pid} and take a conditional
expectation to get
\begin{align}
    \label{pid2}
    P_t = E_t \sum^\infty_{j=1} \left(\prod^j_{k=1} R^{-1}_{t+k} \right)
	D_{t+j} 
\end{align}
Now look at the previous line, and do the reverse of what we did 
in going from Equation \ref{pdid} to Equation \ref{pid} (defining
$\Delta D_t := D_t / D_{t-1}$:
\begin{align}
    \Rightarrow \qquad \frac{P_t}{D_t} &= E_t \sum^\infty_{j=1} 
	\left(\prod^j_{k=1} R^{-1}_{t+k} \right)  \frac{D_{t+j}}{D_t} 
	\notag \\
    \Leftrightarrow \qquad \frac{P_t}{D_t} &= E_t \sum^\infty_{j=1} 
	\left(\prod^j_{k=1} R^{-1}_{t+k} \right)  
	\left(\prod^{j}_{k=1} \frac{D_{t+k}}{D_{t+k-1}}\right) \quad
	\text{Telescoping product trick!} \notag \\
    \Leftrightarrow \qquad \frac{P_t}{D_t} &= E_t \sum^\infty_{j=1} 
	\left(\prod^j_{k=1} R^{-1}_{t+k} \Delta D_{t+k} \right)  
	\label{pdid2}
\end{align}
So, what do we have? The identitiy in Equation \ref{pid2} tells us that 
prices will increase if the discount rate \emph{falls} or if Expected
future dividends rise.  \emph{However}, prices aren't stationary, which
is why we went to the trouble of deriving the identity in 
Equation \ref{pdid2}, which \emph{is} a stationary variable that 
captures the same logic as \ref{pid2}, and can be estimated properly
via traditional time series approaches.
    

\subsection{The Linearization}

To make the identities derived above easier to handle, we take 
logs to linearize!
Letting lowercase letters represent the logs of uppercase letters, we
get from Equation \ref{pdid}
\begin{align}
    \ln \frac{P_t}{D_t} &= 
	\ln \left\{ R^{-1}_{t+1} \left( 1 + \frac{P_{t+1}}{D_{t+1}}\right) \frac{D_{t+1}}{D_t}
	\right\} \notag \\
	p_t - d_t &= -r_{t+1} + \ln( 1 + e^{p_{t+1} - d_{t+1}})
	+ \Delta d_{t+1} \label{approx}
\end{align}
Now do Taylor Expansion of the last term about a point $P/D = e^{p-d}$ 
(we'll use both the left- and righthand side of that point to 
simplify, so watch out for that).  Also implicit in the
deriviation, I'll be evaluating the derivative in the second
term at $P/D = e^{d-d}$, so watch out for that too:
\begin{align*}
    f(p_t - d_t) &= \ln(1 + e^{p_{t+1} - d_{t+1}}) \\
    &\approx \ln(1 + e^{p - d}) + 
	\frac{d\left[\ln(1 + e^{p_{t+1} - d_{t+1}})\right]}{d(p_t - d_t)} 
	\cdot \left\{ (p_{t+1}-d_{t+1}) - (p-d) \right\} \\
    &= \ln(1 + e^{p - d}) + 
	\frac{e^{p_{t+1} - d_{t+1}}}{1+e^{p_{t+1} - d_{t+1}}} 
	\cdot \left\{ (p_{t+1}-d_{t+1}) - (p-d) \right\} \\
     &= \ln(1 + {P}/{D}) + 
	\frac{P/D}{1+P/D}
	\cdot \left\{ (p_{t+1}-d_{t+1}) - (p-d) \right\} \\
    &= \ln(1 + {P}/{D}) + 
	\rho\left\{ (p_{t+1}-d_{t+1}) - (p-d) \right\} 
\end{align*}
So now let's just plug this log-linear approximation into Equation
\ref{approx}:
\begin{equation}
    p_t - d_t \approx -r_{t+1}
	+ \Delta d_{t+1} +  k + 
	\rho\left\{ (p_{t+1}-d_{t+1}) - (p-d) \right\} \\
\end{equation}
where $k$ equals $\ln(1+P/D)$, which is a constant.\footnote{Note,
$\rho$ is just a constant of approximation that can be simplified
using the fact that dividend yields roughly 4\% on average, so
the Price/Dividend ratio is about 25:
    \[ \rho = \frac{P/D}{1+P/D} = \frac{1}{1+ D/P} \approx 1 - D/P = 0.96 \]
}
Now iterating forward is even more straightforward:
\begin{equation}
    \label{todec}
    p_t - d_t = C +  \sum^\infty_{j=1} \rho^{j-1} (\Delta d_{t+j}
	- r_{t+j})
\end{equation}
From this, it's clear that an ex-post high dividend-price ratio will result
only in the presence of high dividend growth or low subsequent returns.
To turn Equation \ref{todec} into an ex ante price-dividend ratio,
take expectations of everything on the right.


\newpage
\subsection{Decomposing the Variance}

To answer the question of what drives a high dividend-price ratio,
we'll decompose the variance in Equation \ref{todec} as follows:
\begin{align*}
    \text{Var}(p_t - d_t) = E\left[ (p_t - d_t) - E(p_t - d_t) \right]^2
    p_t - d_t = C +  \sum^\infty_{j=1} \rho^{j-1} (\Delta d_{t+j}
	- r_{t+j})
\end{align*}







%\cite{LabelInSourcesFile} 
%\citep{LabelInSourcesFile} Cites in parens
%\nocite{LabelInSourceFile} includes in refs w/o specific citation
%\bibliographystyle{apalike} 
%\bibliography{sources.bib} where sources.bib is file




\end{document}


k*mu
mu
0.5 6
k*sigma^2
sigma^2
5.77 1.04
sqrt(k)*(mu/sigma)
0.144 0.02617
the same
8.94 4.47 2.82 0.78 1.56 2.47
33
Smaller

%%%% INCLUDING FIGURES %%%%%%%%%%%%%%%%%%%%%%%%%%%%

   % H indicates here 
   %\begin{figure}[h!]
   %   \centering
   %   \includegraphics[scale=1]{file.pdf}
   %\end{figure}

%   \begin{figure}[h!]
%      \centering
%      \mbox{
%	 \subfigure{
%	    \includegraphics[scale=1]{file1.pdf}
%	 }\quad
%	 \subfigure{
%	    \includegraphics[scale=1]{file2.pdf} 
%	 }
%      }
%   \end{figure}
 

%%%%% Including Code %%%%%%%%%%%%%%%%%%%%%5
% \verbatiminput{file.ext}    % Includes verbatim text from the file
% \texttt{text}	  % includes text in courier, or code-like, font
